{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f1850bc",
   "metadata": {},
   "source": [
    "# 2-5. 프로젝트: SentencePiece 사용하기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d55c2",
   "metadata": {},
   "source": [
    "# 1. 네이버 영화리뷰 데이터 수집 (공통) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82af98df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp -r ~/aiffel/sentiment_classification/data ~/aiffel/sp_tokenizer/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "716195a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "0.5.2\n",
      "1.3.3\n",
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import konlpy\n",
    "from konlpy.tag import Mecab, Kkma, Okt, Komoran, Hannanum \n",
    "import gensim\n",
    "from collections import Counter\n",
    "import os,sys,copy,time\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "import re\n",
    "import urllib\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)\n",
    "print(konlpy.__version__)\n",
    "print(pd.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6698551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ratings_test.txt', <http.client.HTTPMessage at 0x7f81284ea3a0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_train = \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\"\n",
    "url_test = \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\"\n",
    "\n",
    "urllib.request.urlretrieve(url_train, filename=\"ratings_train.txt\")\n",
    "urllib.request.urlretrieve(url_test, filename=\"ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acbbfc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data          id                                           document  label\n",
      "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
      "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
      "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
      "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
      "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1 (150000, 3)\n",
      "------------------------------------------------------------\n",
      "test_data         id                                           document  label\n",
      "0  6270596                                                굳 ㅋ      1\n",
      "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
      "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
      "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
      "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0 (50000, 3)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table(r'~/aiffel/sp_tokenizer/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sp_tokenizer/ratings_test.txt')\n",
    "\n",
    "print(\"train_data\",train_data.head(),train_data.shape)\n",
    "print('-'*60)\n",
    "print(\"test_data\",test_data.head(),test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70323199",
   "metadata": {},
   "source": [
    "# 2. SentencePiece 토크나이저 사용의 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6537a4ac",
   "metadata": {},
   "source": [
    "* **(1) 데이터 기본적 전처리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fc8b1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data['document'].nunique() 146182\n",
      "train_data['label'].nunique() 2\n",
      "중복제거후 len(train_data) 146183\n",
      "test_data['document'].nunique() 49157\n",
      "test_data['label'].nunique() 2\n",
      "중복제거후 len(test_data) 49158\n",
      "결측치 개수 id          0\n",
      "document    1\n",
      "label       0\n",
      "dtype: int64\n",
      "결측치제거후 결측치 여부 False\n",
      "결측치 개수 id          0\n",
      "document    1\n",
      "label       0\n",
      "dtype: int64\n",
      "결측치제거후 결측치 여부 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3107/3168550979.py:36: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[' ']+\",\" \")\n",
      "/tmp/ipykernel_3107/3168550979.py:37: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"\\.{2,30}\",\" \")\n",
      "/tmp/ipykernel_3107/3168550979.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글과 공백,기타일부 등제외후 모두제거상태_train_data.head()          id                                           document  label\n",
      "0   9976970                                 아 더빙  진짜 짜증나네요 목소리      0\n",
      "1   3819312                       흠 포스터보고 초딩영화줄 오버연기조차 가볍지 않구나      1\n",
      "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
      "3   9045019                        교도소 이야기구먼  솔직히 재미는 없다 평점 조정      0\n",
      "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3107/3168550979.py:42: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document' ]= test_data['document'].str.replace(\"[' ']+\",\" \")\n",
      "/tmp/ipykernel_3107/3168550979.py:43: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"\\.{2,30}\",\" \")\n",
      "/tmp/ipykernel_3107/3168550979.py:44: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글과 공백,기타일부 등제외후 모두제거상태_test_data.head()         id                                        document  label\n",
      "0  6270596                                             굳 ㅋ      1\n",
      "1  9274899                                                      0\n",
      "2  8544678             뭐야 이 평점들은  나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
      "3  6825595                     지루하지는 않은데 완전 막장임  돈주고 보기에는       0\n",
      "4  6723715  3만 아니었어도 별 다섯 개 줬을텐데  왜 3로 나와서 제 심기를 불편하게 하죠??      0\n",
      "Nan 존재유뮤 True\n",
      "Nan 존재유뮤 True\n",
      "X_train[:5] 0                                   아 더빙  진짜 짜증나네요 목소리\n",
      "1                         흠 포스터보고 초딩영화줄 오버연기조차 가볍지 않구나\n",
      "2                                    너무재밓었다그래서보는것을추천한다\n",
      "3                          교도소 이야기구먼  솔직히 재미는 없다 평점 조정\n",
      "4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...\n",
      "Name: document, dtype: object y_train[:5] [0 1 0 0 1] X_test[:5] 0                                               굳 ㅋ\n",
      "2               뭐야 이 평점들은  나쁘진 않지만 10점 짜리는 더더욱 아니잖아\n",
      "3                       지루하지는 않은데 완전 막장임  돈주고 보기에는 \n",
      "4    3만 아니었어도 별 다섯 개 줬을텐데  왜 3로 나와서 제 심기를 불편하게 하죠??\n",
      "5                                음악이 주가 된, 최고의 음악영화\n",
      "Name: document, dtype: object y_test[:5] [1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "## 데이터로더\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "voca_size =10000\n",
    "\n",
    "def load_and_preprocess_data(train_data, test_data, voca_size = voca_size):\n",
    "    ## 중복값 제거:  'document'컬럼의 중복값 제거,'label'컬럼은 0,1의 두개면 맞음\n",
    "    #1. train_data\n",
    "    print(\"train_data['document'].nunique()\",train_data['document'].nunique())\n",
    "    if train_data['document'].nunique() < len(train_data):\n",
    "        train_data.drop_duplicates(subset=['document'], inplace=True) \n",
    "        print(\"train_data['label'].nunique()\",train_data['label'].nunique())    \n",
    "        print(\"중복제거후 len(train_data)\",len(train_data))    \n",
    "    #2. test_data    \n",
    "    print(\"test_data['document'].nunique()\",test_data['document'].nunique())\n",
    "    if test_data['document'].nunique() < len(test_data):\n",
    "        test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "        print(\"test_data['label'].nunique()\",test_data['label'].nunique())    \n",
    "        print(\"중복제거후 len(test_data)\",len(test_data))\n",
    "    \n",
    "    ## 결측치제거 : 1개라도 있으면, 해당행 전체 제거\n",
    "    #1. train_data\n",
    "    print(\"결측치 개수\",train_data.isnull().sum())\n",
    "    if train_data.isnull().any().any():\n",
    "        train_data.dropna(how='any',inplace=True)\n",
    "        print(\"결측치제거후 결측치 여부\",train_data.isnull().any().any())    \n",
    "    #2. test_data\n",
    "    print(\"결측치 개수\",test_data.isnull().sum())\n",
    "    if test_data.isnull().any().any():\n",
    "        test_data.dropna(how='any',inplace=True)\n",
    "        print(\"결측치제거후 결측치 여부\",test_data.isnull().any().any())\n",
    "    \n",
    "    ## 데이터 정제 \n",
    "    # 한글과 숫자,공백(한개이상 공백은 한개로 축소),특수문자일부 !?,.^을 제외하고 제거:[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\n",
    "    # --> 한글형태소기를 tokenizer로 쓸 경우에는 영어및 일부선택된 특수문자외에는 모두제거(..., - - 등도 제거)\n",
    "    #1. train_data\n",
    "    train_data['document'] = train_data['document'].str.replace(\"[' ']+\",\" \")\n",
    "    train_data['document'] = train_data['document'].str.replace(\"\\.{2,30}\",\" \") \n",
    "    train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n",
    "    #train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  #한글영어병행형태소기인경우 영어포함                                                         \n",
    "    print(\"한글과 공백,기타일부 등제외후 모두제거상태_train_data.head()\",train_data.head())\n",
    "    #2. test_data\n",
    "    test_data['document' ]= test_data['document'].str.replace(\"[' ']+\",\" \")\n",
    "    test_data['document'] = test_data['document'].str.replace(\"\\.{2,30}\",\" \") \n",
    "    test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n",
    "    #test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  #한글영어병행형태소기인경우 영어포함                                                            \n",
    "    print(\"한글과 공백,기타일부 등제외후 모두제거상태_test_data.head()\",test_data.head())\n",
    "    # 데이터 정제후 빈 공백만 있는 문장의 경우 제거:  Nan 입력후 행제거\n",
    "    #1. train_data\n",
    "    train_data['document'].replace('', np.nan, inplace=True)\n",
    "    print(\"Nan 존재유뮤\",train_data.isnull().any().any() )\n",
    "    if train_data.isnull().any().any():\n",
    "        train_data.dropna(how='any',inplace=True)\n",
    "    #2. test_data   \n",
    "    test_data['document'].replace('', np.nan, inplace=True)\n",
    "    print(\"Nan 존재유뮤\",test_data.isnull().any().any() )\n",
    "    if test_data.isnull().any().any():\n",
    "        test_data.dropna(how='any',inplace=True)\n",
    "    \n",
    "    # X_train , y_train, X_test, y_test    \n",
    "    X_train = train_data['document']\n",
    "    y_train = np.array(train_data['label'].tolist())\n",
    "    X_test = test_data['document']\n",
    "    y_test = np.array(test_data['label'].tolist())\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "    \n",
    "        \n",
    "X_train, y_train, X_test, y_test = load_and_preprocess_data(train_data, test_data)\n",
    "\n",
    "# 전처리된 데이터 확인(불용어처리는 않되었슴, 형태소분석후 해야하는데, sentencepiece는 학습중에\n",
    "# --> 처리될수도 있으나, 확실치 않으니, 결과를 반드시 확인해야함, 형태소분석을 해야하는 한국어인데,\n",
    "# sentencepiece에서는 않해도 되는지 확인필요)\n",
    "print(\"X_train[:5]\",X_train[:5],\"y_train[:5]\",y_train[:5],\"X_test[:5]\",X_test[:5],\"y_test[:5]\",y_test[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f29dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape (146026,) y_train.shape (146026,) X_test.shape (49084,) y_test.shape (49084,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train.shape\",X_train.shape,\"y_train.shape\",y_train.shape,\"X_test.shape\",X_test.shape,\"y_test.shape\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be65497",
   "metadata": {},
   "source": [
    "**[체크필요]: 위에서 불용어처리는 않되었슴**\n",
    "형태소분석후 해야하는데, Sentencepiece는 학습중에 처리될수도 있으나, 확실치 않으니, 결과를 반드시 확인해야함, 형태소분석을 해야하는 한국어인데,\n",
    "Sentencepiece에서는 않해도 되는지 확인필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329be85",
   "metadata": {},
   "source": [
    "#### (2) Sentencepiece 로 1차 Tokenizing\n",
    "* **maxlen 지정전 train data 로 1차 Tokenizing 학습**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eef68793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/sp_tokenizer/data/NaverMovie_trainCorpus_temp_unigram.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/NaverMovie_trainCorpus_temp_unigram.txt --model_prefix=korean_spm_unigram --vocab_size=10000 --model_type=unigram\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/sp_tokenizer/data/NaverMovie_trainCorpus_temp_unigram.txt\n",
      "  input_format: \n",
      "  model_prefix: korean_spm_unigram\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 10000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/NaverMovie_trainCorpus_temp_unigram.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 146026 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5166028\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.95% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1594\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.9995\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 145796 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 302406 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 145796\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 322084\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 322084 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=150911 obj=14.612 num_tokens=708856 num_tokens/piece=4.69718\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=139117 obj=13.5324 num_tokens=712704 num_tokens/piece=5.12305\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=104284 obj=13.6202 num_tokens=744606 num_tokens/piece=7.14017\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=104088 obj=13.5677 num_tokens=745016 num_tokens/piece=7.15756\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=78064 obj=13.7881 num_tokens=785648 num_tokens/piece=10.0642\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=78056 obj=13.7301 num_tokens=785734 num_tokens/piece=10.0663\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=58542 obj=13.9717 num_tokens=824060 num_tokens/piece=14.0764\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=58540 obj=13.9161 num_tokens=824143 num_tokens/piece=14.0783\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=43905 obj=14.1877 num_tokens=865222 num_tokens/piece=19.7067\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=43905 obj=14.1268 num_tokens=865267 num_tokens/piece=19.7077\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=32928 obj=14.4281 num_tokens=906667 num_tokens/piece=27.5348\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=32928 obj=14.3654 num_tokens=906718 num_tokens/piece=27.5364\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=24696 obj=14.7011 num_tokens=949995 num_tokens/piece=38.4676\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=24696 obj=14.6321 num_tokens=950018 num_tokens/piece=38.4685\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=18522 obj=14.9987 num_tokens=995140 num_tokens/piece=53.7275\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=18522 obj=14.9219 num_tokens=995221 num_tokens/piece=53.7318\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=13891 obj=15.3212 num_tokens=1042501 num_tokens/piece=75.0487\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=13891 obj=15.2335 num_tokens=1042606 num_tokens/piece=75.0562\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=11000 obj=15.5872 num_tokens=1083537 num_tokens/piece=98.5034\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=11000 obj=15.5019 num_tokens=1083546 num_tokens/piece=98.5042\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: korean_spm_unigram.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: korean_spm_unigram.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 416992 Feb 18 00:55 korean_spm_bpe.model\r\n",
      "-rw-r--r-- 1 root root 409870 Feb 18 00:38 korean_spm_bpe_new.model\r\n",
      "-rw-r--r-- 1 root root 151059 Feb 18 00:38 korean_spm_bpe_new.vocab\r\n",
      "-rw-r--r-- 1 root root 188138 Feb 18 00:55 korean_spm_bpe.vocab\r\n",
      "-rw-r--r-- 1 root root 416996 Feb 18 00:58 korean_spm_unigram.model\r\n",
      "-rw-r--r-- 1 root root 188138 Feb 18 00:58 korean_spm_unigram.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "import os\n",
    "\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/NaverMovie_trainCorpus_temp_unigram.txt'\n",
    "print(temp_file)\n",
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in X_train: \n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "## SentencePieceTrainer 실행: 1차 실행 (maxlen인자 없이)\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm_unigram --vocab_size={} --model_type=unigram'.format(temp_file, vocab_size)   \n",
    ")\n",
    "#위 Train에서  --model_type = unigram이 디폴트 적용되어 있습니다. --model_type = bpe로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "075649ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput : 학습시킬 파일\\nmodel_prefix : 만들어질 모델 이름\\nvocab_size : 단어 집합의 크기\\nmodel_type : 사용할 모델 (unigram(default), bpe, char, word)\\nmax_sentence_length: 문장의 최대 길이\\npad_id, pad_piece: pad token id, 값\\nunk_id, unk_piece: unknown token id, 값\\nbos_id, bos_piece: begin of sentence token id, 값\\neos_id, eos_piece: end of sequence token id, 값\\nuser_defined_symbols: 사용자 정의 토큰\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "input : 학습시킬 파일\n",
    "model_prefix : 만들어질 모델 이름\n",
    "vocab_size : 단어 집합의 크기\n",
    "model_type : 사용할 모델 (unigram(default), bpe, char, word)\n",
    "max_sentence_length: 문장의 최대 길이\n",
    "pad_id, pad_piece: pad token id, 값\n",
    "unk_id, unk_piece: unknown token id, 값\n",
    "bos_id, bos_piece: begin of sentence token id, 값\n",
    "eos_id, eos_piece: end of sequence token id, 값\n",
    "user_defined_symbols: 사용자 정의 토큰\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b924b43b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1184, 9, 486, 13, 1277, 9, 150, 16, 4]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm_unigram.model')\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoding\n",
    "tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "print(tokensIDs)\n",
    "\n",
    "# SentencePiece를 활용한 sentence -> encoded pieces\n",
    "print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "# SentencePiece를 활용한 encoding -> sentence 복원\n",
    "print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed6efa6",
   "metadata": {},
   "source": [
    "* **sp_tokenize_noPadding 함수 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ac9a7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize_noPadding(s, corpus):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./korean_spm_unigram.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "561a4118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[488, 3072, 12, 1028, 2471, 4], [1199, 2168, 184, 601, 9, 3, 14, 9937, 1070, 4, 4, 4]]\n"
     ]
    }
   ],
   "source": [
    "#sp_tokenize(s, corpus) 사용예제\n",
    "\n",
    "my_corpus = ['나는 밥을 먹었습니다.', '그러나 여전히 ㅠㅠ 배가 고픕니다...']\n",
    "tensor, word_index, index_word = sp_tokenize_noPadding(s, my_corpus)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d7ce14",
   "metadata": {},
   "source": [
    "* **1차 학습된 spm으로 sp_tokenize함수를 통해 X_train,  X_test 각각 토크나이징**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f40421d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor[:10] [[54, 915, 27, 1869, 62, 1593], [1444, 951, 153, 1370, 31, 322, 2549, 419, 1172, 7391, 725, 421], [19, 396, 9797, 403, 6390, 135, 6284, 1789, 306], [2100, 8, 233, 217, 7073, 288, 1084, 106, 71, 7901], [2036, 5779, 2161, 198, 7, 3, 1519, 328, 2117, 433, 3712, 1788, 6, 22, 73, 442, 5, 254, 1010, 53, 6356, 2047, 1119, 2358, 2746, 6460, 3, 144, 770, 9, 1939, 3, 3736, 135, 652], [642, 540, 81, 169, 3, 0, 126, 174, 281, 5449, 47, 4016, 384, 38, 476, 328, 215, 31, 4, 279, 6245, 8, 1392, 4], [3511, 6528, 473, 3385, 226, 18, 527, 195, 4], [221, 3635, 218, 7208, 24, 2403, 391, 976, 215, 132, 72, 4092, 5, 4790, 170, 305, 23, 3067, 684, 2731, 853, 2488, 4064, 7939, 4, 282, 758, 25, 491, 1257, 491, 1257, 4868, 10, 927, 8, 520, 72, 4784, 716, 25, 304, 3061, 43], [1960, 3344, 8, 185, 108, 9392, 6], [3189, 152, 1526, 1238, 17, 903, 8101, 2625, 289, 8841, 5570, 19, 976, 57, 127, 603, 2675, 17]]\n",
      "X_test_tensor[:10] [[2465, 219], [1124, 24, 71, 417, 8261, 3077, 66, 36, 6811, 10, 7707, 6436], [1833, 10, 5821, 99, 501, 114, 1466, 4466], [126, 25, 230, 3521, 8, 221, 4905, 121, 4004, 1943, 44, 126, 26, 1133, 312, 651, 1011, 2578, 86, 3, 7669, 192], [2279, 213, 9, 654, 11, 102, 509, 31], [1024, 90], [1852, 629, 2019, 53, 8531, 2209, 1061, 1683, 7, 690, 267, 3111, 331, 63, 38, 5747, 11, 14, 172, 20, 7174, 29, 306], [875, 3266, 487, 9, 10, 7250, 1791, 292, 1188, 6852, 857, 16, 7551, 3634, 7267, 13, 1468, 245, 232, 54, 4436, 658, 87, 40, 1865, 225, 96, 93, 126, 352, 56, 352, 311, 88], [6189, 7, 2745, 6807, 994, 2011, 1222, 7335, 7, 228, 9986, 3, 11, 402, 679, 3812, 10, 725, 43], [6804, 173, 2090, 25, 595, 6342, 5779, 2382, 896, 9570, 242]]\n"
     ]
    }
   ],
   "source": [
    "# X_train, y_train, X_test, y_test\n",
    "\n",
    "# Tokenizing: X_train \n",
    "X_train_tensor, X_train_word_index, X_train_index_word = sp_tokenize_noPadding(s, X_train)\n",
    "print(\"X_train_tensor[:10]\",X_train_tensor[:10])\n",
    "\n",
    "# Tokenizing: X_test \n",
    "X_test_tensor, X_test_word_index, X_test_index_word = sp_tokenize_noPadding(s, X_test)\n",
    "print(\"X_test_tensor[:10]\",X_test_tensor[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe1f555",
   "metadata": {},
   "source": [
    "#### (3) 적절한 최대 문장 길이 지정: (평균 + 표준편차*2)이내: maxlen 42 개**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9076fff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이평균: 15.63\n",
      "문장길이표준편차: 13.67\n",
      "문장길이Max: 115\n",
      "문장길이Min: 0\n",
      "문장길이 0개수: 308\n",
      "['sans-serif']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEFCAYAAADACsF7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUbUlEQVR4nO3df5BdZX3H8fe3AYMCDiREUdsQSsGxRFtlEYvKFAaoiEM004kIgjOKQX6p0M4Axd8wiigWlSrGH6gQ6OAvoEZtqI2gVJkGpWPFX2kNQkecJVulSSCQ8O0f51lys+zd7I/n7t2zvF8zd3LP95577vNkb/aT85xznhOZiSRJtfxBvxsgSZpdDBZJUlUGiySpKoNFklSVwSJJqspgkSRVtUu/GzAd9tlnn1y0aFG/myFJrXLnnXc+kJkLJvq+J0WwLFq0iLVr1/a7GZLUKhFxz2Te51CYJKkqg0WSVJXBIkmqymCRJFVlsEiSqjJYJElVGSySpKoMFklSVU+KCyT7adEFqyb93vWXHl+xJZI0PdxjkSRVZbBIkqoyWCRJVRkskqSqDBZJUlUGiySpKoNFklSVwSJJqspgkSRV1bMr7yPiAOCisrgNeDdwJPDasvz9zLysrHtyjbokqf96EiwREcClwOmZOVRqewKnAMdlZkbENRFxIHB/jXpm/rIXfZEkTUyv9lgOBe4F3l8CZU1ZviUzs6xzE80ezD2V6gaLJM0AvQqWRcBi4ITMfDgiPgk8B/h1xzpDwIHAxvJ8qvUdRMRyYDnAwoULp9YbSdK49erg/WaavYqHy/LNwMPA3h3rzAM2lEeN+g4yc0VmDmTmwIIFC6bWG0nSuPUqWO4EXtyxfBjNUNXR5fgLwAnAbcAdleqSpBmgJ0NhmfmbiFgdEdcDm4D1mfnViJgLXB8RW4G7MvNnABFxTY26JKn/Yvsx8NlrYGAg165d25fP9kZfktoqIu7MzIGJvs8LJCVJVRkskqSqDBZJUlUGiySpKoNFklSVwSJJqspgkSRVZbBIkqoyWCRJVRkskqSqDBZJUlUGiySpKoNFklSVwSJJqspgkSRVZbBIkqoyWCRJVRkskqSqDBZJUlUGiySpKoNFklSVwSJJqspgkSRVZbBIkqrapRcbjYgfAXeUxa3AOZmZEXE0cC6wCbgvM88r61epS5L6r1d7LBsy8y3lcXYJlQAuBJZm5jJgc0QcU6veo35IkiaoV8EyJyI+EBErI+LVpXYQcHdmbinLNwJHVqxLkmaAngyFZeaRABGxK/CliPgJMB8Y6lhtqNRq1XcQEcuB5QALFy6cWockSePW04P3mfkocAtwMLAB2Lvj5XmlVqs+8rNXZOZAZg4sWLBg6p2RJI3LdJwV9hfAXcA6YHFEzC31JcCtFeuSpBmgV2eFfQF4CNgDuDEz15f6xcDKiNgIDAKry4H9Kdd70Q9J0sT16hjLG7rU1wBrelWXJPWfF0hKkqoyWCRJVRkskqSqDBZJUlUGiySpKoNFklSVwSJJqspgkSRVZbBIkqoyWCRJVRkskqSqDBZJUlUGiySpKoNFklSVwSJJqspgkSRVZbBIkqoyWCRJVRkskqSqDBZJUlUGiySpKoNFklTVLv1ugLpbdMGqSb93/aXHV2yJJI2feyySpKoMFklSVeMOlog4aiIbjohdIuK6iPhUWT46IlZFxA0R8ZGO9arUJUkzw06DJSJOK0/fMcFtvwP4PDAnIgK4EFiamcuAzRFxTK36BNslSeqhMYMlIg4ADh5eHO9GI+IkYC3wi1I6CLg7M7eU5RuBIyvWJUkzRNdgKXsHlwAfLKUczwYj4oXAvpn59Y7yfGCoY3mo1GrVR2vH8ohYGxFrBwcHx9N0SVIFo55uXI6nnAp8LjPv316OV5bnj2Xmt7ps80Rgr4i4CtgTeBHwY2DvjnXmARvKo0b9CTJzBbACYGBgYFyhKEmaum7XsTwf2A/4nxH1fWmGxLZ122Bmnj/8PCIW0RxruRK4JSLmlmGsJcCtwDpgcYW6JGmGGDVYMvOjEbESuC4iTs7Mwaacn5vg9rcBWzNzW0RcDKyMiI3AILA6M7NGfTIdlyT1Rtcr7zPzgYg4B/gAcFq39caSmfcCbynP1wBrRlmnSl2SNDOMeVZYZv4c+GlZHPdZYZKkJ6+dXseSmZeXp5ePuaIkSXQ/K+ylwJwR5Qcj4ojyfFtm3t7TlkmSWqnbMZbn0QRL0gyBnQt8hO3DYVsBg0WS9ATdgmU9OwbLllLrDBZJkp6gW7Dsy/bjL0Gzt/KsjtcNFknSqLpdx3JtRBxHEy4/yMxRr26XJGmksc4KuwzYB/hgRFwZEU+fpjZJklpsrGB5IDO/kJmnAf8AXBsRfzRN7ZIktdRYwfL4xI2Z+VPgTcDHI2K3nrdKktRaYwXL0s6FMl/YRcDuPW2RJKnVxpor7Hej1H7S09ZIklpv3Pe8lyRpPAwWSVJVBoskqapuk1DeUF4L4JnA47cnLn9uycwTe9+8mWHRBav63QRJao1uV94vG34eEWsyc+lo60mSNNJ4hsJuA4jG63rcHklSy3UNloj4WHl6DzQ3vAdOnY5GSZLaa6w9lsXlz2URMXxsxavuJUljGs9QWLL9WMzIu0pKkrSDrlfeA8+OiLcC+wFnRUQCz5ieZkmS2mqsYHktsBdwRkfthJ62RpLUemPNFfYf09kQSdLs0O0CyZMZ+3jKtsxcOdaGI+ITwK40syH/IjPfExFHA+cCm4D7MvO8sm6VuiSp/7odvP/9OB5jyswzM/PNmXkSsH9EPBe4EFhaLsDcHBHHlDPOplyf/F+BJKmmblfef334eUQ8pdQemcwHRMTewAKa4zV3Z+aW8tKNNPd8+XWl+i2TaZ8kqa6ux1gi4gDgY8DDzWLsCrwtM/97PBuOiD8B3gscTjNsNQcY6lhlCJhfHjXqIz9/ObAcYOHCheNpsiSpgrHOCrsaOCUz7wGIiP2BLwBHjGfDmbkOODkidgGuB64E9u5YZR6woTxq1Ed+/gpgBcDAwECOfF2S1BtjXSA5dzhUADLzV8DciX5AZm6l2VtZDyyOiOFtLAFuBdZVqkuSZoCx9lj+swwnraSZLv8UYFy3Jo6IFwHnARuBpwNfycx7IuJiYGVEbAQGgdWZmTXqk+i7JKkHxgqW04HTgE/TTOtyG+WYxc5k5g+B149SXwOs6VVdktR/Y10guRW4qjwkSRqXbhdIvp6xj7/s9AJJSdKTU7c9lvvZSbD0oC2SpFmgW7Aso5mOBZrjKzHi9UeAb/eqUZKk9uoWLGfThEkA3wKOBZ4K7Etz2rDXhUiSRjXqcFeZvuXUzHy4WcxHaO4e+XeZuWWy07tIkma/sY6jvK78eS5AZv6W5qZfkiR1tdNbE2fmXR2LE77yXpL05DLWBZJ/GBHv6lgOxhFEkqQnt7GC5a9opmPp9LEetkWSNAuMdeX9r6azIZKk2cGhLUlSVQaLJKkqg0WSVJXBIkmqymCRJFVlsEiSqjJYJElVGSySpKoMFklSVQaLJKkqg0WSVJXBIkmqymCRJFU11rT5UxIRnwQeA+YBqzLz2og4muaOlJuA+zLzvLJulbokqf96tseSmWdk5lnAScDpERHAhcDSzFwGbI6IY2rVe9UPSdLETMdQ2FxgCDgIuDszt5T6jcCRFeuSpBlgOoLlEuAyYD5NwAwbKrVa9R1ExPKIWBsRawcHByt0Q5I0Hj0Nlog4F/hRZt4ObAD27nh5XqnVqu8gM1dk5kBmDixYsKBCbyRJ49HLg/dnApsyc2UprQMWR8TcMoy1BLi1Yl0dFl2watLvXX/p8RVbIunJpifBEhGHAxcA34iIq0r5ncDFwMqI2AgMAqszMyNiyvVe9EOSNHE9CZbM/Ddg4SgvrSmPketXqUuS+s8LJCVJVRkskqSqDBZJUlUGiySpKoNFklSVwSJJqspgkSRVZbBIkqoyWCRJVRkskqSqDBZJUlUGiySpKoNFklSVwSJJqspgkSRVZbBIkqoyWCRJVRkskqSqDBZJUlUGiySpKoNFklSVwSJJqspgkSRVtUu/G6CZZ9EFq6b0/vWXHl+pJZLayD0WSVJVPdtjiYg5wPuAQzLzFaV2NHAusAm4LzPPq1mXJPVfL/dYXgXcTAmviAjgQmBpZi4DNkfEMbXqPeyHJGkCehYsmXlTZt7RUToIuDszt5TlG4EjK9YlSTPAdB5jmQ8MdSwPlVqt+g4iYnlErI2ItYODg1U6IEnauekMlg3A3h3L80qtVn0HmbkiMwcyc2DBggVVOiBJ2rnpDJZ1wOKImFuWlwC3VqxLkmaA6biO5VGAzNwWERcDKyNiIzAIrM7MrFGfhn5Iksah58GSmcd1PF8DrBllnSp1SVL/eYGkJKkqg0WSVJXBIkmqymCRJFVlsEiSqjJYJElVeT8WVTeV+7l4Lxep/dxjkSRVZbBIkqoyWCRJVRkskqSqDBZJUlUGiySpKk831oziqcpS+7nHIkmqymCRJFVlsEiSqvIYi8TUju2Ax3ekTgaLZo2phkO/PttQ0mzjUJgkqSr3WKQ+c29Hs417LJKkqgwWSVJVDoVJLeYwmmai1gZLRJwMvBbYBnw/My/rc5OkVjGU1CutHAqLiD2BU4Almfka4PkRcWCfmyVJor17LIcDt2RmluWbgCOBX/avSdKThxeUaixtDZb5wFDH8hCwwx5LRCwHlpfFjRHx8yl83j7AA1N4/0wz2/oD9qkt9gEeiA/2uxlVzdqfE7DfZN7c1mDZABzcsTyv1B6XmSuAFTU+LCLWZuZAjW3NBLOtP2Cf2sI+tcNU+9TKYyzAHcDRERFl+QTgtj62R5JUtHKPJTN/FxHXANdHxFbgrsz8Wb/bJUlqabAAZOb1wPXT9HFVhtRmkNnWH7BPbWGf2mFKfYrtJ1ZJkjR1bT3GIkmaoQwWSVJVrT3GMh1my7QxEfFJ4DGa07JXZea1EXE0cC6wCbgvM8/rZxsnIyJ2Ab4I/F9mnt72PkXEAcBFZXEb8G6aC39b+x2MiHOBQ4BHgDnAGTQXOLfq5xQRc4D3AYdk5itKbdTvWxu+h136cwnN74jdgR9n5odL/c+A9wMbgc3A8sx8dMwPyEwfozyAPYFvsf041DXAgf1u1xT7FMB3y5/fBuaW+iXAMf1u3yT68x7gWOAzbe9Taf+XgHkdtVZ/B4G9aP4jM7x8PrCkjT+n0u7DgH/p+Hk9oR9t+R6O7M8or/8zsHt5vmr4ewmcBrx5Z9t3KKy7btPGtNlcmlkKDgLuzswtpX4jLetbRJwErAV+UUpt79OhwL3A+yNiZUScRvu/g78HfhMRz4qIp9JcxX0/Lfw5ZeZNmXlHR6nb960V38NR+vO4cn3gY8BDEbEbsDUzh2c6uZFx9MehsO52Om1MC10CXMbofZvflxZNQkS8ENg3M6+LiEWl3Oo+AYuAxcAJmflwGb58DvDrjnVa9R3MzIyIq4EzaWbGuJ1mOKzNP6dh3b5vbf8eArwNuDozH4uIecDvOl4bohkuG5PB0t1Op41pkzLW/aPMvD0ingvs3fFy2/p2IrBXRFxFM1z0IuDHtLtPm2n2Th4uyzcDL6DFfYqIFwCvyswLy/JS4Pm0uE8dNjB6P7rVWyEilgFPycwbSmm0/gw94Y0jOBTW3ayZNiYizgQ2ZebKUloHLI6IuWV5CXBrXxo3CZl5fmaenplvoTnYfTtwJS3uE3An8OKO5cNoZutu83fwWTTHHIY9RNkza/HPaVi3f0Ot/bcVEUuAP82OE0TKkN6uETEcLuPqj3ssXeQsmTYmIg4HLgC+Uf6HD/BO4GJgZURsBAaB1X1q4lRtoxkD3hYRre1TZv4mIlZHxPU0ZxOtz8yvll9Qbf0OrgaOiIgvAluApwFvpdkTa+XPCXgUoNv3rQz/tel7+ChAROxHc7X91zp+T1xRvm/nA5+OiAeBrcA5O9uoV95LkqpyKEySVJXBIkmqymCRJFVlsEiSqjJYJElVGSxSh4g4ICK+Ux6f6qh/qdL2Xx4ROz9dc4KfFxHnRMTLd7LO0yPisxPZrjQZXsciFRFxFHAU8L2O2iXA1cCuI9a9nXINQIdFwOLM3BgR84Evs/0Cwb0y889ppjSZ07Gdb9Bc3zHsqsz8x5Gf17H+24FXl8U9gZsz872jbPftwOvL5783M2+m+Y/kHKQeM1ik7b4H/JDmCvhDgG8C64EHR1n3fzPzVZ2FiPg8sBuwMTM3UCbrK3sSR3T5zEcy85Wj1P8gIvYAHsrMbcPFzLwCuKJs90SaiUV3EBHPAw7LzIEyieA3I6IVV39rdnAoTCoy8xGaAHgpzSyufwPskZmPAS8rw2MHldU3dgyZfScivgPsz4gQioiDaaa777z6+uyyp/IEETGnzAQ8n2aK8j/ust4C4A00e0UjHQFcV/r0MM2syC/ZSfelatxjkXb0GuCMMsPwSuA44NPA9zLz1cMrZeaJY22k3EjpdJoJMl8CXBYR62jm+rqy7HkAbI2I1TRTZWyjmYzySmCwY52R2z4GeDtwdmZuKuUHaebieny1Ls+lnjNYpB39BHhTmd/qdTS/5B8XEYcCHwKeSvOLfHfgGcCvOlb7DM3cWPdl5idK7dQyH9NjNOEBQGb+9WiNiIh9u9Q/DLwQ+C/gnO3zU/IozZ4JNDdzexdwcxkKOwH4LI5QaJoYLNKOPkrzi/kVwA2Z+e+lngBl+S8j4muZ+ZqIWAycmJnvGG1jEXEq8EaaQNmF5uZkF4xY50DgcpqQCprgOX+07WXm35ZbMu824qW30tzP5dbMvDsifhARa8v23p2ZD0bEXhP4e5AmzWCROmTmoxFxf+ewV/GGEcvDuwpb6dgD2WGFiGcDS4GjynEaIuKNwFnA33es+iHgrMy8t6yzL81xmWO6NPNYmhmqt3TUnkZza+PhflxBOcgvTTeDRXqiZ5aD8Z0yIk7MzN+W5f0714mIY8vTyzPzn8rzjTT3fT+oHF/Zh2YY67sjtj0EvDgiNtDsGR3KjnftG+lA4KLM/NeJdIpmr2nrBN8jTZjT5ks9VO6ieAbNGWNDwJcz86sj1tmDZijrMJrjIHcAH8/M33fZ5suA9/HEYyYfz8yv1O2BNHEGiySpKs8SkSRVZbBIkqoyWCRJVRkskqSqDBZJUlX/D9iCXvO2XV1yAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 42\n"
     ]
    }
   ],
   "source": [
    "## 데이터셋 내 문장 길이 분포\n",
    "total_data_text = list(X_train_tensor) + list(X_test_tensor)\n",
    "total_data_text_dist = [len(x) for x in total_data_text]\n",
    "#print(total_data_text_dist)\n",
    "\n",
    "mean = round(np.mean(total_data_text_dist),2)\n",
    "std = round(np.std(total_data_text_dist),2)\n",
    "max = np.max(total_data_text_dist)\n",
    "min = np.min(total_data_text_dist)\n",
    "min_count = len([x for x in total_data_text_dist if x == 0])\n",
    "print(\"문장길이평균:\",mean)\n",
    "print(\"문장길이표준편차:\",std)\n",
    "print(\"문장길이Max:\",max)\n",
    "print(\"문장길이Min:\",min)\n",
    "print(\"문장길이 0개수:\", min_count)\n",
    "\n",
    "# 히스토그램 시각화: total_data\n",
    "print(plt.rcParams['font.family'])\n",
    "plt.rc('font',family='NanumGothic')\n",
    "plt.hist(total_data_text_dist, bins = 20)\n",
    "plt.xlabel('한문장당 길이')\n",
    "plt.ylabel('데이터 개수')\n",
    "plt.show()\n",
    "\n",
    "# 박스플롯: total_data\n",
    "plt.boxplot(total_data_text_dist)\n",
    "plt.show()\n",
    "\n",
    "## 적절한 최대 문장 길이 지정: (평균 + 표준편차*2)\n",
    "maxlen = int(mean + 2*std)\n",
    "print(\"maxlen\", maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16d6aa",
   "metadata": {},
   "source": [
    "#### (4) Sentencepiece 로  최종 Tokenizing\n",
    "* **maxlen 지정후 train data 로 최종 Tokenizing 학습** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "086a124e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/aiffel/aiffel/sp_tokenizer/data/NaverMovie_trainCorpus_temp_unigram_new.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/NaverMovie_trainCorpus_temp_unigram_new.txt --model_prefix=korean_spm_unigram_new --vocab_size=10000 --max_sentence_length=42 --model_type=unigram\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/sp_tokenizer/data/NaverMovie_trainCorpus_temp_unigram_new.txt\n",
      "  input_format: \n",
      "  model_prefix: korean_spm_unigram_new\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 10000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 42\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/NaverMovie_trainCorpus_temp_unigram_new.txt\n",
      "trainer_interface.cc(356) LOG(WARNING) Found too long line (44 > 42).\n",
      "trainer_interface.cc(358) LOG(WARNING) Too long lines are skipped in the training.\n",
      "trainer_interface.cc(359) LOG(WARNING) The maximum length can be changed with --max_sentence_length=<size> flag.\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 41199 sentences\n",
      "trainer_interface.cc(391) LOG(INFO) Skipped 104827 too long sentences.\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=492239\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.95% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1687\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.9995\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 40969 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 43731 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 40969\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 45504\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 45504 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=24575 obj=14.136 num_tokens=100162 num_tokens/piece=4.07577\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=23113 obj=13.2108 num_tokens=100525 num_tokens/piece=4.34928\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=17332 obj=13.4908 num_tokens=106552 num_tokens/piece=6.1477\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=17316 obj=13.4071 num_tokens=106606 num_tokens/piece=6.1565\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=12986 obj=13.8368 num_tokens=114569 num_tokens/piece=8.8225\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=12986 obj=13.7197 num_tokens=114609 num_tokens/piece=8.82558\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=11000 obj=13.9628 num_tokens=118891 num_tokens/piece=10.8083\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=11000 obj=13.9052 num_tokens=118907 num_tokens/piece=10.8097\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: korean_spm_unigram_new.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: korean_spm_unigram_new.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 416992 Feb 18 00:55 korean_spm_bpe.model\r\n",
      "-rw-r--r-- 1 root root 409870 Feb 18 00:38 korean_spm_bpe_new.model\r\n",
      "-rw-r--r-- 1 root root 151059 Feb 18 00:38 korean_spm_bpe_new.vocab\r\n",
      "-rw-r--r-- 1 root root 188138 Feb 18 00:55 korean_spm_bpe.vocab\r\n",
      "-rw-r--r-- 1 root root 416996 Feb 18 00:58 korean_spm_unigram.model\r\n",
      "-rw-r--r-- 1 root root 420291 Feb 18 01:00 korean_spm_unigram_new.model\r\n",
      "-rw-r--r-- 1 root root 191454 Feb 18 01:00 korean_spm_unigram_new.vocab\r\n",
      "-rw-r--r-- 1 root root 188138 Feb 18 00:58 korean_spm_unigram.vocab\r\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "temp_file = os.getenv('HOME')+'/aiffel/sp_tokenizer/data/NaverMovie_trainCorpus_temp_unigram_new.txt'\n",
    "print(temp_file)\n",
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in X_train: \n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "## SentencePieceTrainer 실행: 1차 실행 (maxlen인자 없이)\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=korean_spm_unigram_new --vocab_size={} --max_sentence_length={} --model_type=unigram'.format(\n",
    "        temp_file, vocab_size, maxlen)   \n",
    ")\n",
    "#위 Train에서  --model_type = unigram이 디폴트 적용되어 있습니다. --model_type = bpe로 옵션을 주어 변경할 수 있습니다.\n",
    "\n",
    "!ls -l korean_spm*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35be82",
   "metadata": {},
   "source": [
    "* **sp_tokenize_withPadding 함수 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a177aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize_withPadding(s, corpus, maxlen):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(\"./korean_spm_unigram_new.vocab\", 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,maxlen= maxlen, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e53fc3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 새롭게 학습한 모델로 s객체 변경:및 new 모델로드  SentencePieceProcessor()\n",
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('korean_spm_unigram_new.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8f14e",
   "metadata": {},
   "source": [
    "* **최종 학습된 spm으로 sp_tokenize함수를 통해 X_train,  X_test 각각 토크나이징**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64e45972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor[:10] [[  26  869   15 1294   96 2046    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 379  623  307  998   27  484 3198  579 1595  188 9971   22  941  311\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  12  756 9544  424 2359   64 1221  438   18 1376  313    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [5420   16  297  206 2275  205  570   62   48 2902    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [3218 5576 3026  371    8    3 1886  811  106  782  486 6606 4101    5\n",
      "     6  106  602    7  292 1514  128    3 9958   55  212    7  986 4551\n",
      "  1985 4003    3  279  807   11 1619 2204  212  783    0    0    0    0]\n",
      " [1055 1004   65  190    3    0  110  237  452  728  675 5582   28 1489\n",
      "   315  712   81  485  811  150   27    4  117 5174  509    4    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 392    8  642   18  878 1039  368  335   22 4864    4    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  32 2180  695 1321  150  170  107 6090    7 4825  315  674   14 2284\n",
      "  1653 1882  957 2210 2927    3 6670  175    4  303  849   30  775 2339\n",
      "   775 2339 5452   13  966   16  498  107  826  191 5681  478 1975   41]\n",
      " [1385    3 4584   16   66  322  810 2420   13    5    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [2150  105 2338 2157    9  416 2674 4350  369 8151   20   30   12 1321\n",
      "   100   92  519 3276    9    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "X_test_tensor[:10] [[ 549   79    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 274   32   48 1110 6675  941  136   31   19 4772   13   90 8929 1800\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [3102   13    3 4750   46  601   98 1397 4525    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [ 110   30  398 1469   16  133 4942   95    3 1428   18 3150   34  110\n",
      "    44 1420  461  967 1836 1426  217  122  231  101    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [2065  381   11  888   25   39  481   27    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [1065   50    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   3 6412  906 1629  128 6143   55 4867  173   23    3 1427    8 1149\n",
      "   418 4389  235   45   81  452   11   25   24  183   42    3 4303   36\n",
      "   313    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [1072 3567  475 1834 4655 1448  291  940    3 9904 5467  500  477 3931\n",
      "   284 1483 1225  477  417   26 2037 1406  157   64 2998  245  167   52\n",
      "   110  302   51  302  447   80    0    0    0    0    0    0    0    0]\n",
      " [  32 2979    8 3490 3349   20 1636  152   13 1433 1061  468    8  258\n",
      "  9537  238  931 2700 6454   13 5451    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [1532 2440 1079 9489 5576 3188  234 9999  286    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "# X_train, y_train, X_test, y_test\n",
    "\n",
    "# Tokenizing: X_train \n",
    "X_train_tensor, X_train_word_index, X_train_index_word = sp_tokenize_withPadding(s, X_train, maxlen)\n",
    "print(\"X_train_tensor[:10]\",X_train_tensor[:10])\n",
    "\n",
    "# Tokenizing: X_test \n",
    "X_test_tensor, X_test_word_index, X_test_index_word = sp_tokenize_withPadding(s, X_test, maxlen)\n",
    "print(\"X_test_tensor[:10]\",X_test_tensor[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b5010",
   "metadata": {},
   "source": [
    "* **토크나이징 최종완료후 데이터 shape 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c64b61cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor.shape (146026, 42) y_train.shape (146026,) X_test_tensor.shape (49084, 42) y_test.shape (49084,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train_tensor.shape\",X_train_tensor.shape,\"y_train.shape\",y_train.shape,\"X_test_tensor.shape\",X_test_tensor.shape,\"y_test.shape\",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b455f0c",
   "metadata": {},
   "source": [
    "#### (5) 모델 구성 및 validation set 구성¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5e2d9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper param 설정\n",
    "vocab_size = len(X_train_word_index)   # 어휘 사전의 크기(8000 )#10,000개의 단어)\n",
    "\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수\n",
    "hidden_unit = 16\n",
    "drop_rate = 0.2\n",
    "epochs= 20 \n",
    "\n",
    "#cnn_dense_hidden_unit = 8\n",
    "#cnn_filter = 7\n",
    "#cnn_maxpool = 4\n",
    "epochs= 20 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5528d2d4",
   "metadata": {},
   "source": [
    "* **LSTM 모델**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eef3353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 162,401\n",
      "Trainable params: 162,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## LSTM 모델\n",
    "\n",
    "model_lstm = tf.keras.Sequential()\n",
    "model_lstm.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model_lstm.add(tf.keras.layers.LSTM(hidden_unit)) \n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model_lstm.add(tf.keras.layers.Dense(hidden_unit, activation='relu'))\n",
    "model_lstm.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38934d1",
   "metadata": {},
   "source": [
    "* **valid data 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2b39eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_tensor 총개수: 146026 80%분리:  116820 20%분리: 29206\n",
      "partial_X_train 116820 partial_y_train 116820\n",
      "X_val_tensor 29206 y_val 29206\n"
     ]
    }
   ],
   "source": [
    "## 총 train data : 80:20 \n",
    "print(\"X_train_tensor 총개수:\", len(X_train_tensor), \"80%분리: \",int(len(X_train_tensor)*0.8), \"20%분리:\",len(X_train_tensor)-int(len(X_train_tensor)*0.8))\n",
    "train_len = int(len(X_train_tensor)*0.8)\n",
    "valid_len = len(X_train_tensor)-int(len(X_train_tensor)*0.8)\n",
    "\n",
    "# validation set 20% 분리: \n",
    "X_val_tensor = X_train_tensor[:valid_len]   \n",
    "y_val = y_train[:valid_len]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_X_train = X_train_tensor[valid_len:]  \n",
    "partial_y_train = y_train[valid_len:]\n",
    "\n",
    "print(\"partial_X_train\",len(partial_X_train),\"partial_y_train\",len(partial_y_train))\n",
    "print(\"X_val_tensor\",len(X_val_tensor), \"y_val\",len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ecc52a",
   "metadata": {},
   "source": [
    "#### (6) LSTM모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dbb1277c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "229/229 [==============================] - 5s 8ms/step - loss: 0.6091 - accuracy: 0.6209 - val_loss: 0.3943 - val_accuracy: 0.8252\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3673 - accuracy: 0.8420 - val_loss: 0.3494 - val_accuracy: 0.8465\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3290 - accuracy: 0.8602 - val_loss: 0.3387 - val_accuracy: 0.8506\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3133 - accuracy: 0.8666 - val_loss: 0.3383 - val_accuracy: 0.8511\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3033 - accuracy: 0.8700 - val_loss: 0.3503 - val_accuracy: 0.8434\n",
      "Epoch 6/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2933 - accuracy: 0.8743 - val_loss: 0.3511 - val_accuracy: 0.8494\n",
      "Epoch 7/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2850 - accuracy: 0.8768 - val_loss: 0.3467 - val_accuracy: 0.8516\n",
      "Epoch 8/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2777 - accuracy: 0.8794 - val_loss: 0.3481 - val_accuracy: 0.8500\n",
      "Epoch 9/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2726 - accuracy: 0.8804 - val_loss: 0.3604 - val_accuracy: 0.8490\n",
      "Epoch 10/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2657 - accuracy: 0.8826 - val_loss: 0.3569 - val_accuracy: 0.8471\n",
      "Epoch 11/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2629 - accuracy: 0.8823 - val_loss: 0.3733 - val_accuracy: 0.8485\n",
      "Epoch 12/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2579 - accuracy: 0.8851 - val_loss: 0.3724 - val_accuracy: 0.8489\n",
      "Epoch 13/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2545 - accuracy: 0.8865 - val_loss: 0.3832 - val_accuracy: 0.8480\n",
      "Epoch 14/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2493 - accuracy: 0.8875 - val_loss: 0.3775 - val_accuracy: 0.8480\n",
      "Epoch 15/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2455 - accuracy: 0.8901 - val_loss: 0.3931 - val_accuracy: 0.8491\n",
      "Epoch 16/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2406 - accuracy: 0.8922 - val_loss: 0.3868 - val_accuracy: 0.8474\n",
      "Epoch 17/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2349 - accuracy: 0.8947 - val_loss: 0.3839 - val_accuracy: 0.8476\n",
      "Epoch 18/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2307 - accuracy: 0.8975 - val_loss: 0.3874 - val_accuracy: 0.8416\n",
      "Epoch 19/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2240 - accuracy: 0.9005 - val_loss: 0.3875 - val_accuracy: 0.8452\n",
      "Epoch 20/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2194 - accuracy: 0.9032 - val_loss: 0.4111 - val_accuracy: 0.8476\n"
     ]
    }
   ],
   "source": [
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])              \n",
    "  \n",
    "history_lstm = model_lstm.fit(partial_X_train, partial_y_train, epochs=epochs, batch_size=512, validation_data=(X_val_tensor, y_val), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965571d",
   "metadata": {},
   "source": [
    "* **SentencePiece의 경우 LSTM Loss, Accuracy 시각화**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f3c604b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcIAAAEYCAYAAADPvfYMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABDUElEQVR4nO3deXxU1fn48c9DCER2DCAiElCDtXWFVKvigoJK646gQilVlrqC4IZ1+UEJKqBVq0VEW1Hgi7jiWhUEERFQaBEVEVAQKGghirJDkuf3x7mT3CSTmUkyk9me9+t1X5m7n7mTO8+cc88iqooxxhiTrurEOwHGGGNMPFkgNMYYk9YsEBpjjElrFgiNMcakNQuExhhj0poFQmOMMWnNAmGMiEgjEXkkwm3HikiLWKepOkTkKRHpEqVjfeX9zRGR/xdiu1ki0jaC4/UTkca++YkiUjcaafUd86toHi+d2T0R9FhJd0+kooQMhCKyqpLl14vIfBGZKyIficghIvJ7EXnfm/b4Xv9ZRA4Vkb0icnclx3tMRHYHWd7CO8f7IrJORFZ6r2eLSGYk70FVd6jq0Ai3vV1Vt0aybRzU9aZoqA+gqt+q6qgQ22VGeM4BQHZgRlWvUdXCmiWxgvpRPl612D2RUNL9nkg5ifpLoV75BSJyCnAJ0LXcBzvVmxCRdap6pm+f9sDHwPkiMl5V9/jWHQh0BL4vfy7vBuzqbTcSWKeqk2v6poypAbsnjImRhMwRVkKB6vyyKcJ9KfQvt3ww8GRVDyYiS0TkBu9X+AUi0kVE3vN+LS8WkT6+bQPFHiIii0Rksrfff0TkD77tZgeKPbzXd4nIhyLysYj8zbddcxF5zlv3tojcJCJvVpLO67w0zfW2P85bfqaIPCMi74jIB16aO/n2+4OILPP2eR44MMixM0XkMxGp41v2pogcEep6+LZtKyKzffO3+875FL5cWLD34Z1/FnA88JyIDPVfb+91Zy8d87xrfpOIiLfuaRH5fyKywMtFPRdJrkZE+nrbB3JY3b3ljUTkRe96zhaR84MtC3f8arB7wu6JWr8nRGSS7/xviFcUKyL1RWSMd+wPAp+TiLQRkWnesnkicrW3fGW54/o/81kiMsjbZ5CIHOktm+v93wz37XekiMz0tv1ARHp4fw/2bbNIRBoGez8AqGrCTbhfm8GWXwi8DlwcyX5Ae+B9oCHwEVDHW54JzAcyKjuX7xgjgT/65tcA1/rmGwDie70qWHqAYuA33uumwEYg05t/H2jve32791qAd4Eu3vwjgXXe/P3A+5Wku6Hv9anADO/1md65s735LsBs7/WhwFdAS2/+KGAXcGaQ408EzvZetwbmRno9Ap+L9/o3wOJAenG5jmLf9Qj6Pspft3LHbwasAjp68/WAF4G+3vxkYIJvv6eA34f6nwJOAxYATbz5g4DPgcOAC4CJ5farsMzuCbsnKrseJNc94T//nYHPHngYuCvwXr1ldYBFwFkR/G+W/8zH+NZlARm+Y67A/Q83BpYDx5Q71jXArb5r9HSo/+lkyhGiqq8BPYF2IvK6iDSNcL+dwGzclwZAL+AlVS2qRjLqAs/55lsCj4vIfOAt3I0TzHequshLz0/AOuDgSrZ9xdtOccVYh3nLT8P9gwY8FCKdnUTkeS9dDwCtfOs+UNUC7/Ui3/E7A2+q6hbv/F8Csyo5/jPAld7rPrgbCSK/HgG/AaZ5nxGqOhf4LML3UZkuwLuquso75j5gPHCxb5uZvtf+a1CZi4CHVPVn75jfA1OAHsB7wH4RuVVEmnnbB1sWdXZP2D1B7d8Tl4vIv0RkHvB73/kvAO71PqOAI4EfVHVOBGks70Xf64bAeO+cc3D/Jy289/Whqn5Wbt/pwGXe66sp+z9SQVIFQnAfoKr+DfdGb6vCro8B13uvrwL+UYM0/OibfRn4F+45zZm4X4vB7Cs3X0jl139fJdsJsD/EMd1GIq1x7y9fVU/DFXlJsP3UPVsKHL+43HbgcgoVqOpC4GgRqYcLEi94qyK9HgGVnjOC91GZynqSL/a9ruwaV/mYqrpLVW/E3bjPiMgpwZZFkO5qsXvC7okwx4Mo3RMicgnuR9PVqnoGMKHc+cunRXGlDMGUP36TcvP+/6l/4nK053jX8BvvXEGP7/2w+lJETgeOVdUFlaQhaEISlog0EJH63mvB/Wqq8FC/Mqr6P2CNiNwCfKqq26OUtFa4X1qFInIpFT/MaHoTGOKbv42y/8gBhwBrVXW5d63KPwuqzEKgu4i0BBCRPFyxUWVeA24BVqpq4Oau6vWYA1whIg28c16Iq7ARyfvYCzQPcswPvffxC++Y9XDX6uUwaQllJjA8kOPyvpD6Af8KPBdS1bW4nEvPYMtqcO6g7J4A7J6o7XviMFzuebOXvt6+dW8BY8T3nBQXvFqKyAVBjrU/8BxP3DPZX4Y576uquldETsQVUYN7XNFVRH4dZJ9JuFKbGeHeVKLWGi0Wkfd98y/jnmdMFJFduF8A84G/l9uv/K/BIspWJngQ+JTSiwjuHyeUQu84lW0/CpjvpWspsEhE6qhqcblty+/nP25lrwPzgfeQDzwoIh9Seg3+GyTN/wbWishH3rGmAIGH//7jlUmbqm4RkduAN0SkEFdU9UqQ7QOeBb4EzvIti+R6lHwuqvq5iEwC5onIPi/t87z1od4HwEvADBH5RFX7+t7HTyJyBfCouAf+GcALqhq4Icpfg2DXpPy1WeA9/H9TRPbjfo0OVdV14tpuDQd2ePsMAPoGWVYTdk+U3c7uifjcE1OAKSJynnf+N3DPPQFuB8YAC0VkL/C5ql7n5SIfEpE7vH2eUdWngJuBl0RkMy739yaVf+Z3AK+Ja9rzjbetqOp2EemJKzZtjPsRdL+qvqmqH3mf2bNB3kcZgQe4Jgl4v/73q2qx96trAvCOqr4S56QZExd2T5jKeLnfUap6ebhtEzVHaII7DnjE+7UFMNNueJPm7J4wFYjIo0Ae8Idw24LlCI0xxqS5pKksY4wxxsSCBUJjjDFpLemfEbZo0ULbt28f72SYNLR06dKtqtoy3umIFruXTLzE+15K+kDYvn17lixZEu9kmDQkIt/GOw3RZPeSiZd430tWNGqMMSatWSA0xhiT1iwQGmOMSWtJ/4wwFe3fv5+NGzeyZ8+e8BubmMvKyqJt27ZkZkY0ELsxJslYIExAGzdupHHjxrRv3x7Xr66JF1WloKCAjRs30qFDh3gnxxgTA1Y0moD27NlDdna2BcEEICJkZ2db7tyYFJaygXDaNGjfHurUcX+nTYt3iqrGgmDisM/CmOpJlu/hlAyE06bB4MHw7beg6v4OHpy4H4IxxiSryoJdMn0Pp2QgvPNO2FVuDOhdu9zyVBTNX135+fkMHDiQjh070qdPHwYOHMjy5cvD7nf33Xezdu3aStd///33DB8+vPoJ8/To0aPGxzDGREeoYJdU38OqmtRT586dtTwRVfexlJ1EKmyakFasWBHxtlOnqjZoUPZ9NmjgltdE//79dcOGDTU7SAycffbZcTlvsM8EWKK18D8O9MWNfP4KcFu5dQLcC/wTNyjvrb513XADmD4P/DXceYLdS8aEkpMT/Ls2J6dq38O1dS9VNqVkrdF27dwvk2DLU02oX119+0bnHL179yY3N5dvvvmG6dOnM3LkSH7++WcKCwu54IIL6N69OwMGDCA/P5+vvvqKCRMm0Lx5c1SVNm3aMHLkSDZs2EB+fj5PPPEEvXr14tBDD2X//v1s2rSJsWPHcsQRR7B8+XLy8/Np164de/bsYcWKFcyZMydomn7++WeGDx9ORkYGO3fupGvXrgwYMIAXXniBd955h6ZNm3LZZZfRrFkz8vPzOeiggzjhhBPo169fdC5KLfFG3e4H9FBVFZEpIpKrqqu9TboDu1X1am/7QSJyLPAZblTv36rqXhHJF5HuqjorLm/EJK1A7m79evcdOmZM6XfL+vXB9wlsmyzfwykZCMeMcdlzf4Bo0MAtTzWh/hGjZevWrQwdOpRTTz0VcH1SfvzxxzRq1IjHHnuM7t27U1RURFFREQAHHHAATzzxBOCKMrdv315m/datWxk3bhwdOnRg0aJFPPHEE4wfP56RI0cyceJEWrVqxdq1aznvvPMqTdN9991Hr169OPfccwHo168fXbp04dVXX+Wee+6hY8eOADz55JOceeaZDBo0KHoXpHadAszyfjUDvAp0BQKBcBeQ7du+JXAysBdYoaolA9YClwJlAqGIDAYGA7RLxG8oE1eBos/Ad2mg6BNcMAwV7JLpezhmzwhFpK+IvCYir4jIbUHWHy4i//SmJ0WkTST7RaJvX5g0CXJyQMT9nTQpejmkRFLZd1e0v9NOPvlkAGbOnMnSpUv5+9//zj333MPOnTsrbJubm1vy+qCDDuKnn34qsz4jI6OkTV7r1q358ccfAdi+fTutWrUCoEOHDmRnZ1OZ5cuX07Vr15L5Ll268NlnnzFhwgReeOEFhg8fztatWxk4cCB16tThhhtu4N///nc1331cZQM/+OZ/wBf4VPVDYIWI/ENEHgYUaBBuP9/+k1Q1T1XzWrZMmYE0TBVVVs8g3HO+MWNccPMLBLtk+h6OSSD0FedcpKqXAMeISK5vvQD3A7eo6tWqOkhVN4Xbz7f/YBFZIiJLtmzZEjQNffvCunVQXOz+JuLFj4ZQ/4jRUqdOHerUcf8qq1evpkePHogIs2fPjmrTgubNm7Np0yYA1qxZw9atWyvd9rjjjmPu3Lkl8wsWLOC4446jSZMm3HnnnVx22WWMGzcOEWHAgAE88MAD3HZbtX5XxVsB0Nw3f6C3rIQXzAao6k3Az8C3kexn0keoCnWhKryEK3EKF+yS5Xs4VkWj4Ypzfg1sAO71gt9cVX0qgv0Ad+MDkwDy8vKUNBb4x6qsDL+6MjIyyMjIAKBevXoly6+88kqGDx/O22+/TdOmTWndunWZ7f37+ZeratDj+bcfO3YsI0aMoFmzZtStW5cWLVpUSFegm7MRI0Zwyy238Morr7Bjxw7OOusscnNzyc/PZ+PGjWzdupVhw4bx8ssv89Zbb7Fv3z4uueSSml2U+FgMDBWRh7z74kJc5ZgKRKQp0Bv4LbAHOFpE6nvFoxcB82opzSaBhCveDJXri+Q5X9++iRvgIhaLGjhAH+Aq3/xZwB2++d7Au0CWN/84cFq4/YJNqVjTrSq1RlPVnDlz9MYbb4x3MkrEudbolcBzwFRcKUr5WqOPAX8D/g843reuK/AiMBkYD0io86TivZQupk4tramZk1O21niomp2qoWt3xqpWenm1dS9VNsUqR1gA/Mo3X75YZhcu5xfot+o1oDPwZZj9TAqbN28eM2bMIDMzk507dzJu3Lh4JykhqOp0YLp/mYi8BPRW1SLghkr2mwvMDbbOpI5wOb5wxZuhcn2xKnFKOLGIrkAz4C28X6DAs8AvfOsPBl7wzY/E5f5C7hdsSsVfsZYjTDzxzBHW1pSK91IyCZWrC7U+XI4v3PrayvWFEu97KSaVZVR1GzAFmC4iU4HlqrrSt34z8K6ITBeRp4BCVZ0Tbj9jjElm1e2OrCYVWsJVqEum2p0xU5tRF3gJyIjmMVPxV6zlCBOP5QhNTYXKedUkVxdu38C5Q+U24y3e91Kt9jWqqj3VPdMwxpikFK4pQmXrQtXODJerC7U+kiZUydKMIV5SsmcZY4yJhVAVU6D6lVbCNVOwCi2xlZKjT5jqu/rqq1m3bl2ZZTNmzGDKlClBtx8wYACbN29m2bJljB8/vsL6hQsXMnr06JDnPP/880teDx48mF3lfzZX0ejRo1m4cGGNjmHSV3VzdeF6YQnVC1S4XF0kz/ksx1d9FghNGf3792fy5Mlllj3//PP06tUr6PaBPkSPP/54br311krXh+If/X3SpEk0KH/HV1Ek5zTpq7q9rEDoXF1NKq1E0kNL2ldoiSErGk1wN90Ey5ZF95jHHw8PPxx83RlnnMG9996LqiIirFq1ipycHLKysoKOOhEwf/58PvzwQ+644w6effZZXn/9dXJycvjuu+844ogjAJgyZQrLvDeTk5PDkCFDuOuuu1i1ahXDhg0jPz+fXr168dZbb1U6usTkyZOZN28eDRo0YPv27Zx66qn86U9/qvS9/uUvf2Ht2rXUrVuXRo0aMX78eFavXl1mRIqePXty3XXX0bx5c5o2bcrIkSOjc6FN3FQ2YkJNelkJ18l04HiVrQtXhBmuh5aU6MElQVkgNBV069aN9957j27duvHkk0+WjNwQbNSJgEAurLCwkKeffpo5c+YgItx///0lOb727duzcOFCGjZsyKRJkxgyZAj5+fksWrSIhx56CIB9+/YBlY8uAW6UhFGjRgGus+3KAuE777zD7t27efrppwE3EkXgtX9EilWrVlFcXMxf//rXqPadauIjVLALF+giydWFGlEh3GgLFswSkwXCBFdZzi2W+vfvz2233cbpp5/O2rVrOeqoo8qMOrFz504uvvjioPsWFBTQrl27koDSuXNnFixYwPfff8/dd9/N66+/TuPGjZk/f37INCxfvrwk2EHp6BJQdnSLrKysSo/x6aeflhmh4vTTT+fRRx/l0Ucf5Z///Cc33HADV199NZ06deKqq65iyJAhdOnShcsvvzzsNTLxFWqMvJrUzgyX44ukYopVWkk+9ozQVNCqVSuKi4uZPHkyPXv2BCIfdaJFixZ89913gXajJZVW1q9fz4knnkjjxo3ZvHkzK1asKNknsK1fZaNLVMXxxx9f5hgffPABnTp1CjoiRdeuXXn00UeZPHky27dvr9J5TO2qyXO8cMOW1bQpglVaSU6WIzRB9evXj4EDB7Jq1Sog8lEnMjIyuPbaa+nTpw9t2rShTp06NGnShE6dOjFx4kSGDBnCnj17OPPMM0vOlZuby7XXXsv1119fMjJFZaNLLFq0qMzoFoHRKPwC6TjnnHP4+OOPueqqq6hbty5NmjRh3LhxFUak+PLLL7nvvvs44IADaN++PY0bN47hlTU1VZPneOGKNq0pQpqKZ2v+aEyp2BuG9SyTeKxnmdpXWW8ooUZLCOwXqu/MRO9lJR3F+16yHKExJuGEqvBS0+d4VmHFlGfPCI0xCSdU8ad1KWaizQJhgnKlBSYR2GcRG6Eatoeq8GKNy020WdFoAsrKyqKgoIDs7Gxr1xZnqkpBQUHIZhqm6sI1bI+k+NMCn4kWC4QJqG3btmzcuJEtW7bEOykG98Okbdu28U5GSglX8zNc7U5joskCYQLKzMykQ4cO8U6GMTETrmG7NWMwtcmeERpjYiLUM8BwDdvBKryY2hOzHKGI9AUuB4qAhao6rtz6/wCLvdlC4EZVVRGZDazxbTpCVbfFKp3GmOgL9wzQij5NIolJIBSRxkA/oIcX3KaISK6qrvZtVqCq1wTbv7LlxpjkEO4ZoBV9mkQSqxzhKcAsLa13/irQFfAHwgwRuQ9oB7ygqjO95TtEZDTQHvhAVZ8sf3ARGQwMBjcSgTEmsYR7BghW89MkjlgFwmzgB9/8D0CufwNV7QogIpnACyLyhaquVtWLveUCPC4iX6vqnHL7TgImAeTl5VkjL2MSTLjmD8YkklhVlikAmvvmD/SWVaCq+4FZwK/KLVfgdeDYGKXRGBMjkfT+YkyiiFUgXAx0k9LW4BcCH4TY/mRgWZDlpwOfRDdpxphYs95fTDKJSdGoqm4TkSnAdBEpBJap6kr/NiLyDLAbaATMVNV13vIHvWVZwGJVXRCLNBpjYsueAZpkEbPmE6o6HZjuXyYiLwG9VbVIVftXst/NsUqTMSY97NwJn30GjRrB4YfDAQfEO0UmkdVqzzKq2rM2z2dMsougPe4woDOwD8gArlXVXYnQHreoCGbPhjfegG3bXHDasaP0b+B1587w5JPQpk31zrNzJyxbBkuXwpIl7u/Kla4hPrii2XbtoGPHstMRR8DBB0PDhtF6xyZZWRdrxiSocO1xRaQZ0E1Vf+fN3w50xzVXilt73A0b4J//dNP69S5X1rKlCziNGrm/gfn69WHGDDj2WJg8Gc4/P7Jz7NkDDz8MU6fCl1+WBr3WrSEvD3r1ghNOcG0XV60qnZ59FrZvL3ushg3hoIPc1Lp16evDDoPjj4ejjoLMzMjff1ER/PijO3ewafduaNzYXYOWLaFFCzdf1f71i4rg++9h48bSqaDApfuXv3TpbtSoasdMVxYIjUlc4drj/gRsFpGDgW1ADvCUty5se1yIXpvc/fvh9dfhqafg7bfduPDdu8MDD8CFF7qAV5nbboMrroALLoChQ2Hs2Mq3V4WXX4Zbb4W1a6FrV7jsMper7Nw5fK5SFf73PxcUv/7aBZLvv4fvvnN/V62C+fNdQAlc9Xr14OijXVAMTEce6Y7z9ddu+uab0tfr1rnrURX16pUGxebNXbd0deq44Oh/LeKC7MaNsGkTFBaGPm5OjguKv/qV+3vQQS5t5afAcS680OWSo2X7dli8GD76CO64o2o/KGqTJPtYa3l5ebpkyZJ4J8OkIRFZqqp5MTx+H6C+qj7tzZ8FnKSq9/m2ORU4D9c8aYuqTit3DAEeB54v3x63vOreSw89BPff7wLDIYfA1VfDVVdBVfqN37PHBcRHH3U5ueeec8WXfp9+CjfdBO+/7wLTww/D2WdXObkR2b8f1qxxRa6B6T//gcoGhGna1D2LPPxwlyM75BCX02zQoOKUlQU//wxbt7rjBabA/LZtLoerWvZv4HWzZtC2bfCpWTMXlL/4AlasKJ1WroS9e8O/74YNYcQIuPnm6j1XXb8eFiwonZYvd+kWcdfw2Eoaw8X6XgpLVZN66ty5sxoTD8ASjeH/NnAuMNw3fxkw2Dd/LHCfb/5SYGCQ4/wOuCnc+apzL40Zo+q+nlVbtlR95pkqH6KMV19VPfBA1YYNS4/1v/+pDh6sWqeOana26oQJqvv31+w81VFcrPrf/6q++abqQw+pTp+u+vHHqgUFbl0iKyxUXbVKddEi1aVLVZcvV/3yS9U1a1S//VZ10ybVzz9XvfRS91keeqjqtGnh39fu3aozZ6r27avatm3p/0LDhqpnn616zz2q77yj+tNPoY8T63sp3BT3QFbTyQKhiZdaCITNgLcoLbl5FviFb/25wP2++R5AfpDjjAVODXe+qt5LU6eqZmSUfvmBaoMGbnlNbNigesYZ7njnnqvatKlq3bqqQ4eq/vBDzY5twnv/fdVOndz1P+kk1Y8+Krt+717VN95Q7ddPtUkTt112tuoVV6g++qgLtFX9oRLvQGhFo8ZUU20U54jIlcBFuBFalqnqA751AuQDhwJ7gQbAEFUtCNIed0K4c1X1XmrTBjZvrrg8J8c9J6uJoiLXC82oUXDuufDXv8IvflGzY5rIFRe7ikV//rP7jK+4Ai6/3D0HfuUV95yyWTO45BK3/Kyzavb8L95FoxYIjammeN28/va40TxuVe+lymo5ipTW4qyp7dtdjUoTHzt2wPjxbgrUdr3oIhf8zjnHVfKJhngHQqs1akyS0QRoj/vZZ5Wvi2bH2hYE46tRI5crHzzYVbo57TRX2SfVWCA0xlTZ6NHuC1HE5RQCrGPt1HTIIW5KVbHqdNsYk6I+/xxeeMFVsX/ySetY2yQ/yxEaY6pk9GhXZDZsGGRnW+Azyc9yhMaYiH3xhcsN3nijC4LGpAILhMaYiI0e7XofGT483ikxJnosEBpjIrJiBTz/PNxwg+sT05hUYYHQGBOR/HxXK/RmGzHUpBgLhMaYsL780nWEbblBk4osEBpjwsrPd6MRWG7QpKKYNZ+IYGTt/wCLvdlC4EZVVRHpBgwDdgIbVdUeyxsTRytXutzgzTe7MfOMSTUxCYThRtb2FGi5EbS9ToTvAH6rqntFJF9EuqvqrFik0xgT3lNPuV5kbrkl3ikxJjZiVTRa2cjafhkicp+ITBORi71lHYEVqhoYQnJmkP0QkcEiskRElmypbKRMY0xUjB3rBllt1SreKTEmNmJVNJoN/OCb/wHI9W+gql0BRCQTeEFEvqhkvwrNdlV1EjAJXI/5UU25MaaMjAw4/vh4p8KY2IlVjrAAaO6bP9BbVoGq7gdmAb+qyn7GGGNMNMQqEC4GunnP/AAuBD4Isf3JwDJgDXC0iNT3ll8EzItRGo0xxpjYFI2q6jYRmQJMF5HAyNor/duIyDPAbtwo2jNVdZ23fDQwTUR2AFuAd2ORRmOMMQZi2HxCVacD0/3L/CNrq2r/SvabC8yNVbqMMcYYv1odhikRRtY2xhhj/KxnGWOMMWnNAqExxpi0ZoHQGGNMWrNAaIwxJq1ZIDTGGJPWLBAaY4xJaxYIjTHGpDULhMYYY9KaBUJjjDFprVZ7ljHGVJ2I9AUuB4qAhao6rtz6YUBnYB+QAVyrqrtEpBswDNgJbFTV4bWbcmOSg+UIjUlgItIY6AdcpKqXAMeISK5vfTOgm6r+XlWvBlYA3b2RX+4ALlXV3sAuEeke5Pg2yLVJexYIjUlspwCzVDUwAPWrQFff+p+AzSJysIgcAOQAHwIdgRWqutfbbma5/QA3yLWq5qlqXsuWLWP1HoxJaFY0akxiywZ+8M3/AJTkCFVVReRp4DrcINYLVLVARI4Msl92LaTXmKRjOUJjElsB0Nw3f6C3DAARORY4X1XvVtWHgd0iMjDcfsaYUhYIjUlsi4Fu3jM/gAuBD3zrDwbEN78baA+sAY4Wkfre8ouAebFNqjHJyYpGjUlgqrpNRKYA00WkEFimqit9m7wLnC4izwJ7gQbAEFUtEpHRwDQR2QFs8bY1xpRjgdCYBKeq04Hp/mUi8hLQW1WLgDsr2W8uMDf2KTQmucUsEIZr++RtUxd4Ftiuqn/yls3GFesEjFDVbbFKpzHJSFV7xjsNxqSKmARCX9unHl6ttikikquqq8ttehcwGejtX6iq18QiXcYYY0x5saosE67tEyLSB1gCrCq37w4RGe0Fz0HBDm6NgE0yEpHW8U6DMaaiWAXCYG2fStowicgJQGtVfaP8jqp6sareDfwB6CwiZwXZxhoBm2R0p4g8JyJ9RCQr3okxxjixCoTh2jBdARwpIhOBMcCpInKd/wBebvJ14NgYpdGYWqWqN+J+4O0BJonIUyJyepyTZUzai1UgDNn2SVVvV9U/ec8C78T1hjEhyHFOBz6JURqNiYc84EwgC1gIHC4ij8Y1RcakuZhUlomg7ZNfEVAYmBGRB4FGuC+Kxaq6IBZpNKa2ici/cP2APqiq3/qWt4pfqowxMWs+EUHbp8B2G4BrfPM3xypNxsTZA6r6XmBGRM5W1fdUdWw8E2VMuqvVLtZUtac/CBqTZnqUmz8/LqkwxpRhfY0aU3salZtvFo9EGGPKsi7WjKk9X4jIKGA+cA7wZZzTY4zBAqExtUZVHxWRM3A1R99W1TnxTpMxxopGjak1XnOibbhmE3tE5OT4psgYA5YjNKY2PYjLDS7GdTn4MS4oGmPiKKIcoYjc4P09W0TmicjImKbKmNRUBHyiqrcCJwL1w2xvjKkFkRaNtvf+XozrFeOQGKTFmFRXDCAih6lqMbA/zukxxhB50ehB3mjX73nDKmXEMlHGpKjXgA3AMyKiwJtxTo8xhsgD4c3Asao625t/OkbpMSaVZXtdBnYNu6UxptZEWjTaWVVni0gHEZmBb0glY0zE+sc7AcaYiiLNEZ4F/AsYCtyEq/02MzZJMiZlbfU63l6I62i+yPoZNSb+Ig2ELUXkbGCdqm4Wke2xTJQxKWoK4H++bv3uGpMAIg2E/8B1CTXKm18am+QYkzjuuQfOPRdOPTU6x1PVD6NzJGNMNEUUCFV1vojUB4aIyL9VdVKM02VMXM2aBaNHQ5060QuEIvImkIm7744CPlbVi6JzdGNMdUUUCEXkz8ABuM6Cu4nIb1T1/pimzJg42bMHrrsOcnNhxIjoHVdVfxd4LSKNgPHRO7oxproiLRo9XFUHeK/fFZF/xCpBxsTbfffBmjUuV5iVFZtzqOoOESmMzdGNMVURaSAs3wOG9YhhUtJXX8H990PfvtCtW3SPLSJXUNpkqQ3WQ5MxCSHSQLhbRAYBc3FNKXaG20FE+gKX42rGLVTVcUG2qQs8C2xX1T95y7oBw7xzbFTV4RGm0ZgaUYVrr4UGDeDBB2NyirqU1hpdA/w9JmcxxlRJpA3qbwUEF6CKgdtCbSwijYF+wEWqeglwjIjkBtn0LmAy3peDN0zNHcClqtob2CUi3SNMozE1MnUqzJ3rcoQHHRSTU2xS1We8aSZwSkzOYoypkkhrjRYCJTVFvdEoHguxyynALFVVb/5VXLdSq33H6AMsAVb59usIrFDVvd78TOBSYJb/4CIyGBgM0K5du0jegjEh/fAD3Hwz/OY3MGhQzE7zW8A/GO/5wHvhdgpVuiIiv8B1chFwMjBIVT8Wkf/ghnwC14D/Rt89aYzxVHc8wmPDrM8GfvDN/wCU5AhF5ASgtar+n4i0D7Nfhe7cvOYbkwDy8vLsxjY1NmKEC4azZrkmEzHSqNx8s3A7+EpXengd3k8RkVxVXQ2gqiuBa7xtM3A/Oj/xdi9Q1WvCHN9+VJq0F6tbvgBo7ps/0FsWcAVwpIhMBMYAp4rIdRHsF7Fvv4WTT4a33qrO3qY2/fgj7NoVv/MvWABPPgk33QTHHRfTU30hIqNEpJuIjAO+jGCfykpXgukJvOrbNkNE7hORaSJycbAdVHWSquapal7Lli2r8FaMSR0hc4S+BsBlFgNHhjnuYmCoiDzk3ZQXAvcGVqrq7b5ztAfuUtUJ3i/ao0Wkvlc8ehEwL9I349e6NXz5Jbz4Ivz2t9U5gqkNn38OZ5wBxcUwcKBrv9ehQ+2df/9+uOYaOPRQGDkytudS1UdF5AzcKPVvq+qccPsQpnSlnD/iHiUEztcVQEQygRdE5ItATtIYUypkjlBVf6eq55SbuqtqyDIUVd2G61dxuohMBZZ7RTjBFOGeX6CqRcBoYJqITAaygHer9I489evDBRfAzJnuy84knq+/hu7dXVu97t3hoYfg8MPh4ovhvfdcLc5Ye+ghF4wfewwalS+4jDIR+ZOqzlPVB1V1joj8KYLdIiol8foCXqSqe8qvU9X9uOfsv6pm0o1JadV9RhiWqk4HpvuXichLQG8v4AW224D3jMObn4trplFjl13magK+/777ojWJ47//de309u+HDz6AX/4SNm6EiRPhiSfg1VfdshtvhH79oGHDqp+jsNC1C9y5E4qKyk7FxbBjh8sFXnQRXHhh1N9iMOVzckdFsE/I0hWfG4BQ1XxOxtXSNsaUE7NAGIyq9qzN851zjvsCfeklC4SJZOtW99kUFMCcOS7gAbRtC/n5cNddMGMG/O1vrl3frbfCiSdC586l0+GHg0jZ4+7aBYsXw4cfumnhQtgeZpyUxo3deWpJScUvEakDhG2koarbRCRQulIILCtfuiIixwH/VdWt5ZY/A+zGVdKZqarrav4WjEk9kuy1qfPy8nTJkiWVrr/8cpcj3LQJMjIq3czUUODfqHxwKu/nn+Hss+Gzz+Dtt+HMM0Mfc+FCmDIFliyB5cth3z63rlkz6NTJBUVVmD8fli51uUAROOYY6NIFTjkFmjd3n31GhqsR6n99+OHVbzMoIktVNa8K25+Fa+qwHPg18FdVfaea565QulJT4e4lY2KlqvdStNVqjjAeLrsMnn/e5RDOOCPeqUlNzz4LQ4dC+/auDV7fvtC0acXtdu92RZDLlsErr4QOguAC2imnuAlcEPz8cxfwli51wfHhh912J57oco6B4NesWVTfYlR4zwU/wRWJbsMNdF2tQFjbpSvGpLKUD4Q9erjKGC+9ZIEw2nbsgBtugGeecU1Vdu+G66+HW25xOfFBg9xyEfcssHdv9zxw2jQ4//yqn69ePZcL7NSptNH7vn0uR1i/fnTfWyx47WevAroA16rqA3FOkjGG2LUjTBiNGsF557lAWFwc79Skjs8+g1//2uUG77nHFU3++9/wySeucsuLL7px/I4+2uXa+veHN96ACRPgyiujl4569RI/CIrIlSLyIm5w67uBT1V1cZjdjDG1JOUDIbji0U2bXEUKUzOqrvH5iSfCtm0wezaMGuWeuYlAXp6r9bl5Mzz1lPshMmwYTJ/uhje6JmQ/JynrTuAfqjpWVX8CkvvBvDEpJi0C4fnnQ2amyxWa6vv5Z+jTBwYPhtNOc8/6zjor+LaNGsGAAe7Hx6efuvac0RzkNsl0AlqKyFMicjmlI1AYYxJAyj8jBFdx45xzXHHd+PHhazamo4ULXeAqKnIVTQJT8+bub5Mm8PTTsHYt3Hsv3H575H1yHnusm9KVqu7DDTf2rIicBhSLyD3ADFX9Kr6pM8akRSAE6NkT3nzTPcdauRLuvBPWr4d27WDMGFfTMV2tXOlyzU2auNEXfvzRFXt++637++OPrlLKoYe6pihdusQ5wUlMVecD80UkB9eRxB1xTpIxaS9tAuGFF7rnWKNGue67Ap08f/utK+qD9AyGmze7ykR167rnfYcfHny73btd8XLdtPmPiS1V/RYLgsYkhLR4RgiQne2eZ/3rXxVHOti1y+UQ083PP7vmJVu3utxyZUEQ4IADLAgaY1JT2gRCcMWjhYXB161fX7tpibd9++DSS+GLL9yz07y49elgjDHxlVaB8OKLK1+XTmOSFhfDVVe5IuKnnnJFo8YYk67SKhAedBD84hcVa402aOAqzCS7oiJYtSr8sFMjRsD//Z+r/dm/f+2kzRhjElVaBUJwA7+qQps2LiDm5MCkSclfUWbbNpezO/JI19yhWzdXMWju3LLPRB95xDUhuf76tG7XZ4wxJdKu+sOll8KQIS4Q/PnP8U5NdHz9tWv+8PXX8Je/wJYtrsuzUaNc0M/MdKM0/OpX8M9/umvwyCPWntIYYyANA+Ehh7iOoF98MTUC4fz5cMklLuDNng2nn166bts2+Ogjt80HH7h+Qc86yw1WbENSGWOMk3aBEFzt0VtugW++gcMOi3dqqu/ZZ2HgQOjQwTV/OOKIsuubNYPf/tZN4J4dZmbWejKNMSahxSwQikhf4HKgCFioquPKrZ8AZAINgVWqOtJbPhtY49t0hKpui2baAoHw5Zfd31hQdcMUbdsGP/1Udtq9G046yY3MXp3iyeJiN+LDmDEuh/fii64rtHAsCBpjTEUxCYQi0hjoB/RQVRWRKSKSq6qrA9uo6nW+7Z8RkSMD/S6qakzHKGjf3j0ze+45NzJCNIsJt2yB3//eFVOGG/bpsMPgggvcdPrpkQWqXbtcTc8XX3Rj8v397xbgjDGmJmKVIzwFmKWqgeFmXgW6AqvLbygizYGWwPfeoh0iMhpoD3ygqk8G2WcwMBigXTUbAF59tasw0707TJninh3W1KefwkUXwfffw/DhrrlG06auiLJp09IpI8PV5nztNTdk0SOPuOXnneeC4gknuN5evvvOHev770tff/EFrFsHDzzgzmEVXowxpmZiFQizgR988z8Auf4NROQIYBQuaA4LFH+q6sXeegEeF5GvVXWOf19VnQRMAsjLy6vW2G7XXuu6DbvhBjjuOJg8uXqjpge89BL84Q+uiHL+/PA9teTmuj5Od+50Ddtfe80NXDtjRsVtMzKgVSsXWI88Eh59FH73u+qn1RhjTKlYBcIC4Fe++QO9ZSVUdQ3QV0TqAtNFZJGqfudbryLyOnAsUCYQRoOI613llFPgiitcTmzIEBg7FrKyIj9OcbFrsjBqlBu54eWX4eCDI9+/YUPXIfiFF7pjffKJawZx0EGlU3Z25EMeGWOMqZpYfb0uBrp5uTqAC4EPgm2oqoW4gUrrBVl9OvBJTFLoOfJIWLQIhg6Fv/3NBbOVKyPbd8cOuOwyFwT/+Ec3RFFVgmB5deq4SjR9+sDZZ8PRR0PLlhYEjTEmlmKSI1TVbSIyBZfTKwSWqWpJeBGRTsBwYAfQBHhJVdd76x4EGgFZwGJVXRCLNPrVrw8PP+x6Y7nqKleR5m9/c88RK3sGt3atex74xRfw0EMukNrzOmOMST5SWp+lFk4m8hLQW1WLonXMvLw8XbJkSbQOx6ZN0K8fzJnjii3r13dFpfXrl51Wr3ZNJGbMgHPOidrpTRIRkaWqmjLjdkT7XjImUvG+l2q1Qb2q9qzN81VHmzbw7ruuK7KVK2HvXjft2VP6eu9eOPNM9zwxNzfsIY0xxiSwtOxZJpyMDNdGzxhjTOqzahhBTJvmGt3XqeP+TpsW7xQZY4yJFcsRljNtmmvfFxi66Ntv3Twk/1BNJjmF6q5QRH4B3OTb/GRgkKp+HK6bQ2OMYznCcu68s+z4feDm77wzPukx6c3XXeFFqnoJcIyIlDyZVtWVqnqN1y3h9cAG4JNw+xljSlkgLGf9+qotNybGKuuuMJiewKvethHtJyKDRWSJiCzZsmVLlJNuTHKwQFhOZV2XVrNLU2NqKlh3hdmVbPtHYEpV9lPVSaqap6p5LVu2rHlqjUlCFgjLGTMGGjQou6xBA7fcmDgoAPyDbFXorhBARM4GFqnqnqrsZ4yxQFhB374waRLk5LieYnJy3LxVlDFxEml3hTcAE6qxnzFpz2qNBtG3rwU+kxjCdVcIICLHAf9V1a1V2c8Y41iOsIqsjaGpbao6XVWvUNXfq+oD4LorFJEMb/2nqnpDJPsZYyqyHGEVWBtDkyiSobtCY5KF5QirwNoYGmNM6rFAWAXWxtAYY1KPBcIqsDaGxhiTeiwQVkEkbQytMo0xxiQXC4RVEK6NYaAyzbffukF7A5VpLBgaY0ziskBYRX37wrp1UFzs/vpri1plGmOMST4xaz4RbggYEZkAZAINgVWqOtJb3g0YBuwENqrq8FilMdqsMo0xxiSfmOQIIxkCRlWvU9VBqtoH6CAiR3rdQd0BXKqqvYFdItI9FmmMBatMY4wxySdWRaMRDx0jIs2BlsD3QEdgharu9VbPDLZfog4dY5VpjDEm+cQqEIYdAkZEjhCRacC/gUmqui2S/SBxh46xyjTGGJN8YhUIww4Bo6prVLUvkAv0FZHWkeyX6KwyjTHGJJdYBcKIh4BR1UIgA6gHrAGOFpH63uqLgHkxSmOts8o0xhiTeGJSazTcEDAi0gkYDuwAmgAvqep6b91oYJqI7AC2AO/GIo3x0K6dKw4NttwYY0x8xKwdYaihY1T1397ya1S1j6pO8+03V1UvU9U/quqtvgo3SS9cZRqrSGOMMbWvVhvUq2pPVS2qzXMmklCVaawijTHGxIf1LFPLKqtMYxVpjDEmPiwQJohIKtJY0akxxkSfBcIEEa5XGis6NcaY2LBAmCDCVaSxolNjjIkNC4QJIlyvNOGKTq3Y1Bhjqidmo0+Yquvbt2xPNH6h2iAGik0DOcZAsWngmMYYYypnOcIkEaro1IpNjTGm+iwQJolQRafWdZsxxlSfBcIkUlkbxEjGQbRniMYYE5w9I0wBY8aUfUYIFbtuC/cMcdo0V5S6fr0LoGPG2PNFkxr279/Pxo0b2bNnT7yTkvaysrJo27YtmZmZ8U5KGRYIU4C/d5pggSzUM0R/925W2cakoo0bN9K4cWPat29P6YA4prapKgUFBWzcuJEOHTrEOzllWNFoigg1DmK4Z4hW2caksj179pCdnW1BMM5EhOzs7ITMmVsgTAPhniFaG8XEJiJ9ReQ1EXlFRG4Lsv5wEfmnNz0pIm285f8RkYne9JikcSRI47eeUBL1c7BAmAbC9VoTKlBG0rWbBcrYEZHGQD/gIlW9BDhGRHJ96wW4H7hFVa9W1UGquslbXeANdXaNqt6QSkOaxZL9P6cfC4RpIFyvNTVpo2h9oMbcKcAsXxB7FejqW/9rYANwr4hME5GBvnUZInKft/ziYAcXkcEiskRElmzZsiUW6U8qsfh/zs/PZ+DAgXTs2JE+ffowcOBAli9fHna/u+++m7Vr11a6/vvvv2f48OHVT5gppapJPXXu3FlNzU2dqpqToyri/k6d6paLqLqvhLKTiFufkxN8fU5OfN5HbQKWaIz/v4E+wFW++bOAO3zzvYF3gSxv/nHgtHLHyARmArmhzpWq99KKFSsi3jaW/8/9+/fXDRs21PxASS7Y51Eb91KoyWqNGqDy7t1Cde0GkT1ftGYZNVIA/Mo3f6C3LGAXLscYqIHwGtAZmB/YQFX3i8gs7zirY5vc5FZbnVP07t2b3NxcvvnmG6ZPn87IkSP5+eefKSws5IILLqB79+4MGDCA/Px8vvrqKyZMmEDz5s1RVdq0acPIkSPZsGED+fn5PPHEE/Tq1YtDDz2U/fv3s2nTJsaOHcsRRxzB8uXLyc/Pp127duzZs4cVK1YwZ86cMml54403eP/991FVGjduzMiRI1FV7rnnHn788UcyMzPp168f7dq1484776RBgwYUFxczZswYGjVqFN0LEycxC4Qi0he4HCgCFqrquHLrHweKcTf2m6o61Vs+G1jj23SEqm6LVTpNaOHaKFofqDG3GBgqIg95v5wvBO71rV8K9PfNnwR8EOQ4JwN3xSyVKSLcD79o2bp1K0OHDuXUU08FoH379nz88cc0atSIxx57jO7du1NUVERRUREABxxwAE888QQAPXr0YPv27WXWb926lXHjxtGhQwcWLVrEE088wfjx4xk5ciQTJ06kVatWrF27lvPOO69CWnJyctizZw9ZWVm89NJLDB06lFdffZX27dszevToku0GDBjA7bffTseOHaN7MRJATJ4RhnvAD6Cq16rq9biinz+VW3eNb9oWizSayMTy+SJYxYRwvP//KcB0EZkKLFfVlb71m4F3RWS6iDwFFKrqHAARecarMToVmKmq62r/HSSXcBXLounkk08GYObMmSxdupS///3v3HPPPezcubPCtrm5pV+fBx10ED/99FOZ9RkZGSVt81q3bs2PP/4IwPbt22nVqhUAHTp0IDs7u8x++/btY/Dgwdx111088MADHHnkkezcuZMlS5Zw2mmnldl2w4YNKRkEIXY5wsoe8AcrlqkP/OCb3yEio4H2wAeq+mT5HURkMDAYoF20f6qZCkKNihGqMX+/fsH38RebWo4xPFWdDkz3LxORl4Deqlrk3SMV7hNV7V9+mQktXOcU0VKnTh3q1HH5kNWrV9OjRw9EhNmzZ0e1iUHz5s3ZtGkTbdq0Yc2aNWzdurXM+p9++olDDz2U1q1bs3v3bj766CMATjjhBGbNmlUm8B188MF89tlnHHPMMVFLX6KIVSDMpmxw+wHIrWTbfKCk2FRVL4aSauGPi8jXgV+4vm0mAZMA8vLyrEp4nFX3+WK4Hm9M5VS1Z7zTkKpC/fCriYyMDDIyMgCoV69eyfIrr7yS4cOH8/bbb9O0aVNat25dZnv/fv7lqhr0eP7tx44dy4gRI2jWrBl169alRYsWZdLUsmVL2rVrxw033MCuXbs488wzERGuuuoqbrvtNgYPHswBBxxA//79GTduHLfeeiuNGzcmIyODe++9N2WeEcaqptu5wHDf/GXA4CDbDQP6hjjO74CbQp0rVWu6pYKpU1UbNChb+65Bg8hrpFZWkzVREOeabtGeUvVeqkqt0VQ2Z84cvfHGG+OdjLSqNRruAT8ich2wU1VDPRU6HVcLziShcMVMVtHGmNiaN28eM2bMIDMzk507dzJu3LjwO6WhmARCVd0mIoEH/IXAMvU94BeRU4ARwFsiMtFbfLeqbhGRB4FGQBawWFUXxCKNpnaEKmYKVSPVik2NqbkzzjiDM844I97JSHgxaz6hoR/wfwQEreWiqjfHKk0msdSkog1YG0VjTHTUaoN6tQf8ppzqVrSxolNjTLRYX6MmIYVrz2VtFI0x0WKB0CSkcA35I+nazToDN8ZEwgKhSVihBhsON8aiDTZsEsXVV1/NunXryiybMWMGU6ZMCbr9gAED2Lx5M8uWLWP8+PEV1i9cuLBM12fBnH/++SWvBw8ezK7yN4MpwzrdNkkpXB+o1hm4Ceamm2DZsuge8/jj4eGHK1/fv39/Jk+ezMiRI0uWPf/880yrpHgi0Ifo8ccfz/HHH1/p+lD8o8BPmjQp5LbGAqFJUtZG0SSLM844g3vvvRdVRURYtWoVOTk5ZGVlBR11ImD+/Pl8+OGH3HHHHTz77LO8/vrr5OTk8N1333HEEUcAMGXKFJZ5kT0nJ4chQ4Zw1113sWrVKoYNG0Z+fj69evXirbfe4ueff2b48OFkZGSwc+dOunbtyoABA5g8eTLz5s2jQYMGbN++nVNPPZU//alM9898/vnnTJkyhcLCQnbt2sW4ceNo3Lgxzz33HLNmzaJp06acdNJJ9O7du8KoFZ06daq1a11dFghN0rI2iqaqQuXcYqlbt2689957dOvWjSeffJJBgwYBwUedCAjk/AoLC3n66aeZM2cOIsL9999fkuNr3749CxcupGHDhkyaNIkhQ4aQn5/PokWLeOihhwDXsTbAfffdR69evTj33HMB6NevH126dAFcn82jRo0CoEuXLhUC4cEHH0ydOnUoLCxk/fr1zJ49m2OOOYZ33nmHp59+umS7yZMnVxi1IhnYM0KTkkJVtolkzDmrcerYdYiO/v37M3XqVPbt28fatWs56qijIhp1AqCgoIB27dqVdMbduXNnwI1Qf/fddzN27FjGjx8ftt/P5cuX07Vr15L5Ll268NlnnwFlR7fIysqqsO+gQYO4+OKLeeSRR+jRowc7d+5k2bJlJSNoBAQbtSIZWCA0KauyyjbhKtpYjVPHrkP0tGrViuLiYiZPnkzPnq45daSjTrRo0YLvvvsu0P8yCxcuBGD9+vWceOKJNG7cmM2bN7NixYqSfQLb+h133HHMnTu3ZH7BggUcd9xxEaX/xx9/5KSTTgLgvffeA+DYY48tczwoHbUi2VjRqEk74SraWNGpY9chuvr168fAgQNZtWoVEPmoExkZGVx77bX06dOHNm3aUKdOHZo0aUKnTp2YOHEiQ4YMYc+ePZx55pkl58rNzeXaa6/l+uuvLxmZYsSIEdxyyy288sor7Nixg7POOovc3FwWLVpUZnSLzMzMCmkfOHAg/fv3p169ehx22GGICB07dqRHjx707duXFi1acMoppwQdtSIZnhFKsF8OySQvL0+XLFkS72SYJBOq1midOi4HVJ6Iy12WzstSVc2rnRTHXvl7KdLrkOi+/PJLjjrqqHgnw3iCfR7xvpcsR2jSUqiKNuG6d0sXdh1MurBnhMaUE657t3Rh18GkCwuExpQTrnu3dJFK1yHZHwGlikT9HKxo1JggQhWdppNUuA5ZWVkUFBSQnZ1dac1ME3uqSkFBQdDmGfFmgdAYk9Latm3Lxo0b2bJlS7yTkvaysrJo27ZtvJNRgQVCY0xKy8zMpEOHDvFOhklg9ozQGGNMWotZjlBE+gKXA0XAQlUdV27940AxcCDwpqpO9ZZ3A4YBO4GNqjo8Vmk0xhhjYhIIRaQx0A/ooaoqIlNEJFdVVwe2UdVrvW0F+ACY6r2+A/itqu4VkXwR6a6qyddnjzHGmKQQqxzhKcAsLa0r+yrQFVgdZNv6wA/e647AClXd683PBC4FygRCERkMeAPnsENEvope0qOmBbA13okIwtJVNaHSlVObCYm1pUuXbhWRIE3o4y4Z/zfiJRHTBOHTFdd7KVaBMJvS4Ib3OreSbfOBQLFpsP2yy++gqpOAhB5tUkSWJGL3W5auqknUdMWCqraMdxqCSdTPIBHTlYhpgsRNV0CsKssUAM198wd6y8oQkWHAf1R1QVX2M8YYY6IlVoFwMdBNSluvXoh7DlhCRK4Ddqqqf1CXNcDRIlLfm78ImBejNBpjjDGxKRpV1W0iMgWYLiKFwDJVXRlYLyKnACOAt0Rkorf4blXdIiKjgWkisgPYArwbizTWgkQturV0VU2ipiudJOpnkIjpSsQ0QeKmC6jlYZhE5CWgt6oW1dpJjTHGmBCSfjxCY4wxpiasZxljjDFpzfoajTIR+Q+ushBAIXCjxinbLSIZwF+Azqp6nrcs7j33VJKu2bjKUgEjVHVbLaerQm9HiXC90pXdS9VOl91LVaWqNkVxAmbHOw2+tFwEnBRIEyDAe0B9bz4f6B7vdCXgdRNgfqJcr3SdEux/wu6l6qUvKe4lKxqNvgwRuU9EponIxfFMiKq+qqqLfYuC9dzTNQHSBa6HoNFed3yDajtN5QR6O0qI65XG7F6qerrA7qUqs6LRKFPVrgAikgm8ICJfqK+P1TiLqOeeeFDVi6Gk79nHReRrVZ0Tp+QEejtK2OuVDuxeqh67l6rOcoQxoqr7cX2k/ireafFJ+J571JWbvA4cG4/zl+vtKOGvVzqwe6l67F6KnAXC2DoZWBbvRPgkS889pwOf1PZJg/R2lCzXKx3YvVQ9di9FwIpGo0xEngF2A42Amaq6Lr4pAmA/gKoWJVjPPfsDL0TkQdw1ywIWa2n/s7Wist6OgES6XmnF7qWqpwvsXqoOa1BvjDEmrVnRqDHGmLRmgdAYY0xas0BojDEmrVkgNMYYk9YsEBpjjElrFgiTnIhsEJGnvGl0FI/7DxE5OFrHMybR2b2UvqwdYfL7SlUHxuC4Gd5kTLqweylNWSBMQSJyN9AOWOX9naeqL4pIE+CvQBHQEJirqv8QkQOA+3E9xBcBD3uHGi0i/wM6AH9V1UUiciPwS2AX8KSqrqzFt2ZMrbJ7KT1YIEx+vxSRyd7rf6vq33C/Pv+jqhMARGSWiLwM3AG8oKrveMuniMiHwJXAa6r6XuCgrr9eHlfVj0XkEOABYBFwHvBHVd1SO2/PmFpj91KaskCY/Fao6h+DLP/K97oAaIbrfPf/+ZZ/CBwD5AH3BjnGJgBV/a+ItPCWDQCGeAOC5qvqrhql3pjEYfdSmrLKMqmrM5SMYN1KVX8APqXsGGCnesv+A3QPczwBUNXvVPVu4HPgj1FOszGJyO6lFGc5wuR3pIg85b3eq6rXe6+PEJH7gRzceGDgnl08ICKX4DrlnaOqq73t/ioi5wP7KH32UeQ7z34AEXkEyAQOAv4cw/dlTG2zeylNWafbKUhERgKzVfXDeKfFmGRm91J6sKLR1FQMFMY7EcakALuX0oDlCI0xxqQ1yxEaY4xJaxYIjTHGpDULhMYYY9KaBUJjjDFpzQKhMcaYtPb/AU5yLcc2VKJ7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_lstm = history_lstm.history\n",
    "print(history_lstm.keys()) \n",
    "\n",
    "acc = history_lstm['accuracy']\n",
    "val_acc = history_lstm['val_accuracy']\n",
    "loss = history_lstm['loss']\n",
    "val_loss = history_lstm['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# LOSS\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('LSTM Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# ACCURACY\n",
    "#plt.clf()   # 그림을 초기화합니다\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('LSTM Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93920dc2",
   "metadata": {},
   "source": [
    "#### (7) test data 로 모델 성능평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b2714f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534/1534 - 3s - loss: 0.4204 - accuracy: 0.8433\n",
      "results_lstm [0.42039772868156433, 0.8432890772819519]\n"
     ]
    }
   ],
   "source": [
    "## LSTM 모델 성능평가\n",
    "results_lstm = model_lstm.evaluate(X_test_tensor,  y_test, verbose=2)\n",
    "\n",
    "print(\"results_lstm\", results_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d215759",
   "metadata": {},
   "source": [
    "#### [Unigram SentencePiece 평가] Unigram SentencePiece의 경우 LSTM test accuracy 84.32% 였슴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dca4da3",
   "metadata": {},
   "source": [
    "###  (8)  Bpe  (Byte Pair Encoding)  Model Type로 했을 경우 :\n",
    "상세 작업과정은 아래 깃허브파일을 참조\n",
    "\n",
    "*  **bpe GitHub 링크** : https://github.com/lkh-7/first-repository/blob/master/%5BGDeep%5D02_%5Bsp_tokenizer%5D_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_%EB%A9%8B%EC%A7%84%20%EB%8B%A8%EC%96%B4%EC%82%AC%EC%A0%84%20%EB%A7%8C%EB%93%A4%EA%B8%B0_Project_%EC%A0%9C%EC%B6%9C%EC%A4%80%EB%B9%84%EC%9A%A9_SPM_Bpe_ONLY.ipynb\n",
    "\n",
    "#### [평가] bpe SentencePiece의 경우 LSTM test accuracy 83.64 % 였슴\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89439a38",
   "metadata": {},
   "source": [
    "### (9) [ Unigram  vs. bpe SentencePiece 성능 비교평가]\n",
    "**Unigram** 이 **test accuracy 84.32%** 로서, bpe 83.64% 보다   LSTM Model test accuracy 에서  성능이 큰차이는 아니지만 **더 우수했슴**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf642b",
   "metadata": {},
   "source": [
    "# 3. Konlpy 토크나이저 사용의 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12bd3fe",
   "metadata": {},
   "source": [
    "* **Mecab, Kkma, Okt 와 비교**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2a4e89",
   "metadata": {},
   "source": [
    "####  (1) 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bee952ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data          id                                           document  label\n",
      "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
      "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
      "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
      "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
      "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1 (150000, 3)\n",
      "------------------------------------------------------------\n",
      "test_data         id                                           document  label\n",
      "0  6270596                                                굳 ㅋ      1\n",
      "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
      "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
      "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
      "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0 (50000, 3)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table(r'~/aiffel/sp_tokenizer/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sp_tokenizer/ratings_test.txt')\n",
    "\n",
    "print(\"train_data\",train_data.head(),train_data.shape)\n",
    "print('-'*60)\n",
    "print(\"test_data\",test_data.head(),test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3c0b61",
   "metadata": {},
   "source": [
    "####  (2) Mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28abd757",
   "metadata": {},
   "source": [
    "* **데이터 전처리,형태소분석,Tokenizer 함수생성 및 word_to_index, index_to_word 관련 함수생성**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a7664e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data['document'].nunique() 146182\n",
      "train_data['label'].nunique() 2\n",
      "중복제거후 len(train_data) 146183\n",
      "test_data['document'].nunique() 49157\n",
      "test_data['label'].nunique() 2\n",
      "중복제거후 len(test_data) 49158\n",
      "결측치 개수 id          0\n",
      "document    1\n",
      "label       0\n",
      "dtype: int64\n",
      "결측치제거후 결측치 여부 False\n",
      "결측치 개수 id          0\n",
      "document    1\n",
      "label       0\n",
      "dtype: int64\n",
      "결측치제거후 결측치 여부 False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3107/1893021137.py:37: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[' ']+\",\" \")\n",
      "/tmp/ipykernel_3107/1893021137.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"\\.{2,30}\",\" \")\n",
      "/tmp/ipykernel_3107/1893021137.py:39: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글과 공백,기타일부 등제외후 모두제거상태_train_data.head()          id                                           document  label\n",
      "0   9976970                                 아 더빙  진짜 짜증나네요 목소리      0\n",
      "1   3819312                       흠 포스터보고 초딩영화줄 오버연기조차 가볍지 않구나      1\n",
      "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
      "3   9045019                        교도소 이야기구먼  솔직히 재미는 없다 평점 조정      0\n",
      "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3107/1893021137.py:43: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document' ]= test_data['document'].str.replace(\"[' ']+\",\" \")\n",
      "/tmp/ipykernel_3107/1893021137.py:44: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"\\.{2,30}\",\" \")\n",
      "/tmp/ipykernel_3107/1893021137.py:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글과 공백,기타일부 등제외후 모두제거상태_test_data.head()         id                                        document  label\n",
      "0  6270596                                             굳 ㅋ      1\n",
      "1  9274899                                                      0\n",
      "2  8544678             뭐야 이 평점들은  나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
      "3  6825595                     지루하지는 않은데 완전 막장임  돈주고 보기에는       0\n",
      "4  6723715  3만 아니었어도 별 다섯 개 줬을텐데  왜 3로 나와서 제 심기를 불편하게 하죠??      0\n",
      "Nan 존재유뮤 True\n",
      "Nan 존재유뮤 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146026/146026 [00:15<00:00, 9654.47it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train [['아', '더', '빙', '진짜', '짜증', '나', '네요', '목소리'], ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍', '지', '않', '구나'], ['너무', '재', '밓었다그래서보는것을추천한다'], ['교도소', '이야기', '구먼', '솔직히', '재미', '없', '다', '평점', '조정'], ['사이몬페그', '익살', '스런', '연기', '돋보였', '던', '영화', '!', '스파이더맨', '에서', '늙', '어', '보이', '기', '만', '했', '던', '커스틴', '던스트', '너무나', '이뻐', '보였', '다']] 146026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49084/49084 [00:04<00:00, 11512.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test [['굳', 'ㅋ'], ['뭐', '야', '평점', '나쁘', '진', '않', '지만', '10', '점', '짜리', '더더욱', '아니', '잖아'], ['지루', '하', '지', '않', '은데', '완전', '막장', '임', '돈', '주', '고', '보', '기'], ['3', '만', '아니', '었', '어도', '별', '다섯', '개', '줬', '을', '텐데', '왜', '3', '로', '나와서', '제', '심기', '불편', '하', '게', '하', '죠', '?', '?'], ['음악', '주', '된', ',', '최고', '음악', '영화']] 49084\n",
      "X_train[:5] [[31, 70, 869, 38, 223, 19, 32, 723], [994, 503, 535, 662, 5, 117, 1591, 52, 894, 975, 14, 43, 376], [23, 201, 3], [8141, 154, 4048, 289, 91, 17, 6, 56, 3375], [3, 8618, 1079, 52, 2750, 58, 5, 13, 2718, 40, 1149, 34, 337, 41, 21, 39, 58, 3, 3, 410, 2968, 1719, 6]] y_train[:5] [0 1 0 0 1] X_test[:5] [[809, 129], [82, 113, 56, 920, 326, 43, 37, 98, 36, 617, 3449, 71, 885], [94, 8, 14, 43, 227, 135, 343, 127, 150, 53, 7, 10, 41], [137, 21, 71, 20, 450, 229, 2047, 120, 541, 9, 570, 61, 137, 28, 613, 333, 3, 817, 8, 12, 8, 287, 16, 16], [233, 53, 157, 11, 54, 233, 5]] y_test[:5] [1 0 0 0 1]\n",
      "len( word_to_index) 9997\n"
     ]
    }
   ],
   "source": [
    "## 데이터로더\n",
    "tokenizer = Mecab()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "num_words=10000\n",
    "\n",
    "def load_data(train_data, test_data, num_words=num_words):\n",
    "    ## 중복값 제거:  'document'컬럼의 중복값 제거,'label'컬럼은 0,1의 두개면 맞음\n",
    "    #1. train_data\n",
    "    print(\"train_data['document'].nunique()\",train_data['document'].nunique())\n",
    "    if train_data['document'].nunique() < len(train_data):\n",
    "        train_data.drop_duplicates(subset=['document'], inplace=True) \n",
    "        print(\"train_data['label'].nunique()\",train_data['label'].nunique())    \n",
    "        print(\"중복제거후 len(train_data)\",len(train_data))    \n",
    "    #2. test_data    \n",
    "    print(\"test_data['document'].nunique()\",test_data['document'].nunique())\n",
    "    if test_data['document'].nunique() < len(test_data):\n",
    "        test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "        print(\"test_data['label'].nunique()\",test_data['label'].nunique())    \n",
    "        print(\"중복제거후 len(test_data)\",len(test_data))\n",
    "    \n",
    "    ## 결측치제거 : 1개라도 있으면, 해당행 전체 제거\n",
    "    #1. train_data\n",
    "    print(\"결측치 개수\",train_data.isnull().sum())\n",
    "    if train_data.isnull().any().any():\n",
    "        train_data.dropna(how='any',inplace=True)\n",
    "        print(\"결측치제거후 결측치 여부\",train_data.isnull().any().any())    \n",
    "    #2. test_data\n",
    "    print(\"결측치 개수\",test_data.isnull().sum())\n",
    "    if test_data.isnull().any().any():\n",
    "        test_data.dropna(how='any',inplace=True)\n",
    "        print(\"결측치제거후 결측치 여부\",test_data.isnull().any().any())\n",
    "    \n",
    "    ## 데이터 정제 \n",
    "    # 한글과 숫자,공백(한개이상 공백은 한개로 축소),특수문자일부 !?,.^을 제외하고 제거:[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\n",
    "    # --> 한글형태소기를 tokenizer로 쓸 경우에는 영어및 일부선택된 특수문자외에는 모두제거(..., - - 등도 제거)\n",
    "    #1. train_data\n",
    "    train_data['document'] = train_data['document'].str.replace(\"[' ']+\",\" \")\n",
    "    train_data['document'] = train_data['document'].str.replace(\"\\.{2,30}\",\" \") \n",
    "    train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n",
    "    #train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  #한글영어병행형태소기인경우 영어포함                                                         \n",
    "    print(\"한글과 공백,기타일부 등제외후 모두제거상태_train_data.head()\",train_data.head())\n",
    "    #2. test_data\n",
    "    test_data['document' ]= test_data['document'].str.replace(\"[' ']+\",\" \")\n",
    "    test_data['document'] = test_data['document'].str.replace(\"\\.{2,30}\",\" \") \n",
    "    test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n",
    "    #test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  #한글영어병행형태소기인경우 영어포함                                                            \n",
    "    print(\"한글과 공백,기타일부 등제외후 모두제거상태_test_data.head()\",test_data.head())\n",
    "    # 데이터 정제후 빈 공백만 있는 문장의 경우 제거:  Nan 입력후 행제거\n",
    "    #1. train_data\n",
    "    train_data['document'].replace('', np.nan, inplace=True)\n",
    "    print(\"Nan 존재유뮤\",train_data.isnull().any().any() )\n",
    "    if train_data.isnull().any().any():\n",
    "        train_data.dropna(how='any',inplace=True)\n",
    "    #2. test_data   \n",
    "    test_data['document'].replace('', np.nan, inplace=True)\n",
    "    print(\"Nan 존재유뮤\",test_data.isnull().any().any() )\n",
    "    if test_data.isnull().any().any():\n",
    "        test_data.dropna(how='any',inplace=True)\n",
    "    \n",
    "    ## 한국어 토크나이저로 토큰화    \n",
    "    # 1. train_data\n",
    "    X_train = []\n",
    "    for sentence in tqdm.tqdm(train_data['document']):\n",
    "        tokenized = tokenizer.morphs(sentence) # morphs 형태소추출\n",
    "        #print(\"tokenized\", tokenized)\n",
    "        tokenized_without_stopwords = [word for word in tokenized if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(tokenized_without_stopwords)\n",
    "    print(\"X_train\",X_train[:5],len(X_train))\n",
    "    \n",
    "    # 2. test_data\n",
    "    X_test = []\n",
    "    for sentence in tqdm.tqdm(test_data['document']):\n",
    "        tokenized = tokenizer.morphs(sentence) # morphs 형태소추출\n",
    "        #print(\"tokenized\", tokenized)\n",
    "        tokenized_without_stopwords = [word for word in tokenized if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(tokenized_without_stopwords)\n",
    "    print(\"X_test\",X_test[:5],len(X_test))\n",
    "    \n",
    "    ## word_to_index 구성: train only ???  train + test ??? 로 word vs index 매칭 ??? !!!!!!!!!!!!\n",
    "    words = np.concatenate(X_train).tolist()  \n",
    "    #words = np.concatenate(X_train).tolist() + np.concatenate(X_test).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(num_words-4)   #10000-4)\n",
    "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "    \n",
    "    ## X_Train, X_test 를 word_to_index의 index로 mapping\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "    \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)\n",
    "\n",
    "# 인덱스로 매칭된 데이터 확인\n",
    "print(\"X_train[:5]\",X_train[:5],\"y_train[:5]\",y_train[:5],\"X_test[:5]\",X_test[:5],\"y_test[:5]\",y_test[:5])\n",
    "print('len( word_to_index)', len(word_to_index))\n",
    "\n",
    "## 인덱스를 key로 word 반환 Dict 만들기\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "\n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3e248",
   "metadata": {},
   "source": [
    "* **데이터내 문장 Max_length설정, 보정, Padding 및 train data, valid data 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f7b13a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이평균: 14.9\n",
      "문장길이표준편차: 12.27\n",
      "문장길이Max: 85\n",
      "문장길이Min: 0\n",
      "문장길이 0개수: 320\n",
      "['NanumGothic']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표준편차 +- 2범위내 데이터수: 182439 원래전체데이터대비비중: 93.51 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "적절한 최대 문장 길이 >> pad_sequences maxlen:  39\n",
      "word_to_index_앞쪽 10개 확인: [['', 3], ['.', 4], ['영화', 5], ['다', 6], ['고', 7], ['하', 8], ['을', 9], ['보', 10], [',', 11], ['게', 12]]\n",
      "len(word_to_index) 9997\n",
      "word_to_index_추가된 항목 재확인: [['금기', 9998], ['부셔', 9999], ['<BOS>', 0], ['<PAD>', 1], ['<UNK>', 2]]\n",
      "<BOS>\n",
      "3\n",
      ".\n",
      "더 빙 진짜 짜증 나 네요 목소리\n",
      "라벨:  0\n",
      "8\n",
      "<BOS>\n",
      "보정완료 OK\n",
      "len(word_to_index): 10000\n",
      "X_train [[31, 70, 869, 38, 223, 19, 32, 723], [994, 503, 535, 662, 5, 117, 1591, 52, 894, 975, 14, 43, 376], [23, 201, 3]] 146026 <class 'int'>\n",
      "X_train 내의 인덱스 type확인: float 0 int 2176140 str 0 etc 0 총개수 2176140\n",
      "X_train: (146026, 39)\n",
      "X_test: (49084, 39)\n",
      "X_train 총개수: 146026 80%분리:  116820 20%분리: 29206\n",
      "partial_X_train 116820 partial_y_train 116820\n",
      "X_val 29206 y_val 29206\n"
     ]
    }
   ],
   "source": [
    "#3. 모델 구성을 위한 데이터 분석 및 가공\n",
    "#(1) 데이터셋 내 문장 길이 분포\n",
    "\n",
    "## 데이터셋 내 문장 길이 분포\n",
    "total_data_text = list(X_train) + list(X_test)\n",
    "total_data_text_dist = [len(x) for x in total_data_text]\n",
    "#print(total_data_text_dist)\n",
    "\n",
    "mean = round(np.mean(total_data_text_dist),2)\n",
    "std = round(np.std(total_data_text_dist),2)\n",
    "max = np.max(total_data_text_dist)\n",
    "min = np.min(total_data_text_dist)\n",
    "min_count = len([x for x in total_data_text_dist if x == 0])\n",
    "print(\"문장길이평균:\",mean)\n",
    "print(\"문장길이표준편차:\",std)\n",
    "print(\"문장길이Max:\",max)\n",
    "print(\"문장길이Min:\",min)\n",
    "print(\"문장길이 0개수:\", min_count)\n",
    "\n",
    "# 히스토그램 시각화: total_data\n",
    "print(plt.rcParams['font.family'])\n",
    "plt.rc('font',family='NanumGothic')\n",
    "plt.hist(total_data_text_dist, bins = 20)\n",
    "plt.xlabel('한문장당 길이')\n",
    "plt.ylabel('데이터 개수')\n",
    "plt.show()\n",
    "\n",
    "# 박스플롯: total_data\n",
    "plt.boxplot(total_data_text_dist)\n",
    "plt.show()\n",
    "\n",
    "#(2) 적절한 최대 문장 길이 지정: 39\n",
    "\n",
    "## 적절한 최대 문장 길이 지정: (평균 + 표준편차*2)이내\n",
    "total_data_text_dist_array = np.array(total_data_text_dist)\n",
    "total_data_text_within_2std = total_data_text_dist_array[(total_data_text_dist_array <= mean + std*2) & (total_data_text_dist_array >= mean - std*2)]\n",
    "print(\"표준편차 +- 2범위내 데이터수:\", len(total_data_text_within_2std),\n",
    "      \"원래전체데이터대비비중:\",round(len(total_data_text_within_2std)*100/len(total_data_text),2),\"%\")\n",
    "\n",
    "# 히스토그램 시각화: total_data_text_within_2std\n",
    "plt.hist(total_data_text_within_2std, bins = 20)\n",
    "plt.xlabel('한문장당 길이')\n",
    "plt.ylabel('데이터 개수')\n",
    "plt.show()\n",
    "\n",
    "max_length = int(mean + std*2)\n",
    "print(\"적절한 최대 문장 길이 >> pad_sequences maxlen: \",int(max_length))\n",
    "\n",
    "    \n",
    "## 보정 및 최대길이에 맞추어 Padding\n",
    "\n",
    "#(3) word_to_index 및 index_to_word 보정: 앞쪽 위치 0,1,2번에 3개 항목 입력\n",
    "\n",
    "# word_to_index의 첫 인덱스위치에 '<BOS>' 있는지 확인\n",
    "print(\"word_to_index_앞쪽 10개 확인:\",[[key,value] for key,value in word_to_index.items()][:10] )\n",
    "print(\"len(word_to_index)\",len(word_to_index))   # 3개가 비어있슴\n",
    "\n",
    "# <BOS>, <PAD>,  <UNK> 3항목에 인덱스 0,1,2  보정값 입력\n",
    "word_to_index[\"<BOS>\"] = int(0)\n",
    "word_to_index[\"<PAD>\"] = int(1)\n",
    "word_to_index[\"<UNK>\"] = int(2)  # unknown\n",
    "print(\"word_to_index_추가된 항목 재확인:\",[[key,value] for key,value in word_to_index.items()][-5:] )\n",
    "\n",
    "# index_to_word 도 보정\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[0])     # '<BOS>' 가 출력\n",
    "print(word_to_index[''])  # 3 이 출력\n",
    "print(index_to_word[4])     # '.' 가 출력\n",
    "\n",
    "# 보정 후 x_train[0] 데이터 확인: \n",
    "print(get_decoded_sentence(X_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print(len(X_train[0]))\n",
    "print(index_to_word[y_train[0]])\n",
    "print(\"보정완료 OK\")\n",
    "\n",
    "#(4) keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가\n",
    "\n",
    "### keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가 및 max_length로 일정길이 맞춤\n",
    "print(\"len(word_to_index):\",len(word_to_index))\n",
    "print(\"X_train\", X_train[:3], len(X_train), type(X_train[0][0]))\n",
    "\n",
    "# type 확인: train 내의 word index의 type check: 모두 int 임, 총개수 2,176,140개\n",
    "floatlist = [];intlist = [];strlist = [];etclist = []\n",
    "for X in X_train:\n",
    "    for idx in X:\n",
    "        if type(idx) == float:\n",
    "            floatlist.append(idx)            \n",
    "        elif type(idx) == int:\n",
    "            intlist.append(idx)  \n",
    "        elif type(idx) == str:\n",
    "            strlist.append(idx)   \n",
    "        else:\n",
    "            etclist.append(idx)\n",
    "print(\"X_train 내의 인덱스 type확인:\",\"float\",len(floatlist),\"int\",len(intlist),\"str\",len(strlist),\n",
    "       \"etc\",len(etclist),\"총개수\", len(floatlist)+ len(intlist)+ len(strlist)+len(etclist)) # int만 총개수 2,176,140\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터를 numpy array로 변경. \n",
    "X_train = np.array(X_train, dtype='object')\n",
    "X_test = np.array(X_test, dtype='object')\n",
    "\n",
    "## padding된 데이터: padding된 곳은 1 이 입력됨\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                       value=word_to_index['<PAD>'], # <PAD> index 값 : 1\n",
    "                                                       padding='pre',           # 성능향상위해 'pre'적용\n",
    "                                                       maxlen=max_length)       # maxlen = 39\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index['<PAD>'], # <PAD> index 값 : 1\n",
    "                                                       padding='pre',           # 성능향상위해 'pre'적용\n",
    "                                                       maxlen=max_length)       # maxlen = 39\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "\n",
    "\n",
    "## train data, vaoli data 분리 : 80:20\n",
    "print(\"X_train 총개수:\", len(X_train), \"80%분리: \",int(len(X_train)*0.8), \"20%분리:\",len(X_train)-int(len(X_train)*0.8))\n",
    "train_len = int(len(X_train)*0.8)\n",
    "valid_len = len(X_train)-int(len(X_train)*0.8)\n",
    "\n",
    "# validation set 20% 분리: \n",
    "X_val = X_train[:valid_len]   \n",
    "y_val = y_train[:valid_len]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_X_train = X_train[valid_len:]  \n",
    "partial_y_train = y_train[valid_len:]\n",
    "\n",
    "print(\"partial_X_train\",len(partial_X_train),\"partial_y_train\",len(partial_y_train))\n",
    "print(\"X_val\",len(X_val), \"y_val\",len(y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82fce4c",
   "metadata": {},
   "source": [
    "* **LSTM모델구성 및  학습, 테스트**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "010e5eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 162,401\n",
      "Trainable params: 162,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "229/229 [==============================] - 3s 8ms/step - loss: 0.4879 - accuracy: 0.7704 - val_loss: 0.3583 - val_accuracy: 0.8452\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3524 - accuracy: 0.8497 - val_loss: 0.3447 - val_accuracy: 0.8493\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3299 - accuracy: 0.8611 - val_loss: 0.3462 - val_accuracy: 0.8496\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3166 - accuracy: 0.8670 - val_loss: 0.3441 - val_accuracy: 0.8493\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3049 - accuracy: 0.8724 - val_loss: 0.3509 - val_accuracy: 0.8468\n",
      "Epoch 6/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2945 - accuracy: 0.8757 - val_loss: 0.3501 - val_accuracy: 0.8507\n",
      "Epoch 7/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2846 - accuracy: 0.8799 - val_loss: 0.3504 - val_accuracy: 0.8511\n",
      "Epoch 8/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2759 - accuracy: 0.8829 - val_loss: 0.3596 - val_accuracy: 0.8502\n",
      "Epoch 9/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2675 - accuracy: 0.8863 - val_loss: 0.3671 - val_accuracy: 0.8499\n",
      "Epoch 10/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2585 - accuracy: 0.8895 - val_loss: 0.3805 - val_accuracy: 0.8496\n",
      "Epoch 11/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2516 - accuracy: 0.8936 - val_loss: 0.3848 - val_accuracy: 0.8501\n",
      "Epoch 12/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2453 - accuracy: 0.8951 - val_loss: 0.3874 - val_accuracy: 0.8505\n",
      "Epoch 13/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2376 - accuracy: 0.8987 - val_loss: 0.4050 - val_accuracy: 0.8484\n",
      "Epoch 14/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2321 - accuracy: 0.9011 - val_loss: 0.4057 - val_accuracy: 0.8483\n",
      "Epoch 15/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2278 - accuracy: 0.9038 - val_loss: 0.4269 - val_accuracy: 0.8492\n",
      "Epoch 16/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2231 - accuracy: 0.9049 - val_loss: 0.4262 - val_accuracy: 0.8501\n",
      "Epoch 17/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2166 - accuracy: 0.9081 - val_loss: 0.4349 - val_accuracy: 0.8498\n",
      "Epoch 18/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2128 - accuracy: 0.9104 - val_loss: 0.4456 - val_accuracy: 0.8492\n",
      "Epoch 19/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2091 - accuracy: 0.9122 - val_loss: 0.4441 - val_accuracy: 0.8483\n",
      "Epoch 20/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2049 - accuracy: 0.9141 - val_loss: 0.4651 - val_accuracy: 0.8485\n",
      "  \n",
      "test data 로 LSTM 모델 성능평가 ------------------------------------------------------------------------------------------\n",
      "1534/1534 - 3s - loss: 0.4622 - accuracy: 0.8455\n",
      "results_lstm [0.46219396591186523, 0.845530092716217]\n"
     ]
    }
   ],
   "source": [
    "#4. 모델 구성 및 validation set 구성\n",
    "\n",
    "## Hyper param 설정\n",
    "vocab_size = len(word_to_index)   # 어휘 사전의 크기(10,000개의 단어)\n",
    "\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수\n",
    "hidden_unit = 16\n",
    "drop_rate = 0.2\n",
    "epochs= 20 \n",
    "\n",
    "## Hyper param 설정\n",
    "vocab_size = len(word_to_index)   # 어휘 사전의 크기(10,000개의 단어)\n",
    "\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수\n",
    "hidden_unit = 16\n",
    "drop_rate = 0.2\n",
    "cnn_dense_hidden_unit = 8\n",
    "cnn_filter = 7\n",
    "cnn_maxpool = 4\n",
    "epochs= 20 \n",
    "\n",
    "#(1) LSTM 모델\n",
    "## LSTM 모델\n",
    "\n",
    "model_lstm = tf.keras.Sequential()\n",
    "model_lstm.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model_lstm.add(tf.keras.layers.LSTM(hidden_unit)) \n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model_lstm.add(tf.keras.layers.Dense(hidden_unit, activation='relu'))\n",
    "model_lstm.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model_lstm.summary()\n",
    "\n",
    "## LSTM모델구성 및  학습\n",
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "history_lstm = model_lstm.fit(partial_X_train, partial_y_train, epochs=epochs, batch_size=512, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "## test data 로 LSTM 모델 성능평가\n",
    "## LSTM 모델 성능평가\n",
    "\n",
    "print(\"  \")\n",
    "print(\"test data 로 LSTM 모델 성능평가\", \"---\"*30)\n",
    "results_lstm = model_lstm.evaluate(X_test,  y_test, verbose=2)\n",
    "print(\"results_lstm\", results_lstm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50d9cce",
   "metadata": {},
   "source": [
    "#### [평가] Mecab의 경우 LSTM test accuracy 84.55% 였슴(SentencePiece 84.32% 보다 큰차이는 아니나 더 우수함) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae81cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44c040cd",
   "metadata": {},
   "source": [
    "####  (3) Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab226f",
   "metadata": {},
   "source": [
    "* **데이터 전처리,형태소분석,Tokenizer 함수생성 및 word_to_index, index_to_word 관련 함수생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e52d6f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data          id                                           document  label\n",
      "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
      "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
      "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
      "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
      "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1 (150000, 3)\n",
      "------------------------------------------------------------\n",
      "test_data         id                                           document  label\n",
      "0  6270596                                                굳 ㅋ      1\n",
      "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
      "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
      "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
      "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0 (50000, 3)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 읽어봅시다. \n",
    "train_data = pd.read_table(r'~/aiffel/sp_tokenizer/ratings_train.txt')\n",
    "test_data = pd.read_table('~/aiffel/sp_tokenizer/ratings_test.txt')\n",
    "\n",
    "print(\"train_data\",train_data.head(),train_data.shape)\n",
    "print('-'*60)\n",
    "print(\"test_data\",test_data.head(),test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9100ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data['document'].nunique() 146182\n",
      "train_data['label'].nunique() 2\n",
      "중복제거후 len(train_data) 146183\n",
      "test_data['document'].nunique() 49157\n",
      "test_data['label'].nunique() 2\n",
      "중복제거후 len(test_data) 49158\n",
      "결측치 개수 id          0\n",
      "document    1\n",
      "label       0\n",
      "dtype: int64\n",
      "결측치제거후 결측치 여부 False\n",
      "결측치 개수 id          0\n",
      "document    1\n",
      "label       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3107/2495083662.py:37: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[' ']+\",\" \")\n",
      "/tmp/ipykernel_3107/2495083662.py:38: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"\\.{2,30}\",\" \")\n",
      "/tmp/ipykernel_3107/2495083662.py:39: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치제거후 결측치 여부 False\n",
      "한글과 공백,기타일부 등제외후 모두제거상태_train_data.head()          id                                           document  label\n",
      "0   9976970                                 아 더빙  진짜 짜증나네요 목소리      0\n",
      "1   3819312                       흠 포스터보고 초딩영화줄 오버연기조차 가볍지 않구나      1\n",
      "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
      "3   9045019                        교도소 이야기구먼  솔직히 재미는 없다 평점 조정      0\n",
      "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3107/2495083662.py:43: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document' ]= test_data['document'].str.replace(\"[' ']+\",\" \")\n",
      "/tmp/ipykernel_3107/2495083662.py:44: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"\\.{2,30}\",\" \")\n",
      "/tmp/ipykernel_3107/2495083662.py:45: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글과 공백,기타일부 등제외후 모두제거상태_test_data.head()         id                                        document  label\n",
      "0  6270596                                             굳 ㅋ      1\n",
      "1  9274899                                                      0\n",
      "2  8544678             뭐야 이 평점들은  나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
      "3  6825595                     지루하지는 않은데 완전 막장임  돈주고 보기에는       0\n",
      "4  6723715  3만 아니었어도 별 다섯 개 줬을텐데  왜 3로 나와서 제 심기를 불편하게 하죠??      0\n",
      "Nan 존재유뮤 True\n",
      "Nan 존재유뮤 True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146026/146026 [04:37<00:00, 526.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train [['아', '더빙', '진짜', '짜증나네요', '목소리'], ['흠', '포스터', '보고', '초딩', '영화', '줄', '오버', '연기', '조차', '가볍지', '않구나'], ['너', '무재', '밓었', '다그', '래서', '보는것을', '추천', '다'], ['교도소', '이야기', '구먼', '솔직히', '재미', '없다', '평점', '조정'], ['사이', '몬페', '그', '익살스런', '연기', '돋보였던', '영화', '!', '스파이더맨', '에서', '늙어', '보이기만', '했던', '커스틴', '던스트', '너무나도', '이뻐', '보였다']] 146026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 49084/49084 [01:29<00:00, 548.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test [['굳', 'ㅋ'], ['뭐', '야', '평점', '나쁘진', '않지만', '10', '점', '짜', '리', '더', '더욱', '아니잖아'], ['지루하지는', '않은데', '완전', '막장', '임', '돈', '주고', '보기', '에는'], ['3만', '아니었어도', '별', '다섯', '개', '줬을텐데', '왜', '3', '로', '나와서', '제', '심기', '불편하게', '하죠', '??'], ['음악', '주가', '된', ',', '최고', '음악', '영화']] 49084\n",
      "X_train[:5] [[46, 435, 15, 6959, 649], [908, 436, 40, 597, 5, 197, 1558, 19, 965, 6130, 3], [376, 2870, 3, 6515, 8077, 3, 201, 10], [8742, 103, 3, 218, 56, 72, 21, 4411], [1055, 3, 24, 3, 19, 6516, 5, 12, 3065, 18, 5380, 3, 461, 3, 3, 1107, 3810, 4512]] y_train[:5] [0 1 0 0 1] X_test[:5] [[792, 80], [58, 154, 21, 4739, 1443, 69, 16, 1064, 880, 44, 778, 3696], [3, 2484, 85, 325, 107, 101, 378, 143, 252], [3, 3, 118, 2587, 98, 9936, 32, 99, 17, 605, 179, 3, 3, 6083, 165], [191, 3490, 140, 7, 23, 191, 5]] y_test[:5] [1 0 0 0 1]\n",
      "len( word_to_index) 9997\n"
     ]
    }
   ],
   "source": [
    "## 데이터로더\n",
    "tokenizer = Okt()\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']\n",
    "num_words=10000\n",
    "\n",
    "def load_data(train_data, test_data, num_words=num_words):\n",
    "    ## 중복값 제거:  'document'컬럼의 중복값 제거,'label'컬럼은 0,1의 두개면 맞음\n",
    "    #1. train_data\n",
    "    print(\"train_data['document'].nunique()\",train_data['document'].nunique())\n",
    "    if train_data['document'].nunique() < len(train_data):\n",
    "        train_data.drop_duplicates(subset=['document'], inplace=True) \n",
    "        print(\"train_data['label'].nunique()\",train_data['label'].nunique())    \n",
    "        print(\"중복제거후 len(train_data)\",len(train_data))    \n",
    "    #2. test_data    \n",
    "    print(\"test_data['document'].nunique()\",test_data['document'].nunique())\n",
    "    if test_data['document'].nunique() < len(test_data):\n",
    "        test_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "        print(\"test_data['label'].nunique()\",test_data['label'].nunique())    \n",
    "        print(\"중복제거후 len(test_data)\",len(test_data))\n",
    "    \n",
    "    ## 결측치제거 : 1개라도 있으면, 해당행 전체 제거\n",
    "    #1. train_data\n",
    "    print(\"결측치 개수\",train_data.isnull().sum())\n",
    "    if train_data.isnull().any().any():\n",
    "        train_data.dropna(how='any',inplace=True)\n",
    "        print(\"결측치제거후 결측치 여부\",train_data.isnull().any().any())    \n",
    "    #2. test_data\n",
    "    print(\"결측치 개수\",test_data.isnull().sum())\n",
    "    if test_data.isnull().any().any():\n",
    "        test_data.dropna(how='any',inplace=True)\n",
    "        print(\"결측치제거후 결측치 여부\",test_data.isnull().any().any())\n",
    "    \n",
    "    ## 데이터 정제 \n",
    "    # 한글과 숫자,공백(한개이상 공백은 한개로 축소),특수문자일부 !?,.^을 제외하고 제거:[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\n",
    "    # --> 한글형태소기를 tokenizer로 쓸 경우에는 영어및 일부선택된 특수문자외에는 모두제거(..., - - 등도 제거)\n",
    "    #1. train_data\n",
    "    train_data['document'] = train_data['document'].str.replace(\"[' ']+\",\" \")\n",
    "    train_data['document'] = train_data['document'].str.replace(\"\\.{2,30}\",\" \") \n",
    "    train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n",
    "    #train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  #한글영어병행형태소기인경우 영어포함                                                         \n",
    "    print(\"한글과 공백,기타일부 등제외후 모두제거상태_train_data.head()\",train_data.head())\n",
    "    #2. test_data\n",
    "    test_data['document' ]= test_data['document'].str.replace(\"[' ']+\",\" \")\n",
    "    test_data['document'] = test_data['document'].str.replace(\"\\.{2,30}\",\" \") \n",
    "    test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n",
    "    #test_data['document'] = test_data['document'].str.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  #한글영어병행형태소기인경우 영어포함                                                            \n",
    "    print(\"한글과 공백,기타일부 등제외후 모두제거상태_test_data.head()\",test_data.head())\n",
    "    # 데이터 정제후 빈 공백만 있는 문장의 경우 제거:  Nan 입력후 행제거\n",
    "    #1. train_data\n",
    "    train_data['document'].replace('', np.nan, inplace=True)\n",
    "    print(\"Nan 존재유뮤\",train_data.isnull().any().any() )\n",
    "    if train_data.isnull().any().any():\n",
    "        train_data.dropna(how='any',inplace=True)\n",
    "    #2. test_data   \n",
    "    test_data['document'].replace('', np.nan, inplace=True)\n",
    "    print(\"Nan 존재유뮤\",test_data.isnull().any().any() )\n",
    "    if test_data.isnull().any().any():\n",
    "        test_data.dropna(how='any',inplace=True)\n",
    "    \n",
    "    ## 한국어 토크나이저로 토큰화    \n",
    "    # 1. train_data\n",
    "    X_train = []\n",
    "    for sentence in tqdm.tqdm(train_data['document']):\n",
    "        tokenized = tokenizer.morphs(sentence) # morphs 형태소추출\n",
    "        #print(\"tokenized\", tokenized)\n",
    "        tokenized_without_stopwords = [word for word in tokenized if not word in stopwords] # 불용어 제거\n",
    "        X_train.append(tokenized_without_stopwords)\n",
    "    print(\"X_train\",X_train[:5],len(X_train))\n",
    "    \n",
    "    # 2. test_data\n",
    "    X_test = []\n",
    "    for sentence in tqdm.tqdm(test_data['document']):\n",
    "        tokenized = tokenizer.morphs(sentence) # morphs 형태소추출\n",
    "        #print(\"tokenized\", tokenized)\n",
    "        tokenized_without_stopwords = [word for word in tokenized if not word in stopwords] # 불용어 제거\n",
    "        X_test.append(tokenized_without_stopwords)\n",
    "    print(\"X_test\",X_test[:5],len(X_test))\n",
    "    \n",
    "    ## word_to_index 구성: train only ???  train + test ??? 로 word vs index 매칭 ??? !!!!!!!!!!!!\n",
    "    words = np.concatenate(X_train).tolist()  \n",
    "    #words = np.concatenate(X_train).tolist() + np.concatenate(X_test).tolist()\n",
    "    counter = Counter(words)\n",
    "    counter = counter.most_common(num_words-4)   #10000-4)\n",
    "    vocab = ['', '', '', ''] + [key for key, _ in counter]\n",
    "    word_to_index = {word:index for index, word in enumerate(vocab)}\n",
    "    \n",
    "    ## X_Train, X_test 를 word_to_index의 index로 mapping\n",
    "    def wordlist_to_indexlist(wordlist):\n",
    "        return [word_to_index[word] if word in word_to_index else word_to_index[''] for word in wordlist]\n",
    "        \n",
    "    X_train = list(map(wordlist_to_indexlist, X_train))\n",
    "    X_test = list(map(wordlist_to_indexlist, X_test))\n",
    "    \n",
    "    return X_train, np.array(list(train_data['label'])), X_test, np.array(list(test_data['label'])), word_to_index\n",
    "    \n",
    "X_train, y_train, X_test, y_test, word_to_index = load_data(train_data, test_data)\n",
    "\n",
    "# 인덱스로 매칭된 데이터 확인\n",
    "print(\"X_train[:5]\",X_train[:5],\"y_train[:5]\",y_train[:5],\"X_test[:5]\",X_test[:5],\"y_test[:5]\",y_test[:5])\n",
    "print('len( word_to_index)', len(word_to_index))\n",
    "\n",
    "## 인덱스를 key로 word 반환 Dict 만들기\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트 벡터로 변환해 주는 함수입니다. \n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "\n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "# 여러 개의 문장 리스트를 한꺼번에 단어 인덱스 리스트 벡터로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ab0d56",
   "metadata": {},
   "source": [
    "* **데이터내 문장 Max_length설정, 보정, Padding 및 train data, valid data 분리**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7eaa7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이평균: 12.16\n",
      "문장길이표준편차: 10.08\n",
      "문장길이Max: 79\n",
      "문장길이Min: 0\n",
      "문장길이 0개수: 318\n",
      "['NanumGothic']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표준편차 +- 2범위내 데이터수: 182661 원래전체데이터대비비중: 93.62 %\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "적절한 최대 문장 길이 >> pad_sequences maxlen:  32\n",
      "word_to_index_앞쪽 10개 확인: [['', 3], ['.', 4], ['영화', 5], ['을', 6], [',', 7], ['?', 8], ['너무', 9], ['다', 10], ['정말', 11], ['!', 12]]\n",
      "len(word_to_index) 9997\n",
      "word_to_index_추가된 항목 재확인: [['예뻤다', 9998], ['배달', 9999], ['<BOS>', 0], ['<PAD>', 1], ['<UNK>', 2]]\n",
      "<BOS>\n",
      "3\n",
      ".\n",
      "더빙 진짜 짜증나네요 목소리\n",
      "라벨:  0\n",
      "5\n",
      "<BOS>\n",
      "보정완료 OK\n",
      "len(word_to_index): 10000\n",
      "X_train [[46, 435, 15, 6959, 649], [908, 436, 40, 597, 5, 197, 1558, 19, 965, 6130, 3], [376, 2870, 3, 6515, 8077, 3, 201, 10]] 146026 <class 'int'>\n",
      "X_train 내의 인덱스 type확인: float 0 int 1777541 str 0 etc 0 총개수 1777541\n",
      "X_train: (146026, 32)\n",
      "X_test: (49084, 32)\n",
      "X_train 총개수: 146026 80%분리:  116820 20%분리: 29206\n",
      "partial_X_train 116820 partial_y_train 116820\n",
      "X_val 29206 y_val 29206\n"
     ]
    }
   ],
   "source": [
    "#3. 모델 구성을 위한 데이터 분석 및 가공\n",
    "#(1) 데이터셋 내 문장 길이 분포\n",
    "\n",
    "## 데이터셋 내 문장 길이 분포\n",
    "total_data_text = list(X_train) + list(X_test)\n",
    "total_data_text_dist = [len(x) for x in total_data_text]\n",
    "#print(total_data_text_dist)\n",
    "\n",
    "mean = round(np.mean(total_data_text_dist),2)\n",
    "std = round(np.std(total_data_text_dist),2)\n",
    "max = np.max(total_data_text_dist)\n",
    "min = np.min(total_data_text_dist)\n",
    "min_count = len([x for x in total_data_text_dist if x == 0])\n",
    "print(\"문장길이평균:\",mean)\n",
    "print(\"문장길이표준편차:\",std)\n",
    "print(\"문장길이Max:\",max)\n",
    "print(\"문장길이Min:\",min)\n",
    "print(\"문장길이 0개수:\", min_count)\n",
    "\n",
    "# 히스토그램 시각화: total_data\n",
    "print(plt.rcParams['font.family'])\n",
    "plt.rc('font',family='NanumGothic')\n",
    "plt.hist(total_data_text_dist, bins = 20)\n",
    "plt.xlabel('한문장당 길이')\n",
    "plt.ylabel('데이터 개수')\n",
    "plt.show()\n",
    "\n",
    "# 박스플롯: total_data\n",
    "plt.boxplot(total_data_text_dist)\n",
    "plt.show()\n",
    "\n",
    "#(2) 적절한 최대 문장 길이 지정: 39\n",
    "\n",
    "## 적절한 최대 문장 길이 지정: (평균 + 표준편차*2)이내\n",
    "total_data_text_dist_array = np.array(total_data_text_dist)\n",
    "total_data_text_within_2std = total_data_text_dist_array[(total_data_text_dist_array <= mean + std*2) & (total_data_text_dist_array >= mean - std*2)]\n",
    "print(\"표준편차 +- 2범위내 데이터수:\", len(total_data_text_within_2std),\n",
    "      \"원래전체데이터대비비중:\",round(len(total_data_text_within_2std)*100/len(total_data_text),2),\"%\")\n",
    "\n",
    "# 히스토그램 시각화: total_data_text_within_2std\n",
    "plt.hist(total_data_text_within_2std, bins = 20)\n",
    "plt.xlabel('한문장당 길이')\n",
    "plt.ylabel('데이터 개수')\n",
    "plt.show()\n",
    "\n",
    "max_length = int(mean + std*2)\n",
    "print(\"적절한 최대 문장 길이 >> pad_sequences maxlen: \",int(max_length))\n",
    "\n",
    "    \n",
    "## 보정 및 최대길이에 맞추어 Padding\n",
    "\n",
    "#(3) word_to_index 및 index_to_word 보정: 앞쪽 위치 0,1,2번에 3개 항목 입력\n",
    "\n",
    "# word_to_index의 첫 인덱스위치에 '<BOS>' 있는지 확인\n",
    "print(\"word_to_index_앞쪽 10개 확인:\",[[key,value] for key,value in word_to_index.items()][:10] )\n",
    "print(\"len(word_to_index)\",len(word_to_index))   # 3개가 비어있슴\n",
    "\n",
    "# <BOS>, <PAD>,  <UNK> 3항목에 인덱스 0,1,2  보정값 입력\n",
    "word_to_index[\"<BOS>\"] = int(0)\n",
    "word_to_index[\"<PAD>\"] = int(1)\n",
    "word_to_index[\"<UNK>\"] = int(2)  # unknown\n",
    "print(\"word_to_index_추가된 항목 재확인:\",[[key,value] for key,value in word_to_index.items()][-5:] )\n",
    "\n",
    "# index_to_word 도 보정\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[0])     # '<BOS>' 가 출력\n",
    "print(word_to_index[''])  # 3 이 출력\n",
    "print(index_to_word[4])     # '.' 가 출력\n",
    "\n",
    "# 보정 후 x_train[0] 데이터 확인: \n",
    "print(get_decoded_sentence(X_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print(len(X_train[0]))\n",
    "print(index_to_word[y_train[0]])\n",
    "print(\"보정완료 OK\")\n",
    "\n",
    "#(4) keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가\n",
    "\n",
    "### keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가 및 max_length로 일정길이 맞춤\n",
    "print(\"len(word_to_index):\",len(word_to_index))\n",
    "print(\"X_train\", X_train[:3], len(X_train), type(X_train[0][0]))\n",
    "\n",
    "# type 확인: train 내의 word index의 type check: 모두 int 임, 총개수 2,176,140개\n",
    "floatlist = [];intlist = [];strlist = [];etclist = []\n",
    "for X in X_train:\n",
    "    for idx in X:\n",
    "        if type(idx) == float:\n",
    "            floatlist.append(idx)            \n",
    "        elif type(idx) == int:\n",
    "            intlist.append(idx)  \n",
    "        elif type(idx) == str:\n",
    "            strlist.append(idx)   \n",
    "        else:\n",
    "            etclist.append(idx)\n",
    "print(\"X_train 내의 인덱스 type확인:\",\"float\",len(floatlist),\"int\",len(intlist),\"str\",len(strlist),\n",
    "       \"etc\",len(etclist),\"총개수\", len(floatlist)+ len(intlist)+ len(strlist)+len(etclist)) # int만 총개수 2,176,140\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터를 numpy array로 변경. \n",
    "X_train = np.array(X_train, dtype='object')\n",
    "X_test = np.array(X_test, dtype='object')\n",
    "\n",
    "## padding된 데이터: padding된 곳은 1 이 입력됨\n",
    "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train,\n",
    "                                                       value=word_to_index['<PAD>'], # <PAD> index 값 : 1\n",
    "                                                       padding='pre',           # 성능향상위해 'pre'적용\n",
    "                                                       maxlen=max_length)       # maxlen = 39\n",
    "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test,\n",
    "                                                       value=word_to_index['<PAD>'], # <PAD> index 값 : 1\n",
    "                                                       padding='pre',           # 성능향상위해 'pre'적용\n",
    "                                                       maxlen=max_length)       # maxlen = 39\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)\n",
    "\n",
    "\n",
    "## train data, vaoli data 분리 : 80:20\n",
    "print(\"X_train 총개수:\", len(X_train), \"80%분리: \",int(len(X_train)*0.8), \"20%분리:\",len(X_train)-int(len(X_train)*0.8))\n",
    "train_len = int(len(X_train)*0.8)\n",
    "valid_len = len(X_train)-int(len(X_train)*0.8)\n",
    "\n",
    "# validation set 20% 분리: \n",
    "X_val = X_train[:valid_len]   \n",
    "y_val = y_train[:valid_len]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_X_train = X_train[valid_len:]  \n",
    "partial_y_train = y_train[valid_len:]\n",
    "\n",
    "print(\"partial_X_train\",len(partial_X_train),\"partial_y_train\",len(partial_y_train))\n",
    "print(\"X_val\",len(X_val), \"y_val\",len(y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156f0dce",
   "metadata": {},
   "source": [
    "#### LSTM모델구성 및 학습, 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a551cd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 162,401\n",
      "Trainable params: 162,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "229/229 [==============================] - 3s 7ms/step - loss: 0.5132 - accuracy: 0.7435 - val_loss: 0.3623 - val_accuracy: 0.8406\n",
      "Epoch 2/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.3472 - accuracy: 0.8507 - val_loss: 0.3434 - val_accuracy: 0.8478\n",
      "Epoch 3/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3247 - accuracy: 0.8624 - val_loss: 0.3420 - val_accuracy: 0.8480\n",
      "Epoch 4/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.3132 - accuracy: 0.8686 - val_loss: 0.3425 - val_accuracy: 0.8469\n",
      "Epoch 5/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.3058 - accuracy: 0.8713 - val_loss: 0.3445 - val_accuracy: 0.8472\n",
      "Epoch 6/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2973 - accuracy: 0.8757 - val_loss: 0.3448 - val_accuracy: 0.8465\n",
      "Epoch 7/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2889 - accuracy: 0.8797 - val_loss: 0.3468 - val_accuracy: 0.8468\n",
      "Epoch 8/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2790 - accuracy: 0.8834 - val_loss: 0.3480 - val_accuracy: 0.8473\n",
      "Epoch 9/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2706 - accuracy: 0.8867 - val_loss: 0.3502 - val_accuracy: 0.8486\n",
      "Epoch 10/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2632 - accuracy: 0.8893 - val_loss: 0.3640 - val_accuracy: 0.8488\n",
      "Epoch 11/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2541 - accuracy: 0.8937 - val_loss: 0.3685 - val_accuracy: 0.8461\n",
      "Epoch 12/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2469 - accuracy: 0.8967 - val_loss: 0.3741 - val_accuracy: 0.8455\n",
      "Epoch 13/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2401 - accuracy: 0.8990 - val_loss: 0.3817 - val_accuracy: 0.8436\n",
      "Epoch 14/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2341 - accuracy: 0.9013 - val_loss: 0.3873 - val_accuracy: 0.8427\n",
      "Epoch 15/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2285 - accuracy: 0.9042 - val_loss: 0.4103 - val_accuracy: 0.8429\n",
      "Epoch 16/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2248 - accuracy: 0.9054 - val_loss: 0.4129 - val_accuracy: 0.8425\n",
      "Epoch 17/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2200 - accuracy: 0.9073 - val_loss: 0.4234 - val_accuracy: 0.8414\n",
      "Epoch 18/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2146 - accuracy: 0.9098 - val_loss: 0.4433 - val_accuracy: 0.8407\n",
      "Epoch 19/20\n",
      "229/229 [==============================] - 1s 5ms/step - loss: 0.2127 - accuracy: 0.9101 - val_loss: 0.4342 - val_accuracy: 0.8397\n",
      "Epoch 20/20\n",
      "229/229 [==============================] - 1s 6ms/step - loss: 0.2077 - accuracy: 0.9122 - val_loss: 0.4488 - val_accuracy: 0.8384\n",
      "  \n",
      "test data 로 LSTM 모델 성능평가 ------------------------------------------------------------------------------------------\n",
      "1534/1534 - 3s - loss: 0.4611 - accuracy: 0.8327\n",
      "results_lstm [0.46106794476509094, 0.8327357172966003]\n"
     ]
    }
   ],
   "source": [
    "#4. 모델 구성 및 validation set 구성\n",
    "\n",
    "## Hyper param 설정\n",
    "vocab_size = len(word_to_index)   # 어휘 사전의 크기(10,000개의 단어)\n",
    "\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수\n",
    "hidden_unit = 16\n",
    "drop_rate = 0.2\n",
    "cnn_dense_hidden_unit = 8\n",
    "cnn_filter = 7\n",
    "cnn_maxpool = 4\n",
    "epochs= 20 \n",
    "\n",
    "## Hyper param 설정\n",
    "vocab_size = len(word_to_index)   # 어휘 사전의 크기(10,000개의 단어)\n",
    "\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수\n",
    "hidden_unit = 16\n",
    "drop_rate = 0.2\n",
    "cnn_dense_hidden_unit = 8\n",
    "cnn_filter = 7\n",
    "cnn_maxpool = 4\n",
    "epochs= 20 \n",
    "\n",
    "#(1) LSTM 모델\n",
    "## LSTM 모델\n",
    "\n",
    "model_lstm = tf.keras.Sequential()\n",
    "model_lstm.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model_lstm.add(tf.keras.layers.LSTM(hidden_unit)) \n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model_lstm.add(tf.keras.layers.Dense(hidden_unit, activation='relu'))\n",
    "model_lstm.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model_lstm.summary()\n",
    "\n",
    "## LSTM모델구성 및  학습\n",
    "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "history_lstm = model_lstm.fit(partial_X_train, partial_y_train, epochs=epochs, batch_size=512, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "## test data 로 LSTM 모델 성능평가\n",
    "## LSTM 모델 성능평가\n",
    "\n",
    "print(\"  \")\n",
    "print(\"test data 로 LSTM 모델 성능평가\", \"---\"*30)\n",
    "results_lstm = model_lstm.evaluate(X_test,  y_test, verbose=2)\n",
    "print(\"results_lstm\", results_lstm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbae07f",
   "metadata": {},
   "source": [
    "* **[평가] Okt 의 경우 LSTM test accuracy 83.27% 였슴(Mecab 84.55% 및 Unigram SentencePiece 84.32% 보다 낮음)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95f1ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dac0018",
   "metadata": {},
   "source": [
    "## 4. 종합비교\n",
    "\n",
    "* 데이터 전처리 관련 공통사항: \n",
    "SentencePiece 는 전처리가 필요없다고 dkffuwu dlTsmsep, 중복문장제거가 필요하였고, 결측치 처리가 않될 경우 오유가 발생하는등 기본적인 전처리가 필요하du,, Konlpy의 Mecab, Okt에서 하는 전처리에서처럼, 중복문장제거, 결측치처리, 구두점및특수문자등 3가지 전처리는 공통적으로 하였슴 \n",
    "\n",
    "* 성능평가모델은 공통적으로 LSTM으로 썼으며, 모델 아키텍쳐와 손실함수, 옵티마이저, 하이퍼파람등 모두 동일하게 설정해서, 동일 기준으로 비교하였슴\n",
    "\n",
    "Okt 의 경우 LSTM test accuracy 83.27% 였슴(Mecab 84.55% 및 Unigram SentencePiece 84.32% 보다 낮음)\n",
    " \n",
    "#### (1) SetencePiece 평가\n",
    "* Unigram 모델 성능:  test accuracy 84.32%   \n",
    "* Bpe 모델 성능:  test accuracy 83.64%  (별도 깃허브 링크:  https://github.com/lkh-7/first-repository/blob/master/%5BGDeep%5D02_%5Bsp_tokenizer%5D_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_%EB%A9%8B%EC%A7%84%20%EB%8B%A8%EC%96%B4%EC%82%AC%EC%A0%84%20%EB%A7%8C%EB%93%A4%EA%B8%B0_Project_%EC%A0%9C%EC%B6%9C%EC%A4%80%EB%B9%84%EC%9A%A9_SPM_Bpe_ONLY.ipynb) \n",
    "\n",
    "* (특이점) SetencePiece 모델은 한국어에 적용할 경우 불용어처리기능이 없었는데, 성능이 좋은 편이었으며, 데이터 전처리가 필요없다고,알려진 바와 다르게, 중복문장처리, 결측치제거, 특수문자처리등 기본적인 전처리가 필요했슴\n",
    "\n",
    "* Unigram 모델이 더 우수 \n",
    "\n",
    "\n",
    "#### (2) KoNLPY 평가\n",
    "* Mecab 모델 성능:  test accuracy 84.55%   \n",
    "* Okt 모델 성능:  test accuracy 83.27%  \n",
    "\n",
    "* Mecab 모델이 더 우수\n",
    "\n",
    "#### (3) 종합평가\n",
    "* **전체중에서, Mecab 가 제일 우수**했슴, 2위는 **Unigram방식의  SetencePiece**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7810b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efaae2fe",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caeed37f",
   "metadata": {},
   "source": [
    "본 프로젝트는 LMS교재 Explore 8번에서 네이버영화리뷰 감성분석을 할때, 텍스트를 벡터화하는 단계에서, 사용해보았던 KoNLPy의 Mecab외에, 이번에 새롭게 배운 SentencePiece를 적용해보고, 각가의 특징과 사용법을 배우면서,, 각각의 성능을 비교해 보기 위한 프로젝트입니다.\n",
    "\n",
    "먼저, 단어사전을 만드는 대상 Corpus를 결정해야하는데, 여러기준으로 비교해 보다가, 교재에서 사용했던 Korea-english 병행 Corpus를 사용하려다가\n",
    "Korea-english 병행 Corpus의 전처리된 문장개수가 77,000여개로,\n",
    "네이버영화리뷰의 train data 전처리후 Corpus 문장개수 146,000개의 절반수준밖에 않되는 수준이라서,\n",
    "네이버의 Train data Corpus를 대상으로 단어사전을 만들기로 하였습니다.\n",
    "\n",
    "**(1) Unigram**    \n",
    "\n",
    "그리고는 먼저 SentencePiece의 Unigram과 bpe를 성능비교하기로 하고서, 먼저 Unigram을 시작하였습니다.\n",
    "데이터 전처리가 필요없다던 SentencePiece에서 중복치제거, 결측치제거, 특수기호나 구두점등의 처리를 해야 오류가 않나고, 학습이 잘었습니다. 전처리가 필없다는 이야기는 영어의 경우에 해당되는가 봅니다.\n",
    "그리고, SentencePiece에는 불용어를 처리하는 기능을 찾아보아도 없었습니다.\n",
    "그럼에도 불구하고 SentencePiece를 많이 쓴다는 이야기는 성능이 좋다는 이야기일텐데, 비교해볼 충분한 이유가 됩니다.\n",
    "\n",
    "vocab_size는 10000개로 해서, 1차 SentencePiec Train을 통해서, 생성된 토큰으로, 적절한 크기의 maxlen 42개를 구한후, maxlen 을 산입하여, 2차로 sp_tokenize_withPadding(s, corpus, maxlen)함수를 통해서, SentencePiec Train을 다시 해서, 정식으로 vocab_size 10000개의 단어장과 Word_index, Index_Word를  만들었습니다.\n",
    "학습된 Unigram 모델의 spm.SentencePieceProcessor()로 Train data를 벡터화완료하고, 마찬가지로 Test data의 벡터화도 완료하였습니다. \n",
    "그리고, Train data를 8;2의 비율로 Valid data를 분리하였습니다.\n",
    "\n",
    "모델은 LSTM모델을 사용하였고, word_vector_dim = 16, hidden_unit = 16, drop_rate = 0.2, epochs= 20 로 고정시켰고, 옵티마이저는 adam, 손실함수 'binary_crossentropy 를 사용하였고, 비교를 위해 다른 모델에서도 동일한 구조를 사용할 예정입니다.\n",
    "  \n",
    "학습후에 Test data로 성능테스트를 했는데, 84.32% 였습니다.\n",
    "\n",
    "**(2) Bpe**   \n",
    "\n",
    "model Type을 'bpe'로 바꾸어서, 상기의 작업과정과 동일한 과정을 통해서, 성능테스트를 했는데, 83.64%였습니다.   \n",
    "이는 Unigram보다 성능이 낮았습니다.   \n",
    "\n",
    "Bpe 작업파일 링크: https://github.com/lkh-7/first-repository/blob/master/%5BGDeep%5D02_%5Bsp_tokenizer%5D_%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_%EB%A9%8B%EC%A7%84%20%EB%8B%A8%EC%96%B4%EC%82%AC%EC%A0%84%20%EB%A7%8C%EB%93%A4%EA%B8%B0_Project_%EC%A0%9C%EC%B6%9C%EC%A4%80%EB%B9%84%EC%9A%A9_SPM_Bpe_ONLY.ipynb\n",
    "\n",
    "**(3) KoNLPy 의 Mecab**   \n",
    "\n",
    "[Explore 8] 네이버영화리뷰 분류에서 했던 과정과 같은 과정을 거치되, 위의 LSTM모델과 동일 구조와 하이퍼파람으로 성능테스트해 본 결과 Test Accuracy는 84.55% 였습니다.\n",
    "\n",
    "**(4) KoNLPy 의 Okt**   \n",
    "\n",
    "상기 (3)과 동일 과정을 거쳐서, 성능테스트해 본 결과 Test Accuracy는 83.27% 였습니다.\n",
    "\n",
    "**(5) 종합평가**  \n",
    "\n",
    "전체중에서, Mecab 가 우수했고, 2위는 Unigram방식의 SetencePiece, 3위는 bpe방식의 SetencePiece,\n",
    "4위가 Okt 였습니다.\n",
    "\n",
    "**결론적**으로, 한국어는 한국어형태소분석기가 더 잘맞고, 그중 Mecab이 가장 우수하며, Unigram 방식의 SencePiece\n",
    "도 우수한 편이었어서, **한국어만으로된 문서들을 처리할때는 한국어형태소분석기 Mecab**을 쓰고,\n",
    "**한국어와 영어를 비슷한 비중으로 병행 사용**하는 문서들을 처리할때는 **Unigram 방식의 SencePiece**를 사용하는 것이 좋겠다는 생각입니다.(문서집합에따라 적용상황이 다소 다를수도 물론 있지만) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1821fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bf0c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "095023a1",
   "metadata": {},
   "source": [
    "#### 루브릭\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "평가문항\t상세기준\n",
    "1. SentencePiece를 이용하여 모델을 만들기까지의 과정이 정상적으로 진행되었는가?\n",
    "\n",
    "코퍼스 분석, 전처리, SentencePiece 적용, 토크나이저 구현 및 동작이 빠짐없이 진행되었는가?\n",
    "\n",
    "2. SentencePiece를 통해 만든 Tokenizer가 자연어처리 모델과 결합하여 동작하는가?\n",
    "\n",
    "SentencePiece 토크나이저가 적용된 Text Classifier 모델이 정상적으로 수렴하여 80% 이상의 test accuracy가 확인되었다.\n",
    "\n",
    "3. SentencePiece의 성능을 다각도로 비교분석하였는가?\n",
    "\n",
    "SentencePiece 토크나이저를 활용했을 때의 성능을 다른 토크나이저 혹은 SentencePiece의 다른 옵션의 경우와 비교하여 분석을 체계적으로 진행하였다.\n",
    "프로젝트 업로드 (URL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2613f969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
