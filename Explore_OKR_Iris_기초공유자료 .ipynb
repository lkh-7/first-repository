{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44f2759",
   "metadata": {},
   "source": [
    "# Exp.1.4:  \n",
    "\n",
    "### sklearn.model_selection.train_test_split 인자 random_state의 역할 설명:\n",
    "train_test_split()는 데이터set에서 train data 와 test data를 분리할때, 또 다른 인자인 shuffle = True 에의해서, 랜덤으로 샘플들을 섞는다.그래서,train_test_split()을 호출해서 사용할때마다 train data,test data의 샘플순서가 바뀐다.이렇게 되면, 다음번 하긋ㅂ을 하거나, 다른 이의 컴퓨터에서 동일모델 사용시마다,학습결과가 약간씩 차이가 날수 밖에 없다.\n",
    "이러한 차이가 없도록 하기위해, 랜덤으로 삮을때, 동일한 샘플순서에의해 섞어야할 필요가 있는데,이깨 필요한 것이 random_state(seed)다.\n",
    "난수생성시 초기값을 주면, 나머지는 일정 순서에의해 난수가 발생되므로, random_state(seed)에 일정 수치로 고정입력해주고,사용하면 된다\n",
    "(ex)random_state(7)\n",
    "\n",
    "### 모델의 실험결과를 재현 가능하게 만드는 작업이 중요한 이유:\n",
    "이미 학습된 모델의 실험결과가 때마다, 장소마다 다를 경우, 결과의 차이때문에 모델의 설명 및 교육,전달시 신뢰문제가 생김 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060d3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b750891",
   "metadata": {},
   "source": [
    "# Exp.1.7:\n",
    "\n",
    "### SGD의 장단점에 대해 설명:\n",
    "(1) 장점: \n",
    "  - sgd(Stochastic Gradient Descent,확률적경사하강법알고리즘)은 전체 데이터set을 모두 학습에 투입시키는 것이 아닌,random하게 선정된 sample 1개( batch size 1개)씩으로 학습을 시켜서,적은 수만으로 random의 장점인 모집단 대표성을 활용하면서, 빠른 시간에 학습을 끝낼수 있슴\n",
    "\n",
    "(2) 단점:\n",
    "  - 장점과 관련한 단점으로서, random하게 샘플들을 1개씩 뽑다보니, 적은수의 샘플중에 중복데이터가 생길수 있고 이 경우 샘플들의 모집단 대표성이 떨어져서,학습이 잘않되거나, 중복데이터에의해 오버피팅될수 있슴.\n",
    "  \n",
    "\n",
    "###  SGD, 미니배치, BGD\n",
    "(1) bgd(batch gradient descent): loss function을 경사하강법으로 최소화할때,전체 데이터세트를 한꺼번에 다사용함,즉,batch size 가 전체데이터임, local minima에 빠지기 쉽고,학습시간이 오래 걸림\n",
    "\n",
    "(2) sgd(stochastic gradient descent): loss function을 경사하강법으로 최소화할때,학습데이터 샘플들을 batch size 1개씩으로 하며,전체 데이터세트에서 random하게 1개씩 추출함,bgd의 단점개선용임, 학습시간 빠르나, 중복데이터로 인해 오버피팅가능성있슴\n",
    "\n",
    "(3) mini_batch에의한 Gradient Descent: 상기 (1),(2)의 중간입장으로서,batch size 규모를 10, 또는 100 개등 전체데이터 규모를 고려해서, 여러번에 나누어서, 학습을 하게 함, 상기 3개중 제일 적당함    \n",
    "\n",
    "\n",
    "###  배치 학습에서 이터레이션과 에폭의 관계를 설명\n",
    "\n",
    "(1) 이터레이션(iteration) : 전체 데이터수를 batch size로 나누었을때,그 나눈 수, 즉, 전체데이터수가 10,000개일때 batch size 가 200개이면, 이터레이션은 10000/ 200 = 50 회가 됨, 이터레이션의 의미는 한단위의 batch를 몇회 돌려야 전체 데이터를 모드르 한번 학습시키냐임 \n",
    "\n",
    "(2) 에퐄(epoch): 학습시킬때, 전체데이터세트를 몇 회전 학습시키냐임, 즉, 전체 데이터개수가 10,000개일때, 전체데이터 10,000개를 다 학습시키면 epoch 1회임, 반복해서, 한번 더시키면 2회, 100번 시키면 epoch 100임, 학습을 시키려면, 데이터 종류에따라 다르겠으나,보통 5회~20회정도이나,수천회 이상의 epoch가 필요한때도 있슴   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af62122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d6f9c",
   "metadata": {},
   "source": [
    "# Exp.1.9:\n",
    "\n",
    "###  훈련셋의 데이터 샘플 구성이 불균형하게 분포되어 있으면 발생할 수 있는 문제점\n",
    "학습데이터 label이 불균형하게 분포되어있는 데이터를 다룰 때는 조심해야 합, 즉, label이 범부령으로 나뉘어있을때,두 범주가 샘플수가 5:5\n",
    "로 반반으로 구성되었을때는 정확도(Accuracy)지표가 신뢰할만하지만, 한쪽으로 지나치게 편중되어서, 9:1 로 한쪽의 샘플이 90%로 편중될 경우에, 편중된 쪽으로 학습이되어,10%쪽의 label은 학습이 않되어도, Accuracy가 90%를 넘을수 있다. dlruddn 10% label을 예측해도, 형편없는 결과를 얻게되는 문제가 생긴다.\n",
    "이러한 데이터를 imbalanced data라고 하며, 이런 데이터를 학습시켜서 나온 모델은 Accuracy 한개만으로 평가하면 앟되고,여러 평가지표를 병행해서 봐야함      \n",
    "\n",
    "### 상기 문제점에 대한 대안은 무엇일까? 자료를 찾아 공유\n",
    "\n",
    "-평가관련: 평가지표를 Accuracy뿐 아니라,precision, recall,f1_score 등 여러개를 통해 종합적으로 평가하여 검증된 모델만 사용\n",
    "\n",
    "-데이터 보완: 데이터가 많을 경우 편중된 쪽의 데이터수를 줄여서 비율을 비슷하게 조정(undersampling) 또는 부족한 쪽의 데이터를 증강시킴(oversampling) \n",
    "\n",
    "\n",
    "### recall과 precision이 유효한 task에는 각각 어떤 것들이 있을까?(스팸메일 필터 모델과 암진단 모델 외에 다른 사례를 찾아 이야기해보자)\n",
    "\n",
    "-코로나감염자 진단: 감염자인데, 발견이 않되면 더 많은 사람들에 전연시킬수 있으니, recall이 중요할 듯 ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b61148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
