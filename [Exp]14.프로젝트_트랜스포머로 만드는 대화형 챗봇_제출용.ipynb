{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00081f6b",
   "metadata": {},
   "source": [
    "## 14-14. 프로젝트: 한국어 데이터로 챗봇 만들기\n",
    "\n",
    "영어로 만들었던 챗봇을 한국어 데이터로 바꿔서 훈련시켜봅시다.\n",
    "\n",
    "시작하기 전에 우선 주요 라이브러리 버전을 확인해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd2c1643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7d9a3f",
   "metadata": {},
   "source": [
    "#### Step 1. 데이터 수집하기\n",
    "\n",
    "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용합니다.\n",
    "\n",
    "이 데이터는 아래의 링크에서 다운로드할 수 있습니다.\n",
    "\n",
    "songys/Chatbot_data :  https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv\n",
    "\n",
    "Cloud shell에서 아래 명령어를 입력해 주세요.\n",
    "\n",
    "$ mkdir -p ~/aiffel/transformer_chatbot/data/\n",
    "\n",
    "$ ln -s ~/data/* ~/aiffel/transformer_chatbot/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dedd2044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7014373b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11823, 3)               Q            A  label\n",
      "0        12시 땡!   하루가 또 가네요.      0\n",
      "1   1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2  3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0                              Q                         A  label\n",
      "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
      "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
      "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2 Index(['Q', 'A', 'label'], dtype='object')\n",
      "data.isnull().sum() Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n",
      "Question (11823,) 0                     12시 땡!\n",
      "1                1지망 학교 떨어졌어\n",
      "2               3박4일 놀러가고 싶다\n",
      "3            3박4일 정도 놀러가고 싶다\n",
      "4                    PPL 심하네\n",
      "5                  SD카드 망가졌어\n",
      "6                    SD카드 안돼\n",
      "7             SNS 맞팔 왜 안하지ㅠㅠ\n",
      "8    SNS 시간낭비인 거 아는데 매일 하는 중\n",
      "9          SNS 시간낭비인데 자꾸 보게됨\n",
      "Name: Q, dtype: object\n",
      "Answer (11823,) 0            하루가 또 가네요.\n",
      "1             위로해 드립니다.\n",
      "2           여행은 언제나 좋죠.\n",
      "3           여행은 언제나 좋죠.\n",
      "4            눈살이 찌푸려지죠.\n",
      "5    다시 새로 사는 게 마음 편해요.\n",
      "6    다시 새로 사는 게 마음 편해요.\n",
      "7      잘 모르고 있을 수도 있어요.\n",
      "8         시간을 정하고 해보세요.\n",
      "9         시간을 정하고 해보세요.\n",
      "Name: A, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_to_dataset = '/aiffel/aiffel/transformer_chatbot/data/ChatbotData .csv'\n",
    "\n",
    "data = pd.read_csv(path_to_dataset)\n",
    "print(data.shape, data.head(3), data.tail(3), data.columns)\n",
    "\n",
    "# 데이터 Nan 여부체크: Nan 없슴\n",
    "print(\"data.isnull().sum()\", data.isnull().sum())\n",
    "\n",
    "# question, answer, label 로 분리\n",
    "Question = data['Q']\n",
    "Answer = data['A']\n",
    "label = data['label']\n",
    "print(\"Question\",Question.shape, Question.head(10))\n",
    "print(\"Answer\",Answer.shape, Answer.head(10))\n",
    "#print(\"label\",label.shape, label.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64ab923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7265, '외롭지만 혼자 걸을수 있어_조성모')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터정제 처리 개별 체크 셀 \n",
    "[(i,x) for i,x in enumerate(Question.values) if x.find('_')!=-1]\n",
    "[(i,x) for i,x in enumerate(Question.values)][7265]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a1991",
   "metadata": {},
   "source": [
    "#### Step 2. 데이터 전처리하기\n",
    "영어 데이터와는 전혀 다른 데이터인 만큼 영어 데이터에 사용했던 전처리와 일부 동일한 전처리도 필요하겠지만 전체적으로는 다른 전처리를 수행해야 할 수도 있슴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e1366b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823\n"
     ]
    }
   ],
   "source": [
    "# 사용할 샘플의 최대 개수\n",
    "MAX_SAMPLES = len(data)    #11823  \n",
    "print(MAX_SAMPLES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bf38bf",
   "metadata": {},
   "source": [
    "##### (1) 1차 전처리: 결측치 제거,  데이터 정제,  대화상 멘트가 반복될수 있어서 중복치는 유지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bcacbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "####  1. 1차 한글 전처리 함수: dataframe형 sentence 데이터셑 전처리함수,  결측치 제거, 데이터 정제\n",
    "def preprocess_sentence_df(Question, Answer) :  #, num_words=num_words):\n",
    "        \n",
    "    ## 결측치제거 : 1개라도 있으면, 해당행 전체 제거\n",
    "    #1. Question\n",
    "    print(\"결측치 개수\",Question.isnull().sum())\n",
    "    if Question.isnull().any().any():\n",
    "        Question.dropna(how='any',inplace=True)\n",
    "        print(\"결측치제거후 결측치 여부\",Question.isnull().any().any())    \n",
    "    #2. Answer\n",
    "    print(\"결측치 개수\",Answer.isnull().sum())\n",
    "    if Answer.isnull().any().any():\n",
    "        Answer.dropna(how='any',inplace=True)\n",
    "        print(\"결측치제거후 결측치 여부\",Answer.isnull().any().any())\n",
    "    \n",
    "    ## 데이터 정제 \n",
    "    # 한글과 숫자,공백(한개이상 공백은 한개로 축소),특수문자일부 !?,.^을 제외하고 제거:[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\n",
    "    # --> 한글형태소기를 tokenizer로 쓸 경우에는 영어및 일부선택된 특수문자외에는 모두제거(..., - - 등도 제거)\n",
    "    #1. Question\n",
    "    Question = Question.str.replace(\"[' ']+\",\" \")\n",
    "    Question = Question.str.replace(\"\\.{2,30}\",\" \") \n",
    "    Question = Question.str.replace(r\"([?.!,_])\", r\" \\1 \")\n",
    "    #Question = Question.str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n",
    "    Question = Question.str.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  #한글영어병행형태소기인경우 영어포함                                                         \n",
    "    print(\"한글과 공백,기타일부 등제외후 모두제거상태_Question.head()\",Question.head())\n",
    "    #2. Answer\n",
    "    Answer = Answer.str.replace(\"[' ']+\",\" \")\n",
    "    Answer = Answer.str.replace(\"\\.{2,30}\",\" \") \n",
    "    Answer = Answer.str.replace(r\"([?.!,^])\", r\" \\1 \")\n",
    "    #Answer = Answer.str.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n",
    "    Answer = Answer.str.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  #한글영어병행형태소기인경우 영어포함                                                            \n",
    "    print(\"한글과 공백,기타일부 등제외후 모두제거상태_Answer.head()\", Answer.head())\n",
    "    # 데이터 정제후 빈 공백만 있는 문장의 경우 제거:  Nan 입력후 행제거\n",
    "    #1. Question\n",
    "    Question.replace('', np.nan, inplace=True)\n",
    "    print(\"Nan 존재유뮤\",Question.isnull().any().any() )\n",
    "    if Question.isnull().any().any():\n",
    "        Question.dropna(how='any',inplace=True)\n",
    "    #2. Answer   \n",
    "    Answer.replace('', np.nan, inplace=True)\n",
    "    print(\"Nan 존재유뮤\",Answer.isnull().any().any() )\n",
    "    if Answer.isnull().any().any():\n",
    "        Answer.dropna(how='any',inplace=True)\n",
    "\n",
    "    print(\"Question\",Question.shape,Question.head())     \n",
    "    print(\"Answer\",Answer.shape,Answer.head())  \n",
    "    \n",
    "    return Question, Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7ea0dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 2. 1차 한글 전처리 함수: test용 개별 sentence 전처리함수, 데이터 정제\n",
    "def preprocess_sentence(sentence): \n",
    "    \n",
    "    ## 데이터 정제 \n",
    "    # 한글과 숫자,공백(한개이상 공백은 한개로 축소),특수문자일부 !?,.^을 제외하고 제거:[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\n",
    "    # --> 한글형태소기를 tokenizer로 쓸 경우에는 영어및 일부선택된 특수문자외에는 모두제거(..., - - 등도 제거)\n",
    "    #1. sentence\n",
    "    sentence = sentence.replace(\"[' ']+\",\" \")\n",
    "    sentence = sentence.replace(\"\\.{2,30}\",\" \") \n",
    "    sentence = sentence.replace(r\"([?.!,_])\", r\" \\1 \")\n",
    "    #sentence = sentence.replace(\"[^ㄱ-힣0-9!?,.\\^+ ^\\s]\",\"\")  #한글전용형태소기인 경우 영어제외\n",
    "    sentence = sentence.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  #한글영어병행형태소기인경우 영어포함                                                         \n",
    "    #print(\"한글과 공백,기타일부 등제외후 모두제거상태_sentence\",sentence)\n",
    "          \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f66f4361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 개수 0\n",
      "결측치 개수 0\n",
      "한글과 공백,기타일부 등제외후 모두제거상태_Question.head() 0           12시 땡 ! \n",
      "1        1지망 학교 떨어졌어\n",
      "2       3박4일 놀러가고 싶다\n",
      "3    3박4일 정도 놀러가고 싶다\n",
      "4            PPL 심하네\n",
      "Name: Q, dtype: object\n",
      "한글과 공백,기타일부 등제외후 모두제거상태_Answer.head() 0     하루가 또 가네요 . \n",
      "1      위로해 드립니다 . \n",
      "2    여행은 언제나 좋죠 . \n",
      "3    여행은 언제나 좋죠 . \n",
      "4     눈살이 찌푸려지죠 . \n",
      "Name: A, dtype: object\n",
      "Nan 존재유뮤 False\n",
      "Nan 존재유뮤 False\n",
      "Question (11823,) 0           12시 땡 ! \n",
      "1        1지망 학교 떨어졌어\n",
      "2       3박4일 놀러가고 싶다\n",
      "3    3박4일 정도 놀러가고 싶다\n",
      "4            PPL 심하네\n",
      "Name: Q, dtype: object\n",
      "Answer (11823,) 0     하루가 또 가네요 . \n",
      "1      위로해 드립니다 . \n",
      "2    여행은 언제나 좋죠 . \n",
      "3    여행은 언제나 좋죠 . \n",
      "4     눈살이 찌푸려지죠 . \n",
      "Name: A, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1162/834150812.py:20: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  Question = Question.str.replace(\"[' ']+\",\" \")\n",
      "/tmp/ipykernel_1162/834150812.py:21: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  Question = Question.str.replace(\"\\.{2,30}\",\" \")\n",
      "/tmp/ipykernel_1162/834150812.py:22: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  Question = Question.str.replace(r\"([?.!,_])\", r\" \\1 \")\n",
      "/tmp/ipykernel_1162/834150812.py:24: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  Question = Question.str.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  #한글영어병행형태소기인경우 영어포함\n",
      "/tmp/ipykernel_1162/834150812.py:27: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  Answer = Answer.str.replace(\"[' ']+\",\" \")\n",
      "/tmp/ipykernel_1162/834150812.py:28: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  Answer = Answer.str.replace(\"\\.{2,30}\",\" \")\n",
      "/tmp/ipykernel_1162/834150812.py:29: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  Answer = Answer.str.replace(r\"([?.!,^])\", r\" \\1 \")\n",
      "/tmp/ipykernel_1162/834150812.py:31: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  Answer = Answer.str.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  #한글영어병행형태소기인경우 영어포함\n"
     ]
    }
   ],
   "source": [
    "# 1차 전처리: 결측치제거, 데이터 정제 처리\n",
    "questions, answers = preprocess_sentence_df(Question, Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4de90598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0           12시 땡 ! \n",
      "1        1지망 학교 떨어졌어\n",
      "2       3박4일 놀러가고 싶다\n",
      "3    3박4일 정도 놀러가고 싶다\n",
      "4            PPL 심하네\n",
      "Name: Q, dtype: object\n",
      "0 0     하루가 또 가네요 . \n",
      "1      위로해 드립니다 . \n",
      "2    여행은 언제나 좋죠 . \n",
      "3    여행은 언제나 좋죠 . \n",
      "4     눈살이 찌푸려지죠 . \n",
      "Name: A, dtype: object\n",
      "convers (11823,) 0            12시 땡 ! 하루가 또 가네요 . \n",
      "1          1지망 학교 떨어졌어위로해 드립니다 . \n",
      "2       3박4일 놀러가고 싶다여행은 언제나 좋죠 . \n",
      "3    3박4일 정도 놀러가고 싶다여행은 언제나 좋죠 . \n",
      "4             PPL 심하네눈살이 찌푸려지죠 . \n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(questions.isnull().sum(), questions.head())\n",
    "print(answers.isnull().sum(), answers.head())\n",
    "convers = questions + answers\n",
    "print(\"convers\", convers.shape, convers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f4ef8",
   "metadata": {},
   "source": [
    "1차 전처리를 통하여, 결측치는 없었고, 대화상 멘트가 반복될수 있어서,중복치는 제거하지 않았습니다.특수문자,공백,구두점처리,한글외영어등 제거흐는 데이터 정제처리후 데이터 1차 전처리 완료함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810921fc",
   "metadata": {},
   "source": [
    "#### Step 3. SubwordTextEncoder 사용하기 : 2차 전처리로  병렬 데이터  토크나이징 실행\n",
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 많은 분이 알고 있지만, 여기서는 형태소 분석기가 아닌 이전 교재에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용해야함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13df978",
   "metadata": {},
   "source": [
    "TensorFlow Datasets SubwordTextEncoder 를 토크나이저로 사용해서, 단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고, 각 토큰을 고유한 정수로 인코딩, 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가, 최대 길이 MAX_LENGTH 설정및 MAX_LENGTH를 넘는 문장들은 필터링, MAX_LENGTH보다 길이가 짧은 문장들은 맞도록 패딩\n",
    "\n",
    "###### 가) 단어장(Vocabulary) 만들기\n",
    "\n",
    "우선 각 단어에 고유한 정수 인덱스를 부여하기 위해서 단어장(Vocabulary)을 만듬,. 단어장을 만들 때는 질문과 답변 데이터셋을 모두 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aa3c29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "print(\"살짝 오래 걸릴 수 있어요. 스트레칭 한 번 해볼까요? 👐\")\n",
    "\n",
    "# 질문과 답변 데이터셋에 대해서 Vocabulary 생성: \n",
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(questions + answers, target_vocab_size= 2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8a8c01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8365"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer 의 크기 : target_size 8192(=2**13)개로 했는데, 8365개가 되었슴\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a679795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시작 토큰과 종료 토큰에 고유한 정수를 부여\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ec915c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START_TOKEN의 번호 : [8365]\n",
      "END_TOKEN의 번호 : [8366]\n"
     ]
    }
   ],
   "source": [
    "print('START_TOKEN의 번호 :' ,[tokenizer.vocab_size])\n",
    "print('END_TOKEN의 번호 :' ,[tokenizer.vocab_size + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc7e76f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8367\n",
      "11823 11823\n"
     ]
    }
   ],
   "source": [
    "# 시작 토큰과 종료 토큰을 고려하여 +2를 하여 단어장의 크기를 산정합니다.\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "print(VOCAB_SIZE)\n",
    "print(len(questions),len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "603b3f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' . ', ' ? ', '거예요', '게_', '수_', '너무_', '는_', '더_', '거_', '좋아하는_', '이_', '을_', '도_', '잘_', ' .  ', '고_', '것_', '요', '많이_', '안_', '같아요', '좋은_', '한_', '좀_', '있어요', '가_', '은_', '나_', '에_', '있을_', '지_', '해보세요', '할_', '사람_', '면_', '건_', ' ! ', '사람이_', '마세요', '를_', '다_', '하고_', '하는_', '보세요', '해', '죠', '의_', '서_', '내가_', '싶어', '지', '내_', '네', '마음이_', '이제_', '만_', '썸_', '어떻게_', '어', '같아', '있는_', '왜_', '다른_', '세요', '나', '수도_', '시간이_', '다시_', '다', '그_', '것도_', '또_', '좋을_', '오늘_', '정말_', '싶다', '같이_', '가', '이', '네요', '될_', '해요', '자꾸_', '걸_', '없어요', '하세요', '있어', '로_', '일_', '길_', '바랄게요', '까', '돼요', '에서_', '봐요', '하면_', '할까', '으로_', '때_', '될까']\n"
     ]
    }
   ],
   "source": [
    "# subword 100 개 출력\n",
    "print(tokenizer.subwords[:100])\n",
    "#[(i,x) for i,x in enumerate(tokenizer.subwords) if x.find('_')!=-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbd63a9",
   "metadata": {},
   "source": [
    "[의문] 데이터 1차전처리에서, 특수기호 5개 빼고, 다 정리했는데, tokenizer 처리후 각 토큰에 붙어있는 '_'는 무엇인가????????\n",
    "영어에도 붙어 있는데???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771abf9f",
   "metadata": {},
   "source": [
    "###### 나) 각 단어를 고유한 정수로 인코딩(Integer encoding) & 패딩(Padding)\n",
    "위에서 tensorflow_datasets의 SubwordTextEncoder를 사용해서 tokenizer를 정의하고 Vocabulary를 만들었다면, tokenizer.encode()로 각 단어를 정수로 변환할 수 있고 또는 tokenizer.decode()를 통해 정수 시퀀스를 단어 시퀀스로 변환할 수 있음.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5363d454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정수 인코딩 후의 21번째 질문 샘플: [5831, 605, 2501, 4176]\n",
      "정수 인코딩 후의 21번째 답변 샘플: [2685, 7669, 8, 6378, 95, 1]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 22번째 샘플에 대해서 정수 인코딩 작업을 수행.\n",
    "# 각 토큰을 고유한 정수로 변환\n",
    "print('정수 인코딩 후의 21번째 질문 샘플: {}'.format(tokenizer.encode(questions[21])))\n",
    "print('정수 인코딩 후의 21번째 답변 샘플: {}'.format(tokenizer.encode(answers[21])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be567f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11823 [[8103, 1536, 3063, 37], [8158, 51, 913, 8141, 991, 1714], [8160, 1432, 4679, 8141, 3655, 76], [8160, 1432, 4679, 8141, 1292, 3655, 76], [8189, 8189, 8185, 8141, 4203]]\n",
      "11823 [[3852, 72, 8082, 1], [1833, 5552, 1], [3398, 770, 129, 1], [3398, 770, 129, 1], [979, 2299, 1490, 2182, 5518, 46, 1]]\n",
      "questions 길이 평균, 표준편차, 최대,최소:  5.490992133976148 2.503972833545713 21 1\n",
      "answers 길이 평균, 표준편차, 최대,최소:  5.827370379768248 2.6024579131675876 29 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sample 문장 정수 인덱스화\n",
    "sample_encoding_questions = [tokenizer.encode(x) for x in questions.values] \n",
    "print(len(sample_encoding_questions), sample_encoding_questions[:5])\n",
    "sample_encoding_answers = [tokenizer.encode(x) for x in answers.values] \n",
    "print(len(sample_encoding_answers),sample_encoding_answers[:5])\n",
    "\n",
    "# max_length 설정\n",
    "lenq = [len(x) for x in sample_encoding_questions]\n",
    "lena = [len(x) for x in sample_encoding_answers]\n",
    "\n",
    "# 데이터 길이 분포 파악\n",
    "max_length_q = np.max(lenq)\n",
    "min_length_q = np.min(lenq)\n",
    "mean_length_q = np.mean(lenq)\n",
    "std_length_q = np.std(lenq)\n",
    "print(\"questions 길이 평균, 표준편차, 최대,최소: \", mean_length_q, std_length_q, max_length_q, min_length_q)\n",
    "\n",
    "max_length_a = np.max(lena)\n",
    "min_length_a = np.min(lena)\n",
    "mean_length_a = np.mean(lena)\n",
    "std_length_a = np.std(lena)\n",
    "print(\"answers 길이 평균, 표준편차, 최대,최소: \", mean_length_a, std_length_a, max_length_a, min_length_a)\n",
    "\n",
    "# 분포를 히스토그램으로 보기 plot\n",
    "plt.hist(lenq)\n",
    "plt.title(\"questions_sentence_length\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(lena)\n",
    "plt.title(\"answers_sentence_length\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d39c4",
   "metadata": {},
   "source": [
    "######  max_length 설정\n",
    "question, answer 공히 평균 5.5 내외, 표준편차 2.5내외, 최대길이는 각 21개, 29개인데,\n",
    "max 산정에는 평균치, 표준편차, 시작토큰1개, 종료토큰1개포함하여 12개이면 충분할 것으로 판단됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5c12273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# 샘플의 최대 허용 길이 또는 패딩 후의 최종 길이\n",
    "MAX_LENGTH = 12\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e66d9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩, 최대 길이를 초과하는 샘플 제거, 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "  tokenized_inputs, tokenized_outputs = [], []\n",
    "  \n",
    "  for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "    # 정수 인코딩 과정에서 시작 토큰과 종료 토큰을 추가\n",
    "    sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "    sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "    # 최대 길이 12 이하인 경우에만 데이터셋으로 허용\n",
    "    if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "      tokenized_inputs.append(sentence1)\n",
    "      tokenized_outputs.append(sentence2)\n",
    "  \n",
    "  # 최대 길이 12 로 모든 데이터셋을 패딩\n",
    "  tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "      tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "  \n",
    "  return tokenized_inputs, tokenized_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1d5e244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어장의 크기 : 8367\n",
      "필터링 후의 질문 샘플 개수: 10740\n",
      "필터링 후의 답변 샘플 개수: 10740\n"
     ]
    }
   ],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)\n",
    "print('단어장의 크기 :',(VOCAB_SIZE))\n",
    "print('필터링 후의 질문 샘플 개수: {}'.format(len(questions)))\n",
    "print('필터링 후의 답변 샘플 개수: {}'.format(len(answers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491a0ee6",
   "metadata": {},
   "source": [
    "###### 다). 교사 강요(Teacher Forcing) 사용하기\n",
    "\n",
    "트랜스포머 디코더에서도 교사 강요(Teacher Forcing) 를 적용.\n",
    "\n",
    "<START_TOKEN>은 문장의 시작을 의미하는 시작 토큰, <END_TOKEN>은 문장의 끝을 의미하는 종료 토큰 <PAD>는 패딩을 위해 사용되는 패딩 토큰입니다.\n",
    "\n",
    "입력은 <START_TOKEN>부터 시작하되, 마지막토큰을 없앰(여기서는 마지막토큰이   <END_TOKEN>이 아닌 <PAD>임\n",
    "레이블은 <START_TOKEN>을 없애고 시작함\n",
    "\n",
    "입력 : <START_TOKEN> I AM A STUDENT <END_TOKEN> <PAD> <PAD> <PAD> \n",
    "\n",
    "레이블 : I AM A STUDENT <END_TOKEN> <PAD> <PAD> <PAD> <PAD>\n",
    "\n",
    "질문과 답변의 쌍을 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성,이때, 교사 강요를 위해서 answers[:, :-1]를 디코더의 입력값, answers[:, 1:]를 디코더의 레이블로 사용\n",
    "  \n",
    "    \n",
    "[참고] 아래 코드중 dataset.prefetch(tf.data.experimental.AUTOTUNE)에대한 설명     \n",
    "  \n",
    "훈련 속도를 더 빠르게\n",
    "    \n",
    "prefetch(1)을 호출하면 데이터셋은 항상 한 배치가 미리 준비되도록 최선을 (=알고리즘이 한 배치로 작업하는 동안 이 데이터셋이 동시에 다음 배치를 준비)\n",
    "    \n",
    "GPU에서 훈련하는 스텝을 수행하는 것보다 짧은 시간안에 한 배치 데이터를 준비할 수 있다. (=GPU 100%활용하는 방법)\n",
    "    \n",
    "interleave메소드와 map에 num_parallel_calls을 함께 사용하면 데이터를 적재하고 전처리할때 CPU의 멀티코어를 사용해 더 빠르게 준비 가능\n",
    "    \n",
    "prefetch는 일반적으로 하나도 충분, tf.data.experimental.AUTOTUNE을 전달하면 텐서플로가 자동으로 결정 (하지만 아직 실험 단계)\n",
    "    \n",
    "GPU에서 데이터를 바로 프리페치할 수 있는 tf.data.experimental.prefetch_to_device()를 확인해보자   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4832fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 12000\n",
    "\n",
    "# 디코더는 이전의 target을 다음의 input으로 사용\n",
    "# 이에 따라 outputs에서는 START_TOKEN을 제거.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)  \n",
    "# dataset.prefetch: 데이터 batch를 미리 가져와서,대기시켜 처리속도 빠르게 하는 기능\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66798bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86512f18",
   "metadata": {},
   "source": [
    "#### Step 4. 모델 구성하기\n",
    "위 실습 내용을 참고하여 트랜스포머 모델을 구현합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea473de0",
   "metadata": {},
   "source": [
    "##### 포지셔널 인코딩 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "871a5134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 포지셔널 인코딩 레이어\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, position, d_model):   # position: 입력문장의 최대길이, d_model : 차원수\n",
    "    super(PositionalEncoding, self).__init__()\n",
    "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "    #self.my_transpose = my_transpose\n",
    "    \n",
    "  def get_angles(self, position, i, d_model):\n",
    "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "    #print(\"angles\",angles.shape, angles)\n",
    "    return position * angles\n",
    "\n",
    "  def positional_encoding(self, position, d_model):\n",
    "    angle_rads = self.get_angles(\n",
    "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "        d_model=d_model)\n",
    "    #print(\"angle_rads\",angle_rads.shape,angle_rads)\n",
    "    \n",
    "    # 배열의 짝수 인덱스에는 sin 함수 적용\n",
    "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "    #print(\"sines\",sines.shape, sines)\n",
    "    \n",
    "    # 배열의 홀수 인덱스에는 cosine 함수 적용\n",
    "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "    #print(\"cosines\",cosines.shape, cosines)\n",
    "    \n",
    "    # sin과 cosine이 교차되도록 재배열\n",
    "    pos_encoding = tf.stack([sines, cosines], axis=0)\n",
    "    #print(\"pos_encoding1\",pos_encoding.shape, pos_encoding)\n",
    "    pos_encoding = tf.transpose(pos_encoding,[1, 2, 0]) # 원래축순서(0,1,2)==> Transpose된 축순서(1,2,0)\n",
    "    #print(\"pos_encoding2\",pos_encoding.shape, pos_encoding)\n",
    "    pos_encoding = tf.reshape(pos_encoding, [position, d_model])\n",
    "    #print(\"pos_encoding3\",pos_encoding.shape, pos_encoding)\n",
    "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "    #print(\"pos_encoding4\",pos_encoding.shape, pos_encoding)\n",
    "    return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    posinput = inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "    #print(\"posinput\",posinput ) \n",
    "    return posinput     # inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697e8977",
   "metadata": {},
   "source": [
    "##### 스케일드 닷 프로덕트 어텐션 함수 :   패딩에 마스크 추가  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50445c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일드 닷 프로덕트 어텐션 함수\n",
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "  # 어텐션 가중치는 Q와 K의 닷 프로덕트\n",
    "  matmul_qk = tf.matmul(query, key, transpose_b=True) #tf.matmul(a,b,transpose_a=False,transpose_b=False)\n",
    "\n",
    "  # 가중치를 정규화\n",
    "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "  logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "  # 패딩에 마스크 추가  ?????\n",
    "  if mask is not None:\n",
    "    logits += (mask * -1e9)\n",
    "\n",
    "  # softmax적용\n",
    "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "  # 최종 어텐션은 가중치와 V의 닷 프로덕트\n",
    "  output = tf.matmul(attention_weights, value)\n",
    "  return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50d7bc0",
   "metadata": {},
   "source": [
    "##### MultiHeadAttention 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00fc5f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiHeadAttention 함수\n",
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "    super(MultiHeadAttention, self).__init__(name=name)\n",
    "    self.num_heads = num_heads\n",
    "    self.d_model = d_model\n",
    "\n",
    "    assert d_model % self.num_heads == 0\n",
    "\n",
    "    self.depth = d_model // self.num_heads\n",
    "\n",
    "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "  def split_heads(self, inputs, batch_size):\n",
    "    inputs = tf.reshape(\n",
    "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "  def call(self, inputs):\n",
    "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "        'value'], inputs['mask']\n",
    "    batch_size = tf.shape(query)[0]\n",
    "\n",
    "    # Q, K, V에 각각 Dense를 적용합니다\n",
    "    query = self.query_dense(query)\n",
    "    key = self.key_dense(key)\n",
    "    value = self.value_dense(value)\n",
    "\n",
    "    # 병렬 연산을 위한 머리를 여러 개 만듭니다\n",
    "    query = self.split_heads(query, batch_size)\n",
    "    key = self.split_heads(key, batch_size)\n",
    "    value = self.split_heads(value, batch_size)\n",
    "\n",
    "    # 스케일드 닷 프로덕트 어텐션 함수\n",
    "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "    # 어텐션 연산 후에 각 결과를 다시 연결(concatenate)합니다\n",
    "    concat_attention = tf.reshape(scaled_attention,\n",
    "                                  (batch_size, -1, self.d_model))\n",
    "\n",
    "    # 최종 결과에도 Dense를 한 번 더 적용합니다\n",
    "    outputs = self.dense(concat_attention)\n",
    "\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02961c68",
   "metadata": {},
   "source": [
    "##### 패딩 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4f075dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "  mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "  # (batch_size, 1, 1, sequence length)\n",
    "  return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17f1d6b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f70b7",
   "metadata": {},
   "source": [
    "##### look ahead 마스킹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e13aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "  seq_len = tf.shape(x)[1]\n",
    "  look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)  \n",
    "  # lower -1시 tf.linalg.band_part에서 아래쪽이 1로채워진 하삼각행렬아닌가? 아래 예를 보면\n",
    "  # 상삼각으로 위에가 1로 되었슴, 그러면 위의 1이 마스킹된다는 의미이지?\n",
    "  padding_mask = create_padding_mask(x)\n",
    "  return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3cb20a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 0. 1. 1.]\n",
      "   [0. 0. 0. 0. 1.]\n",
      "   [0. 0. 0. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 3, 4, 5]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12daebe7",
   "metadata": {},
   "source": [
    "##### (1) 인코더 레이어 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1a36979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 두 개의 서브 레이어가 존재합니다.\n",
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 어텐션의 결과는 Dropout과 Layer Normalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "  attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b579e3c",
   "metadata": {},
   "source": [
    "#####  (2) 인코더 모델 생성 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffe70077",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "\n",
    "  # 패딩 마스크 사용\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  # num_layers만큼 쌓아올린 인코더의 층.\n",
    "  for i in range(num_layers):\n",
    "    outputs = encoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name=\"encoder_layer_{}\".format(i),\n",
    "    )([outputs, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31183bb",
   "metadata": {},
   "source": [
    "##### (3) 디코더 레이어 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "45a68568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 하나의 레이어를 함수로 구현.\n",
    "# 이 하나의 레이어 안에는 세 개의 서브 레이어가 존재합니다.\n",
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "  inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "  # 첫 번째 서브 레이어 : 멀티 헤드 어텐션 수행 (셀프 어텐션)\n",
    "  attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "\n",
    "  # 멀티 헤드 어텐션의 결과는 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "  # 두 번째 서브 레이어 : 마스크드 멀티 헤드 어텐션 수행 (인코더-디코더 어텐션)\n",
    "  attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "\n",
    "  # 마스크드 멀티 헤드 어텐션의 결과는\n",
    "  # Dropout과 LayerNormalization이라는 훈련을 돕는 테크닉을 수행\n",
    "  attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "  attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "  # 세 번째 서브 레이어 : 2개의 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "\n",
    "  # 완전연결층의 결과는 Dropout과 LayerNormalization 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "  outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15b15cb",
   "metadata": {},
   "source": [
    "##### (4) 디코더 모델 생성함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dfc92a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "  inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "  enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "  look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "\n",
    "  # 패딩 마스크\n",
    "  padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "  \n",
    "  # 임베딩 레이어\n",
    "  embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "  embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "\n",
    "  # 포지셔널 인코딩\n",
    "  embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "  # Dropout이라는 훈련을 돕는 테크닉을 수행\n",
    "  outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "  for i in range(num_layers):\n",
    "    outputs = decoder_layer(\n",
    "        units=units,\n",
    "        d_model=d_model,\n",
    "        num_heads=num_heads,\n",
    "        dropout=dropout,\n",
    "        name='decoder_layer_{}'.format(i),\n",
    "    )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "  return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60b7ea6",
   "metadata": {},
   "source": [
    "##### (5) 트랜스포머 모델 생성함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9175de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "  inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "  dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "  # 인코더에서 패딩을 위한 마스크\n",
    "  enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "\n",
    "  # 디코더에서 미래의 토큰을 마스크 하기 위해서 사용합니다.\n",
    "  # 내부적으로 패딩 마스크도 포함되어져 있습니다.\n",
    "  look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "\n",
    "  # 두 번째 어텐션 블록에서 인코더의 벡터들을 마스킹\n",
    "  # 디코더에서 패딩을 위한 마스크\n",
    "  dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "  # 인코더\n",
    "  enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "  # 디코더\n",
    "  dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "  )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "  # 완전연결층\n",
    "  outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "  return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f919823",
   "metadata": {},
   "source": [
    "##### (6) 트랜스포머 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "10c9e088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 512)    7439872     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 512)    9543168     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 8367)   4292271     decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,275,311\n",
      "Trainable params: 21,275,311\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# 하이퍼파라미터\n",
    "NUM_LAYERS = 2 # 인코더와 디코더의 층의 개수\n",
    "D_MODEL = 512 # 인코더와 디코더 내부의 입, 출력의 고정 차원\n",
    "NUM_HEADS = 8 # 멀티 헤드 어텐션에서의 헤드 수 \n",
    "UNITS = 512 # 피드 포워드 신경망의 은닉층의 크기\n",
    "DROPOUT = 0.2 # 드롭아웃의 비율\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8bd522",
   "metadata": {},
   "source": [
    "#### (7) 트랜스포머 모델 손실 함수(Loss function)\n",
    "레이블인 시퀀스에 패딩이 되어 있으므로, loss를 계산할 때 패딩 마스크를 적용해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2c7e582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  \n",
    "  loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "  mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "  loss = tf.multiply(loss, mask)\n",
    "\n",
    "  return tf.reduce_mean(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a44afa6",
   "metadata": {},
   "source": [
    "##### (8) 트랜스포머 모델에 쓰일 커스텀 된 학습률(Learning rate) 함수\n",
    "딥러닝 모델학습 시 learning rate는 매우 중요한 하이퍼파라미터임, 최근에는 모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 고급 기법을 널리 사용, 이런 방법을 커스텀 학습률 스케줄링(Custom Learning rate Scheduling)이라함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eea40818",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "\n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e90e68",
   "metadata": {},
   "source": [
    "##### (9) 트랜스포머 모델 컴파일\n",
    "손실 함수와 커스텀 된 학습률(learning rate)을 사용하여 모델을 컴파일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d9ee21f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "  y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "  return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc479c78",
   "metadata": {},
   "source": [
    "##### (10) 트랜스포머 모델 훈련\n",
    "학습을 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2c122933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "168/168 [==============================] - 12s 43ms/step - loss: 4.5492 - accuracy: 0.1053\n",
      "Epoch 2/50\n",
      "168/168 [==============================] - 7s 43ms/step - loss: 3.5514 - accuracy: 0.1753\n",
      "Epoch 3/50\n",
      "168/168 [==============================] - 7s 43ms/step - loss: 3.2001 - accuracy: 0.1797\n",
      "Epoch 4/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 3.0207 - accuracy: 0.1900\n",
      "Epoch 5/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 2.8516 - accuracy: 0.1990\n",
      "Epoch 6/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 2.6696 - accuracy: 0.2115\n",
      "Epoch 7/50\n",
      "168/168 [==============================] - 7s 41ms/step - loss: 2.4655 - accuracy: 0.2282\n",
      "Epoch 8/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 2.2422 - accuracy: 0.2512\n",
      "Epoch 9/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 1.9990 - accuracy: 0.2789\n",
      "Epoch 10/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 1.7431 - accuracy: 0.3093\n",
      "Epoch 11/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 1.4822 - accuracy: 0.3407\n",
      "Epoch 12/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 1.2277 - accuracy: 0.3729\n",
      "Epoch 13/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.9794 - accuracy: 0.4087\n",
      "Epoch 14/50\n",
      "168/168 [==============================] - 7s 43ms/step - loss: 0.7626 - accuracy: 0.4413\n",
      "Epoch 15/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.5758 - accuracy: 0.4721\n",
      "Epoch 16/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.4212 - accuracy: 0.4996\n",
      "Epoch 17/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.3095 - accuracy: 0.5206\n",
      "Epoch 18/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.2306 - accuracy: 0.5345\n",
      "Epoch 19/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.1798 - accuracy: 0.5436\n",
      "Epoch 20/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.1561 - accuracy: 0.5470\n",
      "Epoch 21/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.1390 - accuracy: 0.5494\n",
      "Epoch 22/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.1321 - accuracy: 0.5507\n",
      "Epoch 23/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.1271 - accuracy: 0.5513\n",
      "Epoch 24/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.1224 - accuracy: 0.5525\n",
      "Epoch 25/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.1124 - accuracy: 0.5540\n",
      "Epoch 26/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.1066 - accuracy: 0.5548\n",
      "Epoch 27/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0910 - accuracy: 0.5591\n",
      "Epoch 28/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0841 - accuracy: 0.5613\n",
      "Epoch 29/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0744 - accuracy: 0.5632\n",
      "Epoch 30/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0693 - accuracy: 0.5646\n",
      "Epoch 31/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0663 - accuracy: 0.5657\n",
      "Epoch 32/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0583 - accuracy: 0.5675\n",
      "Epoch 33/50\n",
      "168/168 [==============================] - 7s 41ms/step - loss: 0.0548 - accuracy: 0.5683\n",
      "Epoch 34/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0528 - accuracy: 0.5687\n",
      "Epoch 35/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0492 - accuracy: 0.5696\n",
      "Epoch 36/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0468 - accuracy: 0.5702\n",
      "Epoch 37/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0420 - accuracy: 0.5717\n",
      "Epoch 38/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0381 - accuracy: 0.5726\n",
      "Epoch 39/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0379 - accuracy: 0.5726\n",
      "Epoch 40/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0375 - accuracy: 0.5726\n",
      "Epoch 41/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0341 - accuracy: 0.5734\n",
      "Epoch 42/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0331 - accuracy: 0.5739\n",
      "Epoch 43/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0313 - accuracy: 0.5742\n",
      "Epoch 44/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0289 - accuracy: 0.5750\n",
      "Epoch 45/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0298 - accuracy: 0.5748\n",
      "Epoch 46/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0269 - accuracy: 0.5753\n",
      "Epoch 47/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0265 - accuracy: 0.5756\n",
      "Epoch 48/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0248 - accuracy: 0.5760\n",
      "Epoch 49/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0252 - accuracy: 0.5757\n",
      "Epoch 50/50\n",
      "168/168 [==============================] - 7s 42ms/step - loss: 0.0239 - accuracy: 0.5761\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "history = model.fit(dataset, epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4c124d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "history.history.keys() dict_keys(['loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkIElEQVR4nO3deZgU1bnH8e/LDDBsIoHRsOkQVzARTUbikuuaGCIRzCXeK8aIcSGugNFr1FyNMWJciCEaNS5xixojGhJU1ChicLkRRkENEAQRYRQRUEGEYZl57x+nWpphBnqYqamert/neerprqW739Kh3jrn1DnH3B0REUmvVkkHICIiyVIiEBFJOSUCEZGUUyIQEUk5JQIRkZRTIhARSTklAkkFMyszMzez4hyOPcXMXmyOuETygRKB5B0zW2hm682sW63tM6KLeVlCoYkUJCUCyVfvAMMyK2b2FaB9cuHkh1xKNCINpUQg+eqPwMlZ68OB+7IPMLPOZnafmS0zs3fN7H/NrFW0r8jMxprZcjNbAAyq47N/MLMlZvaemV1lZkW5BGZm483sAzNbaWZTzWyfrH3tzOzXUTwrzexFM2sX7fuGmb1sZp+Y2WIzOyXa/ryZnZ71HZtVTUWloHPMbB4wL9r22+g7VpnZq2b2H1nHF5nZpWb2tpl9Gu3vbWY3m9mva53LRDM7P5fzlsKlRCD56p/ADmbWN7pAnwDcX+uYm4DOwJeAwwiJ40fRvjOA7wL7A+XA92t99h5gI7B7dMzRwOnk5klgD2An4DXggax9Y4GvAQcDXwAuAmrMbNfoczcBpcB+wMwcfw/gOODrQL9ofXr0HV8AHgTGm1lJtO8nhNLUMcAOwKnAGuBeYFhWsuwGfDP6vKSZu2vRklcLsJBwgfpf4FfAQOAZoBhwoAwoAtYD/bI+92Pg+ej9c8CZWfuOjj5bDOwMrAPaZe0fBkyJ3p8CvJhjrDtG39uZcGO1Fuhfx3GXABPq+Y7ngdOz1jf7/ej7j9xGHB9nfheYCwyp57g5wLei9+cCk5L+/60l+UX1jZLP/ghMBfpQq1oI6Aa0Bt7N2vYu0DN63wNYXGtfxq7RZ5eYWWZbq1rH1ykqnYwBjifc2ddkxdMWKAHeruOjvevZnqvNYjOzC4HTCOfphDv/TOP61n7rXuAkQmI9CfhtI2KSAqGqIclb7v4uodH4GOAvtXYvBzYQLuoZuwDvRe+XEC6I2fsyFhNKBN3cfcdo2cHd92HbTgSGEEosnQmlEwCLYqoCdqvjc4vr2Q7wGZs3hH+xjmM+HyY4ag+4CPgvoIu77wisjGLY1m/dDwwxs/5AX+Cv9RwnKaJEIPnuNEK1yGfZG929GngYGGNmnaI6+J+wqR3hYWCkmfUysy7AxVmfXQL8Hfi1me1gZq3MbDczOyyHeDoRksgKwsX76qzvrQHuAm4wsx5Ro+1BZtaW0I7wTTP7LzMrNrOuZrZf9NGZwH+aWXsz2z06523FsBFYBhSb2eWEEkHGncAvzWwPC/Y1s65RjJWE9oU/Ao+6+9oczlkKnBKB5DV3f9vdK+rZfR7hbnoB8CKh0fOuaN8dwNPA64QG3dolipOBNsBsQv36I0D3HEK6j1DN9F702X/W2n8h8CbhYvsRcC3Qyt0XEUo2F0TbZwL9o8/8htDesZRQdfMAW/c08BTwVhRLFZtXHd1ASIR/B1YBfwDaZe2/F/gKIRmIYO6amEYkTczsUELJaVfXBUBQiUAkVcysNTAKuFNJQDKUCERSwsz6Ap8QqsDGJRqM5BVVDYmIpJxKBCIiKdfiOpR169bNy8rKkg5DRKRFefXVV5e7e2ld+1pcIigrK6Oior6nCUVEpC5m9m59+1Q1JCKSckoEIiIpp0QgIpJyLa6NoC4bNmygsrKSqqqqpEOJXUlJCb169aJ169ZJhyIiBaIgEkFlZSWdOnWirKyMrGGFC467s2LFCiorK+nTp0/S4YhIgSiIqqGqqiq6du1a0EkAwMzo2rVrKko+ItJ8CiIRAAWfBDLScp4i0nwKompIRKSpVFfD2rVgBkVFm5ZWrTbfX1UVlsz7detg/frcl+pqaN0a2rTZ/LW4OOxft27Td2beH3ssHHBA05+zEkETWLFiBUcddRQAH3zwAUVFRZSWhg5806ZNo02bNvV+tqKigvvuu48bb7yxWWIVyScbN4aLaE0NuG++ZGQKwWZhcYfVq2HVqs2XTz+FNWvqv0hv2LD5sn592Pfpp5s+v2oVfPZZ3bFCSAY1NfXvj1uPHkoEeatr167MnDkTgCuuuIKOHTty4YUXfr5/48aNFBfX/Z+6vLyc8vLy5ghTJFY1NeFCvHQpLFkC778flsz7FStg5Ur45JPwunJluKDHpVUraNcOSkqgbdtwt117KSmB0lLYbTfYYQfo1Cm8tm8fEk519eZLTU34rpKSsGS+P7O0abPl0rp1+Ezt7a1abZ6UMq8bN4b9bdtu+lwm/rhqhpUIYnLKKadQUlLCjBkzOOSQQzjhhBMYNWoUVVVVtGvXjrvvvpu99tqL559/nrFjx/L4449zxRVXsGjRIhYsWMCiRYsYPXo0I0eOTPpUpMBUV295F7xmzaY758zrunVhe+ainVk++WTTnfOaNZte19Yz6WWbNtC9O3TrBjvuCF/8Ynjt3Dks7duHi2Lmjj97yZQMar927Bgu2NlLp07huzIX5+Li+C6cTaWkJOkIgoJLBKNHQ3Rz3mT22w/GjWv45yorK3n55ZcpKipi1apVvPDCCxQXF/Pss89y6aWX8uijj27xmX//+99MmTKFTz/9lL322ouzzjpLfQYkJ9XV8NFHsGwZLFoE7767+bJoUbgrX7OmYd9rFi6ymQv3jjvCzjtDhw5had8+LJn3O+0ULvw9eoTlC1/I/wty2hVcIsgnxx9/PEVFRQCsXLmS4cOHM2/ePMyMDRs21PmZQYMG0bZtW9q2bctOO+3E0qVL6dWrV3OGLXnks8+gsjJUt3z4YXjNfr98ebjwL18ekkDt6UWKi6FXL9h1VzjiiFANkrl7zlSDdOoULuKZKpRMNUfbtuHuulOnTQ2lUpgKLhFsz517XDp06PD5+8suu4wjjjiCCRMmsHDhQg4//PA6P9O2bdvP3xcVFbFx48a4w5QEuYf687fegvnz4Z13Nl8+/HDLz5iFC/pOO4XXffcN1S6lpeG1Wzfo3Ttc/Hv0CE+8iGxNwSWCfLVy5Up69uwJwD333JNsMJKITz6BZ5+FN94IF/65c2HevM2fUikqgl12gS99CQYPhj59wvoXvxgu/DvvHC70urhLU1IiaCYXXXQRw4cP56qrrmLQoEFJhyPNwB1mz4YnngjLSy+FevxWrcIFfs894bDDwuuee8Luu4dqnHoeMBOJTYubs7i8vNxrT0wzZ84c+vbtm1BEzS9t55tv3MPTNu+/Dx98sPnTN5nXpUvD3f/CheEz/fvDoEFh+drXQv27SHMys1fdvc5n1XXvIamX3VP0449D4+uyZaF+PvN+6dJNz8W///7WOx2ZhSdrvvENuOQSOOaYcKcvkq+UCKTgrF+/qQ5+yZJNT9hkv65eHS7+a9eGjjxb06lTqJ/v2TPczX/3u5sejdx553DRz34Kp317PS4pLUvBJAJ3T8WAbC2tKi9O7uHJmunTYdasUB8/a1ZogK2u3nRcq1ahgTXT2HrAAZt3PspeOnfe/Imc0tL86fQjEpeCSAQlJSWsWLGi4IeizsxHUJLSK1NVFbz2Grz88qZl6dKwr1WrMEzAPvvA0KHQrx/07Rvu4rt21VM2IltTEImgV69eVFZWsmzZsqRDiV1mhrI0+eADuPBCGD8+VPtAuOgffTQcfDB8/evhop/S/CjSaAWRCFq3bq0ZuwpQdTXcdhtcemmoyx8xAo48Eg46KDxXLyJNoyASgRSeGTPgzDNh2jQ46ii45ZbwrL2IND2NICJ55dNP4fzzobw8PIP/wAPwzDNKAiJxUolA8sY778C3vgULFoTSwJgx0KVL0lGJFD4lAskLs2eHJFBVBVOnhs5YItI8lAgkcRUVMHBgmIHpH/+AL3856YhE0kVtBJKoqVPDk0CdOsGLLyoJiCRBiUASM2kSfPvbodPXCy+EvgEi0vyUCCQRDz8MQ4aEHsBTp2pQNpEkKRFIs3v5ZTjxRDjwQHjuuTCej4gkR43F0qxWrYKTTgqzbj3xRBitU0SSpUQgzWrkSHj33VAdpCQgkh9UNSTNZvx4uPde+NnP4JBDko5GRDKUCKRZVFbCj38MAwbAZZclHY2IZFMikNjV1MDw4WEI6fvvDx3HRCR/xJoIzGygmc01s/lmdnEd+08xs2VmNjNaTo8zHknGDTeEp4PGjYM99kg6GhGpLbbGYjMrAm4GvgVUAtPNbKK7z6516J/d/dy44pBkzZwZ5hM47jg47bSkoxGRusRZIhgAzHf3Be6+HngIGBLj70meWbsWfvCDMF/wHXdoQneRfBVnIugJLM5ar4y21TbUzN4ws0fMrHddX2RmI8yswswq0jAdZaH4zW/CqKJ33x2SgYjkp6Qbix8Dytx9X+AZ4N66DnL329293N3LS9UNtUVYsQKuvRaOPTaMJyQi+SvORPAekH2H3yva9jl3X+Hu66LVO4GvxRiPNKNf/QpWr4arr046EhHZljgTwXRgDzPrY2ZtgBOAidkHmFn3rNXBwJwY45FmsmgR3HQTnHyyhpUWaQlie2rI3Tea2bnA00ARcJe7zzKzK4EKd58IjDSzwcBG4CPglLjikebz85+HhuFf/CLpSEQkF+buScfQIOXl5V5RUZF0GFKPf/0L+vcPE9CPHZt0NCKSYWavunt5XfuSbiyWAnPppdCxI1xySdKRiEiulAikybz4Ijz2GFx8MXTtmnQ0IpIrJQJpEu4hAXTvDqNGJR2NiDSE5iOQJvH44/DSS/D730P79klHIyINoRKBNFp1dWgT2HNPOPXUpKMRkYZSiUAa7f77YdasMPGMhpgWaXlUIpBGqa6GMWNg//1h6NCkoxGR7aESgTTK+PEwbx488ohGFxVpqVQikO1WUxPGEurbF773vaSjEZHtpRKBbLfHH4c334T77oNWuqUQabH0z1e2i3toG+jTB4YNSzoaEWkMlQhkuzz7LEybBrfdBsX6KxJp0VQikO0yZgz07AnDhycdiYg0lu7lpMFeegn+8Y8wFWXbtklHIyKNpRKBNNiYMWEO4jPOSDoSEWkKSgTSIK+9Bk8+GeYb6NAh6WhEpCkoEUiDjBkDnTvDOeckHYmINBUlAsnZ7Nnwl7/AeeeFZCAihUGJQHJ2zTVhiGnNNyBSWJQIJCeVlfCnP4UG4m7dko5GRJqSEoHk5MYbQ2/i0aOTjkREmpoSgWzTqlWhB/Hxx0NZWdLRiEhTUyKQbbrzzpAMLrgg6UhEJA5KBLJVGzbAuHFw+OFQXp50NCISBw0xIVs1fjwsXgy33JJ0JCISF5UIpF7uMHYs7L03HHNM0tGISFxUIpB6TZkCM2bAHXdo4hmRQqZ/3lKvsWNhp53gpJOSjkRE4qREIHWaNSsMLnfeeVBSknQ0IhInJQKp0w03QLt2cNZZSUciInFTIpAtLFkC998Pp54KXbsmHY2IxE2JQLbwu9+F/gPnn590JCLSHJQIZDNr18Ktt8L3vge77ZZ0NCLSHGJNBGY20Mzmmtl8M7t4K8cNNTM3M/VdTdif/wwffwwjRyYdiYg0l9gSgZkVATcD3wH6AcPMrF8dx3UCRgGvxBWL5O6WW6BfPzj00KQjEZHmEmeJYAAw390XuPt64CFgSB3H/RK4FqiKMRbJwfTpYTn7bDBLOhoRaS5xJoKewOKs9cpo2+fM7KtAb3d/YmtfZGYjzKzCzCqWLVvW9JEKENoGOnSAH/4w6UhEpDkl1lhsZq2AG4BtDm7s7re7e7m7l5eWlsYfXAp99FGYgeykk2CHHZKORkSaU5yJ4D2gd9Z6r2hbRifgy8DzZrYQOBCYqAbjZNxzD1RVqQOZSBrFmQimA3uYWR8zawOcAEzM7HT3le7ezd3L3L0M+Ccw2N0rYoxJ6lBTA7//PRxyCPTvn3Q0ItLcYksE7r4ROBd4GpgDPOzus8zsSjMbHNfvSsNNngzz5oVGYhFJn20OQ21mxwJPuHtNQ7/c3ScBk2ptu7yeYw9v6PdL07jlFigthaFDk45ERJKQS4ngv4F5Znadme0dd0DSvBYvhokT4fTToW3bpKMRkSRsMxG4+0nA/sDbwD1m9n/R45ydYo9OYnf77WEmshEjko5ERJKSUxuBu68CHiF0CusOfA94zczOizE2idn69WH2sUGDoKws6WhEJCnbTARmNtjMJgDPA62BAe7+HaA/OfQBkPw1YQIsXapGYpG0y2XO4qHAb9x9avZGd19jZqfFE5Y0h1tugT594NvfTjoSEUlSLlVDVwDTMitm1s7MygDcfXI8YUnc3ngDpk6FM8/UxPQiaZfLJWA8kP3oaHW0TVqw668P4wqdcUbSkYhI0nJJBMXR6KEARO/bxBeSxG3RojCu0BlnQJcuSUcjIknLJREsy+4JbGZDgOXxhSRxGzcuvGoqShGB3BqLzwQeMLPfAUYYWvrkWKOS2Hz8ceg7MGwY7LJL0tGISD7YZiJw97eBA82sY7S+OvaoJDa33gqffQYXXph0JCKSL3IpEWBmg4B9gBKLpq5y9ytjjEtiUFUFN94YHhfVKKMikpFLh7LfE8YbOo9QNXQ8sGvMcUkM/vjH0IHsf/4n6UhEJJ/k0lh8sLufDHzs7r8ADgL2jDcsaWo1NTB2LHz1q3DkkUlHIyL5JJeqocyk8mvMrAewgjDekLQgEyfCW2/BQw9pYnoR2VwuieAxM9sRuB54DXDgjjiDkqblDtdeGwaW05wDIlLbVhNBNMH8ZHf/BHjUzB4HStx9ZXMEJ03jpZfgn/+Em26C4pweDxCRNNlqG0E0K9nNWevrlARanuuvh65d4Uc/SjoSEclHuTQWTzazoWaqWW6J5swJ7QPnnBPGFhIRqS2XRPBjwiBz68xslZl9amarYo5Lmsh110G7dnDuuUlHIiL5KpeexZqSsoVavBjuvz8MNV1amnQ0IpKvtpkIzOzQurbXnqhG8s+vfx2eGNJwEiKyNbk8Q5LdD7UEGAC8CqhbUh5bvjzMR3ziibCr+oGLyFbkUjV0bPa6mfUGxsUVkDSN3/0O1qyBn/406UhEJN9tzySFlUDfpg5Ems7q1WFwucGDYZ99ko5GRPJdLm0ENxF6E0NIHPsRehhLnrrjjjDvwCWXJB2JiLQEubQRVGS93wj8yd1fiikeaaR160Ij8WGHwYEHJh2NiLQEuSSCR4Aqd68GMLMiM2vv7mviDU22xwMPwHvvwZ13Jh2JiLQUOfUsBtplrbcDno0nHGmM6urQgWy//cLkMyIiucilRFCSPT2lu682s/YxxiTb6a9/hblzNdS0iDRMLiWCz8zsq5kVM/sasDa+kGR7uMM118Buu8H3v590NCLSkuRSIhgNjDez9wlTVX6RMHWl5JHJk6GiAm67DYqKko5GRFqSXDqUTTezvYG9ok1z3X1DvGFJQ119NXTvDiefnHQkItLS5DJ5/TlAB3f/l7v/C+hoZmfn8uVmNtDM5prZfDO7uI79Z5rZm2Y208xeNLN+DT8FeeklmDIlTEpfUpJ0NCLS0uTSRnBGNEMZAO7+MXDGtj5kZkWESW2+A/QDhtVxoX/Q3b/i7vsB1wE35Bi3ZPnlL6FbNxgxIulIRKQlyiURFGVPShNd4Nvk8LkBwHx3X+Du64GHgCHZB7h79rwGHdjUg1lyNH06PP00XHCBJp4Rke2TS2PxU8Cfzey2aP3HwJM5fK4nsDhrvRL4eu2DoqqnnxCSS50jmprZCGAEwC677JLDT6fHVVdBly5wdk6VdSIiW8qlRPBT4DngzGh5k807mDWKu9/s7rtFv/O/9Rxzu7uXu3t5qWZY+dzrr4dpKEeNgh12SDoaEWmptpkIognsXwEWEqp7jgTm5PDd7wG9s9Z7Rdvq8xBwXA7fK5ExY6BTJxg5MulIRKQlq7dqyMz2BIZFy3LgzwDufkSO3z0d2MPM+hASwAnAibV+Yw93nxetDgLmITmZMwceeSSMMNqlS9LRiEhLtrU2gn8DLwDfdff5AGZ2fq5f7O4bzexc4GmgCLjL3WeZ2ZVAhbtPBM41s28CG4CPgeHbeR6pc/XVYVL60aOTjkREWrqtJYL/JNzFTzGzpwhVNw0awcbdJwGTam27POv9qIZ8nwTz58ODD8L552tSehFpvHrbCNz9r+5+ArA3MIUw1MROZnarmR3dTPFJHa65Blq3Do+Miog0Vi6NxZ+5+4PR3MW9gBmEJ3wkAe++C/feC2ecEYaUEBFprAbNWezuH0ePch4VV0CydddeG4aYvuiipCMRkUKxPZPXS0IWLAgzj516KvTuve3jRURyoUTQglx2GRQXw+WXb/tYEZFcKRG0EDNnhieFRo+GHj2SjkZECokSQQuR6TimtgERaWq5DDonCZsyBZ56Cq6/HnbcMeloRKTQqESQ59zh4ouhVy8499ykoxGRQqQSQZ77y19g2jT4wx80+5iIxEMlgjy2cSP87GfQt6/mIhaR+KhEkMfuvhvmzoUJE8JjoyIicVCJIE+tWQNXXAEHHQRDhmzzcBGR7ab7zDx1003w/vvwpz+FISVEROKiEkEe+uAD+NWv4Jhj4NBDk45GRAqdEkEeGjkS1q6FG25IOhIRSQNVDeWZv/0Nxo+Hq66CvfZKOhoRSQOVCPLIypVw9tnwla9oKAkRaT4qEeSRSy4J7QMTJoQZyEREmoNKBHnihRfg1lth1CgYMCDpaEQkTZQI8kBVVZh6sqwMfvnLpKMRkbRR1VAeGDMm9CB+6ino0CHpaEQkbVQiSNibb8I118APfwjf/nbS0YhIGikRJKi6Gk4/PcwxoD4DIpIUVQ0lxB3OOy8MMf3gg9CtW9IRiUhaqUSQkGuuCU8JXXQRDBuWdDQikmZKBAm47z649FL4wQ/CmEIiIklSImhmf/87nHYaHHUU3HUXtNL/ARFJmC5DzWjGDBg6FPr1g0cfhTZtko5IRESJoNksXBiGle7SBZ58Ejp3TjoiEZFATw01g+XLYeDA0IN48mTo0SPpiERENlGJIGZz54bpJhcuhIkTQ7WQiEg+USKI0ZQpIQmsXAnPPQf/8R9JRyQisqVYE4GZDTSzuWY238wurmP/T8xstpm9YWaTzWzXOONpTnfdBUcfDd27wyuvwMEHJx2RiEjdYksEZlYE3Ax8B+gHDDOz2hUjM4Byd98XeAS4Lq54mktNDfz0p+ER0SOPhJdfhj59ko5KRKR+cZYIBgDz3X2Bu68HHgKGZB/g7lPcfU20+k+gV4zxxG7NGjj+eLjuOjjrLHjiCT0dJCL5L85E0BNYnLVeGW2rz2nAk3XtMLMRZlZhZhXLli1rwhCbztNPQ//+YXaxcePg5puhWM9kiUgLkBeNxWZ2ElAOXF/Xfne/3d3L3b28tLS0eYPbhsrKUAoYODD0En722TDLmFnSkYmI5CbORPAe0DtrvVe0bTNm9k3gZ8Bgd18XYzxNasMGuP562HtvePzxMLnMG2+EdgERkZYkzsqL6cAeZtaHkABOAE7MPsDM9gduAwa6+4cxxtKkXnghtAHMmgXHHgu//a0ahEWk5YqtRODuG4FzgaeBOcDD7j7LzK40s8HRYdcDHYHxZjbTzCbGFU9TqKqCCy6Aww6D1avhb38LncSUBESkJYu1OdPdJwGTam27POv9N+P8/aY0Y0aYTnLWLDjzTBg7VvMLi0hhyIvG4nxWXR3mDPj61+Gjj2DSpDChjJKAiBQKPeC4FW+/DSefHDqFHX98SABduyYdlYhI01IiqOXtt0O9/2OPwdSp0LEj3H8/nHiiHgkVkcKkRABMnx4minnsMZg9O2z78pfDfMJnnw29WnR/ZxGRrUt9Ipg+PdT/FxWFp4FGjAiPhH7pS0lHJiLSPFKfCJ57DtzhnXd05y8i6ZT6p4amTYPddlMSEJH0UiKYBgMGJB2FiEhyUp0I3n8/DBqnRCAiaZbqRDBtWnhVIhCRNEt9Iiguhv33TzoSEZHkpD4R7LsvtGuXdCQiIslJbSKoqQl9CFQtJCJpl9pE8NZbsGqVEoGISGoTwSuvhFclAhFJu9QmgmnTwoBye++ddCQiIslKdSI44IAwxpCISJqlMhFUVcHrr6taSEQEUpoIXn8dNmxQIhARgZQmAvUoFhHZJLWJoHt36Nkz6UhERJKXykTwyiuhNKCpJ0VEUpgIPvoI5s0Ls5KJiEgKE0FFRXhV+4CISJC6RJBpKC4vTzYOEZF8kcpEsPfe0Llz0pGIiOSHVCUCd01NKSJSW6oSwaJFsHSpGopFRLKlKhGoI5mIyJZSlwjatAmzkomISJC6RLD//iEZiIhIkJpEsHFj6EOgaiERkc2lJhHMmQNr1qihWESktlgTgZkNNLO5ZjbfzC6uY/+hZvaamW00s+/HGYumphQRqVtsicDMioCbge8A/YBhZtav1mGLgFOAB+OKI6NbNxgyBHbfPe5fEhFpWYpj/O4BwHx3XwBgZg8BQ4DZmQPcfWG0rybGOAA47riwiIjI5uKsGuoJLM5ar4y2NZiZjTCzCjOrWLZsWZMEJyIiQYtoLHb329293N3LS0tLkw5HRKSgxJkI3gN6Z633iraJiEgeiTMRTAf2MLM+ZtYGOAGYGOPviYjIdogtEbj7RuBc4GlgDvCwu88ysyvNbDCAmR1gZpXA8cBtZjYrrnhERKRucT41hLtPAibV2nZ51vvphCojERFJSItoLBYRkfgoEYiIpJy5e9IxNIiZLQPe3c6PdwOWN2E4LUVazxvSe+4673TJ5bx3dfc6n79vcYmgMcyswt1TN219Ws8b0nvuOu90aex5q2pIRCTllAhERFIubYng9qQDSEhazxvSe+4673Rp1Hmnqo1ARES2lLYSgYiI1KJEICKScqlJBNuaNrNQmNldZvahmf0ra9sXzOwZM5sXvXZJMsY4mFlvM5tiZrPNbJaZjYq2F/S5m1mJmU0zs9ej8/5FtL2Pmb0S/b3/ORr4seCYWZGZzTCzx6P1gj9vM1toZm+a2Uwzq4i2NervPBWJIMdpMwvFPcDAWtsuBia7+x7A5Gi90GwELnD3fsCBwDnR/+NCP/d1wJHu3h/YDxhoZgcC1wK/cffdgY+B05ILMVajCINaZqTlvI9w9/2y+g406u88FYmArGkz3X09kJk2s+C4+1Tgo1qbhwD3Ru/vBY5rzpiag7svcffXovefEi4OPSnwc/dgdbTaOlocOBJ4JNpecOcNYGa9gEHAndG6kYLzrkej/s7TkgiabNrMFmpnd18Svf8A2DnJYOJmZmXA/sArpODco+qRmcCHwDPA28An0VDwULh/7+OAi4DMnOddScd5O/B3M3vVzEZE2xr1dx7rMNSSf9zdzaxgnxk2s47Ao8Bod18VbhKDQj13d68G9jOzHYEJwN7JRhQ/M/su8KG7v2pmhyccTnP7hru/Z2Y7Ac+Y2b+zd27P33laSgRpnzZzqZl1B4heP0w4nliYWWtCEnjA3f8SbU7FuQO4+yfAFOAgYEczy9zoFeLf+yHAYDNbSKjqPRL4LYV/3rj7e9Hrh4TEP4BG/p2nJRGkfdrMicDw6P1w4G8JxhKLqH74D8Acd78ha1dBn7uZlUYlAcysHfAtQvvIFOD70WEFd97ufom793L3MsK/5+fc/QcU+HmbWQcz65R5DxwN/ItG/p2npmexmR1DqFMsAu5y9zHJRhQPM/sTcDhhWNqlwM+BvwIPA7sQhvD+L3ev3aDcopnZN4AXgDfZVGd8KaGdoGDP3cz2JTQOFhFu7B529yvN7EuEO+UvADOAk9x9XXKRxieqGrrQ3b9b6Ocdnd+EaLUYeNDdx5hZVxrxd56aRCAiInVLS9WQiIjUQ4lARCTllAhERFJOiUBEJOWUCEREUk6JQKQWM6uORnbMLE02UJ2ZlWWPDCuSDzTEhMiW1rr7fkkHIdJcVCIQyVE0Dvx10Vjw08xs92h7mZk9Z2ZvmNlkM9sl2r6zmU2I5gp43cwOjr6qyMzuiOYP+HvUI1gkMUoEIltqV6tq6L+z9q10968AvyP0VAe4CbjX3fcFHgBujLbfCPwjmivgq8CsaPsewM3uvg/wCTA01rMR2Qb1LBapxcxWu3vHOrYvJEwCsyAa4O4Dd+9qZsuB7u6+Idq+xN27mdkyoFf2EAfRENnPRBOIYGY/BVq7+1XNcGoidVKJQKRhvJ73DZE99k01aquThCkRiDTMf2e9/l/0/mXCCJgAPyAMfgdhysCz4PPJYzo3V5AiDaE7EZEttYtm/Mp4yt0zj5B2MbM3CHf1w6Jt5wF3m9n/AMuAH0XbRwG3m9lphDv/s4AliOQZtRGI5ChqIyh39+VJxyLSlFQ1JCKScioRiIiknEoEIiIpp0QgIpJySgQiIimnRCAiknJKBCIiKff/wLnLCHRQHi8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# 학습율 변화 시각화\\nplt.plot(lrHistory.lr,'red')\\nplt.title('Model learning rate')\\nplt.xlabel('Epoch')\\nplt.ylabel('LearningRate')\\nplt.legend(['Train'], loc='upper left')\\nplt.show()\\n\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"history.history.keys()\", history.history.keys())\n",
    "    \n",
    "# 훈련 과정 시각화 (loss): train\n",
    "plt.plot(history.history['loss'],'blue')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()       \n",
    "\n",
    "# 훈련 과정 시각화 (accuracy): train\n",
    "plt.plot(history.history['accuracy'],'blue')\n",
    "plt.title('Model accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(['Train'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b337713",
   "metadata": {},
   "source": [
    "#### Step 5. 모델 평가하기\n",
    "Step 1에서 선택한 전처리 방법을 고려하여 입력된 문장에 대해서 대답을 얻는 예측 함수를 만듬.\n",
    "\n",
    "예측(inference) 단계는 기본적으로 다음과 같은 과정을 거칩니다.\n",
    "\n",
    "새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거친다.\n",
    "\n",
    "입력 문장을 토크나이징하고, START_TOKEN과 END_TOKEN을 추가한다.\n",
    "\n",
    "패딩 마스킹과 룩 어헤드 마스킹을 계산한다.\n",
    "\n",
    "디코더는 입력 시퀀스로부터 다음 단어를 예측한다.\n",
    "\n",
    "디코더는 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여 새로운 입력으로 사용한다.\n",
    "\n",
    "END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면 디코더는 동작을 멈춘다.\n",
    "\n",
    "위의 과정을 모두 담은 decoder_inference() 함수를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "85cfe002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  decoder_inference() 함수\n",
    "def decoder_inference(sentence):\n",
    "  sentence = preprocess_sentence(sentence)  \n",
    "  # 입력된 문장을 정수 인코딩 후, 시작 토큰과 종료 토큰을 앞뒤로 추가.\n",
    "  # ex) Where have you been? → [[8331   86   30    5 1059    7 8332]]\n",
    "  sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "  # 디코더의 현재까지의 예측한 출력 시퀀스가 지속적으로 저장되는 변수.\n",
    "  # 처음에는 예측한 내용이 없음으로 시작 토큰만 별도 저장. ex) 8331\n",
    "  output_sequence = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "  # 디코더의 인퍼런스 단계\n",
    "  for i in range(MAX_LENGTH):\n",
    "    # 디코더는 최대 MAX_LENGTH의 길이만큼 다음 단어 예측을 반복합니다.\n",
    "    predictions = model(inputs=[sentence, output_sequence], training=False)\n",
    "    predictions = predictions[:, -1:, :]\n",
    "\n",
    "    # 현재 예측한 단어의 정수\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "    # 만약 현재 예측한 단어가 종료 토큰이라면 for문을 종료\n",
    "    if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "      break\n",
    "\n",
    "    # 예측한 단어들은 지속적으로 output_sequence에 추가됩니다.\n",
    "    # 이 output_sequence는 다시 디코더의 입력이 됩니다.\n",
    "    output_sequence = tf.concat([output_sequence, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output_sequence, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd265e93",
   "metadata": {},
   "source": [
    "임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ecab07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(sentence):\n",
    "  # 입력 문장에 대해서 디코더를 동작 시켜 예측된 정수 시퀀스를 리턴받습니다.\n",
    "  prediction = decoder_inference(sentence)\n",
    "\n",
    "  # 정수 시퀀스를 다시 텍스트 시퀀스로 변환합니다.\n",
    "  predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "  print('입력 : {}'.format(sentence))\n",
    "  print('출력 : {}'.format(predicted_sentence))\n",
    "\n",
    "  return predicted_sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dfa175",
   "metadata": {},
   "source": [
    "#### 7가지 질문또는 멘트에 대한 모델의 응답:  5개는 일상생활관련, 2개는 주식및 정치관련 대화내용임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a6a2058c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 날씨가 춥지요 ?\n",
      "출력 : 감기 조심하세요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'감기 조심하세요 . '"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation('날씨가 춥지요 ?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "54687820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 요즘 주식시장 불투명하네요\n",
      "출력 : 많이 힘들었을 거라 생각해요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'많이 힘들었을 거라 생각해요 . '"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"요즘 주식시장 불투명하네요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4700fd4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 너는 누구니\n",
      "출력 : 저는 위로해드리는 로봇이에요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'저는 위로해드리는 로봇이에요 . '"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"너는 누구니\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d5a78f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 공부 골아프지만 재미있네요\n",
      "출력 : 미래의 배우자가 달라져요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'미래의 배우자가 달라져요 . '"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"공부 골아프지만 재미있네요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "752fd35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 즐거운 하루되세요\n",
      "출력 : 내일은 만날 수 있을 거예요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'내일은 만날 수 있을 거예요 . '"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"즐거운 하루되세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2a4ac5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 우리나라 정치문화 개선해야지요?\n",
      "출력 : 하나씩 의 취향 차이입니다 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'하나씩 의 취향 차이입니다 . '"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"우리나라 정치문화 개선해야지요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "35b12229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : 인재에게는 책임감이 필요하지요\n",
      "출력 : 그럴거예요 . \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'그럴거예요 . '"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_generation(\"인재에게는 책임감이 필요하지요\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca5e6cc",
   "metadata": {},
   "source": [
    "#### [질문에 대한 모델의 응답의 적절성 수준 평가]\n",
    "일상생활멘트및 질문과 주식시장, 정치측면 질문및 멘트를 섞어서 7개를 했는데, 정치측면 질문은 전혀 엉뚱하지는 않지만, 어울리지 않는\n",
    "응답이 나왔으나, 나머지 6개는 그럴듯하다는 생각이 들수 있는 응답을 했다는 평가를 할수 있겠습니다.\n",
    "\n",
    "Epoch 50정도인데, 이전 프로젝트에서의 seq2seq 모델의 결과보다 조금은 더 그럴듯하다는 생각이 듭니다만, GPT3를 만든 트랜스포머의 잠재능력이 발휘되도록 데이터가 충분했으면 평가가 훨씬 더좋았겠다 생각을 해봤습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3526481f",
   "metadata": {},
   "source": [
    "## 회고 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b8a80a",
   "metadata": {},
   "source": [
    "본 프로젝트는 트랜스포머의 작업처리과정과 내부구조를 익히며, 한글 corpus를 사용하여,트랜스포머 챗봇을 만들어서, 성능을 평가해보는 프로젝트입니다.\n",
    "\n",
    "#### Step 1. 데이터 수집하기\n",
    "\n",
    "한국어 챗봇 데이터는 송영숙님이 공개한 챗봇 데이터를 사용하는데, 사랑과 이별, 일상의 대화가 Question, Answer형태로 짝을 이룬 \n",
    "11823개의 문장 pair로 되어있습니다.(라벨도 있는데 제외) \n",
    "\n",
    "데이터의 내용을 눈으로 처음부터 끝까지 대략 살펴보면,Question, Answer 데이터가 일상생활의 대화이고 1만여개가 조금 넘는 적은 데이터라서, 일상생활에 관한 대화를 할수 있는 챗봇으로서, 그외 뉴스, 철학적이나, 전문적인 내용을 대화할수 있는 종합형 챗봇이 될수는 없을 것 같았습니다.  \n",
    "\n",
    "#### Step 2. 데이터 전처리하기\n",
    "\n",
    "먼저, 전처리 함수를 만들었는데, csv dataframe형태로 로드한 11823개의 문장을 일괄 전처리하는 preprocess_sentence_df(Question, Answer)함수와,  문장 하나씩을 전처리하면서,모델학습후 추론하는데 쓸수있는 preprocess_sentenc(sentence)함수를 만들었습니다.\n",
    "preprocess_sentence_df(Question, Answer)를 통해서, 불필요한 특수문자,공백,구두점처리, 토크나이저가 한글형태소분석기가 아닌데다, 영어가 섞인 문장들이 더러 있어서, 한글과 영어를 포함해서 데이터 정제를 했으며,,결측치는 없었고, 중복문장은 제거하지 않았는데 이는 대화형 문장이므로,멘트가 반복될수 있어서였습니다. \n",
    "이렇게 해서 데이터 1차 전처리를 깔끔하게 완료하였습니다.\n",
    "\n",
    "#### Step 3. SubwordTextEncoder 사용하기 : 2차 전처리로  병렬 데이터  토크나이징 실행\n",
    "한국어 데이터는 형태소 분석기를 사용하여 토크나이징을 해야 한다고 생각했는데, 여기서는 프로젝트 가이드에서 추천하고,전 교재에서 사용했던 내부 단어 토크나이저인 SubwordTextEncoder를 그대로 사용했습니다.\n",
    "TensorFlow Datasets SubwordTextEncoder 를 토크나이저로 사용해서, 단어보다 더 작은 단위인 Subword를 기준으로 토크나이징하고, 각 토큰을 고유한 정수로 인코딩, 각 문장을 토큰화하고 각 문장의 시작과 끝을 나타내는 START_TOKEN 및 END_TOKEN을 추가, 최대 길이 MAX_LENGTH 설정및 MAX_LENGTH를 넘는 문장들은 필터링, MAX_LENGTH보다 길이가 짧은 문장들은 MAX_LENGTH에 맞도록 패딩했습니다.\n",
    "\n",
    "###### 가) 단어장(Vocabulary) 만들기\n",
    "\n",
    "각 단어에 고유한 정수 인덱스를 부여하기 위해서 단어장을 만들었는데, 질문과 답변 데이터셋을 모두 사용했으며,\n",
    "시작 토큰과 종료 토큰에 고유한 정수를 부여했습니다.\n",
    "tokenizing 결과를 보면, tokenizer 의 크기(target_size)를 8192(= 2 ** 13)개로 했는데, tokenizer.vocab_size는 그것보다 많은 8365개가 되었으며, START_TOKEN 8365번, END_TOKEN 8366번의 정수인덱스를 부여했습니다.\n",
    "\n",
    "###### 나) 각 단어를 고유한 정수로 인코딩(Integer encoding) \n",
    "위에서 tensorflow_datasets의 SubwordTextEncoder를 사용해서 Vocabulary를 만들고서,tokenizer.encode()로 각 단어를 정수인덱스로 변환하거나,tokenizer.decode()를 통해 정수인덱스 문장을 단어인덱스 문장으로 변환할 수 있게 되었습니다.\n",
    "\n",
    "######  max_length 설정 & 패딩(Padding)\n",
    "question, answer 데이터의 분포를 살펴보면, 둘다 공히 평균 5.5 내외, 표준편차 2.5 내외, 최대길이는 각 21개, 29개인데, 히스토그램을 보니, max 산정에는 평균치, 표준편차, 시작토큰1개, 종료토큰1개포함하여 12개이면 충분할 것으로 판단되어\n",
    "MAX_LENGTH는 12로 설정했습니다. \n",
    "\n",
    "그리고서, tokenize_and_filter(inputs, outputs)함수를 만들어서, 전체 정수 인코딩, MAX_LENGTH 12 를 초과하는 샘플 제거,tf.keras.preprocessing.sequence.pad_sequences을 이용한 'post'방식의 패딩처리를 하였습니다.\n",
    "\n",
    "###### 다). 교사 강요(Teacher Forcing) 사용하기\n",
    "\n",
    "seq2seq에서와 마찬가지로 트랜스포머 디코더에서도 교사 강요(Teacher Forcing) 를 적용하였는데,.\n",
    "decoder input data 은 <START_TOKEN>부터 시작하되, 마지막토큰을 없앴고,decoder target data 는 <START_TOKEN>을 없애고 시작했습니다\n",
    "\n",
    "question, answer의 pair를 tf.data.Dataset API의 입력으로 사용하여 파이프라인을 구성하고 교사 강요를 위해서 answers[:, :-1]를 decoder input data 로, answers[:, 1:]를 decoder target data로 사용했습니다.\n",
    "    \n",
    "이때, 데이터 파이프 라인내에 BATCH_SIZE = 64, BUFFER_SIZE = 12000 로 설정했고, 데이터 batch를 미리 가져와서,대기시켜 처리속도 빠르게 하는 dataset.prefetch(tf.data.experimental.AUTOTUNE) 기능을 처음 사용해 보았습니다. \n",
    "\n",
    "\n",
    "#### Step 4. 모델 구성하기\n",
    "    \n",
    "먼자,모델구성에 필요한 함수로 실습시간에 배운 포지셔널 인코딩 레이어 함수, 스케일드 닷 프로덕트 어텐션 함수,    \n",
    "MultiHeadAttention 함수, 패딩 마스킹,look ahead 마스킹함수를 생성하고서,\n",
    "다음의 순서로 모델을 구성하였습니다.\n",
    "\n",
    "포지셔널 인코딩 레이어 함수에서, 사인,코사인 곡선이 -1~1 사이로 주기성있게 교차와 시차를 반복적 파동하며 서로 다르게 움직이긴 하는데, 궤적상 포지셔널인덱싱 위치를 지정하는데,사인곡선과 코사인 곡선이 주기적으로  교차되는 곳에서는 position이 동일해져서, 타임스텝상 문제가 생기지 않을까 의문이 생겨서, model dimention을 10000개까지 늘려서, 동일해지지 않는지 리스트 컴프리헨션내에서 두쌍을  대비시켜 보았는데, x축이positional 인덱스인 정수에서는 교차하지 않고, positional 인덱스인 정수 사이의 소수점에서만 동일해져서, 전혀 상관없았습니다. \n",
    "\n",
    "(1) 인코더 레이어 함수 만들었고,   \n",
    "\n",
    "(2) 인코더 모델 생성 함수만들었고,\n",
    "\n",
    "(3) 디코더 레이어 함수만들었고,\n",
    "\n",
    "(4) 디코더 모델 생성함수만들었고,   \n",
    "\n",
    "(5) 트랜스포머 모델 생성함수만들었고,    \n",
    "\n",
    "(6) 트랜스포머 모델 생성:  하이퍼파라미터는 \n",
    "\n",
    "NUM_LAYERS = 2, \n",
    "D_MODEL = 512, \n",
    "NUM_HEADS = 8, \n",
    "UNITS = 512, \n",
    "DROPOUT = 0.2 \n",
    "로 설정\n",
    "    \n",
    "(7) 트랜스포머 모델 손실 함수(Loss function)만들었고,\n",
    "\n",
    "(8) 트랜스포머 모델에 쓰일 커스텀 된 학습률(Learning rate) 함수:\n",
    "\n",
    "모델학습 초기에 learning rate를 급격히 높였다가, 이후 train step이 진행됨에 따라 서서히 낮추어 가면서 안정적으로 수렴하게 하는 커스텀 학습률 스케줄링(Custom Learning rate Scheduling) 사용   \n",
    "    \n",
    "(9) 트랜스포머 모델 컴파일: 손실 함수와 커스텀 된 학습률(learning rate)을 사용하여 모델을 컴파일    \n",
    "    \n",
    "(10) 트랜스포머 모델 훈련: Epoch 50으로 학습을 진행했으며, history에 학습과정의 loss, accuracy 기록했습니다.\n",
    "     여러번의 Epoch 변경끝에 Epoch 50로 결정하고,학습결과로는  loss 0.0239, accuracy: 0.5761 이었습니다. \n",
    "     Epoch 50으로 한 이유는 valid data가 없어서, 과적합을 파악하기 곤란해서,Epoch를 얼마나 길게 해야할지 파악이 않되는 점이 \n",
    "     좀 아쉬웠습니다. \n",
    "    \n",
    "(11) 훈련 과정 시각화: 학습loss,  학습 accuracy 를 Epoch 진행에따라 궤적을 보았는데, Epoch 20넘어가면서 부터 수렴되었습니다.     \n",
    "    \n",
    "#### Step 5. 모델 평가하기\n",
    "Step 1에서 선택한 한문장단위 전처리함수를 사용하여, 입력된 문장에 대해서 대답을 얻는 decoder_inference() 함수를 만들었습니다.\n",
    "\n",
    "decoder_inference() 함수내에는 새로운 입력 문장에 대해서는 훈련 때와 동일한 전처리를 거치고, 입력 문장을 토크나이징하고,\n",
    "START_TOKEN과 END_TOKEN을 추가하고서, 패딩 마스킹과 룩 어헤드 마스킹을 하며, \n",
    "디코더는 디코더 입력 시퀀스로부터 다음 타임스텝의 단어를 예측하며, 예측된 다음 단어를 기존의 입력 시퀀스에 추가하여,\n",
    "새로운 입력으로 사용하는 과정을 코딩했습니다. 그 과정을 반복하다가, END_TOKEN이 예측되거나 문장의 최대 길이에 도달하면,\n",
    "디코더는 동작을 멈추고, 예측을 종료하게끔 코딩을 했습니다.\n",
    "\n",
    "임의의 입력 문장에 대해서 decoder_inference() 함수를 호출하여 챗봇의 대답을 얻는 sentence_generation() 함수를 만들었고,\n",
    "이 함수를 통하여, Question input sentence에대해, 얼마나 그럴듯하고, 납득이 가는 Answer output sentence를 내는지\n",
    "평가를 하였습니다.\n",
    "\n",
    "#### [질문에 대한 모델의 응답의 적절성 수준 평가]\n",
    "일상생활멘트및 질문과 주식시장, 정치측면 질문및 멘트를 섞어서 7개를 했는데, 정치측면 질문은 전혀 엉뚱하지는 않지만, 어울리지 않는\n",
    "응답이 나왔으나, 나머지 6개는 맥락에 그럴듯하게 맞다는 생각이 들수 있는 응답을 했다는 평가를 할수 있겠습니다.\n",
    "\n",
    "Epoch 50정도인데, 이전 프로젝트에서의 seq2seq 모델의 결과보다 조금 더 맥락상 그럴듯하다는 생각이 듭니다만, GPT3를 만든 트랜스포머의 잠재능력이 발휘되도록 데이터가 충분했으면 맥락상 평가가 훨씬 더좋았겠다는 생각을 해봤습니다.\n",
    " \n",
    "그리고, 초거대 Ai챗봇인 GPT3를 만들만큼 Capacity가 큰 모델이라 일상생활 대화 11000여개문장은 작아서, 충분히 평가받지 못한다는 생각이 일견 들었으나, 그러한 트랜스포머를 이렇게 프로젝트를 통해서 익힐수 있어서 아주 좋은 학습이었고, 이번 프로젝트에서 익힌 트랜스포머의 지식을 토대로 심화학습단계에서, 더 깊게 더 크게 모델을 확장해서, 더 충분한 데이터로 트랜스포머 모델의 능력을 확인해 보고 싶습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16273d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b06492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "baf4c246",
   "metadata": {},
   "source": [
    "## 루브릭\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "평가문항\t상세기준\n",
    "\n",
    "#### 1. 한국어 전처리를 통해 학습 데이터셋을 구축하였다.\n",
    "\n",
    "공백과 특수문자 처리, 토크나이징, 병렬데이터 구축의 과정이 적절히 진행되었다.\n",
    "\n",
    "#### 2. 트랜스포머 모델을 구현하여 한국어 챗봇 모델 학습을 정상적으로 진행하였다.\n",
    "\n",
    "구현한 트랜스포머 모델이 한국어 병렬 데이터 학습 시 안정적으로 수렴하였다.\n",
    "\n",
    "#### 3. 한국어 입력문장에 대해 한국어로 답변하는 함수를 구현하였다.\n",
    "\n",
    "한국어 입력문장에 맥락에 맞는 한국어로 답변을 리턴하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301880a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
