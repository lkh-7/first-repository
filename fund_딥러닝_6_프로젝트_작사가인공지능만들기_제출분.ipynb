{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16a51821",
   "metadata": {},
   "source": [
    "## 6-7. 프로젝트: 멋진 작사가 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1055f86",
   "metadata": {},
   "source": [
    "#### 라이브러리 버전을 확인해 봅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10da0cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import glob  #glob 모듈의 glob 함수는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2948769",
   "metadata": {},
   "source": [
    "### Step 1. 데이터 다운로드\n",
    "\n",
    "이미 실습(1) 데이터 다듬기에서 Cloud shell에 심볼릭 링크로 ~/aiffel/lyricist/data를 생성하셨다면, ~/aiffel/lyricist/data/lyrics에 데이터가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353b300b",
   "metadata": {},
   "source": [
    "### Step 2. 데이터 읽어오기\n",
    "\n",
    "glob 모듈을 사용하면 파일을 읽어오는 작업을 하기가 아주 용이해요. glob 를 활용하여 모든 txt 파일을 읽어온 후, raw_corpus 리스트에 문장 단위로 저장하도록 할게요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5eaacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txt_list 49 ['/aiffel/aiffel/lyricist/data/lyrics/michael-jackson.txt', '/aiffel/aiffel/lyricist/data/lyrics/blink-182.txt', '/aiffel/aiffel/lyricist/data/lyrics/nursery_rhymes.txt', '/aiffel/aiffel/lyricist/data/lyrics/jimi-hendrix.txt', '/aiffel/aiffel/lyricist/data/lyrics/eminem.txt', '/aiffel/aiffel/lyricist/data/lyrics/al-green.txt', '/aiffel/aiffel/lyricist/data/lyrics/cake.txt', '/aiffel/aiffel/lyricist/data/lyrics/bob-dylan.txt', '/aiffel/aiffel/lyricist/data/lyrics/bjork.txt', '/aiffel/aiffel/lyricist/data/lyrics/leonard-cohen.txt']\n",
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['', '', '[Spoken Intro:]', 'You ever want something ', \"that you know you shouldn't have \"]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*' \n",
    "txt_list = glob.glob(txt_file_path)\n",
    "print('txt_list',len(txt_list), txt_list[:10])\n",
    "\n",
    "raw_corpus = [] \n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines() \n",
    "        raw_corpus.extend(raw) \n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8faf02fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples:\n",
      " ['', '', '[Spoken Intro:]', 'You ever want something ', \"that you know you shouldn't have \", \"The more you know you shouldn't have it, \", 'The more you want it ', 'And then one day you get it, ', \"It's so good too \", \"But it's just like my girl \"]\n",
      "U x \n",
      "U x \n",
      "U x [Spoken Intro:]\n",
      "D x \n",
      "U x You ever want something \n",
      "OK You ever want something \n",
      "U x that you know you shouldn't have \n",
      "OK that you know you shouldn't have \n"
     ]
    }
   ],
   "source": [
    "print(\"Examples:\\n\", raw_corpus[:10])\n",
    "for x in raw_corpus[:5]:\n",
    "    print('U x',x)\n",
    "    if len(x)==0:\n",
    "        continue\n",
    "    if x[-1]==']':\n",
    "        print('D x','')\n",
    "        continue\n",
    "    print('OK',x)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78da76f7",
   "metadata": {},
   "source": [
    "### Step 3. 데이터 정제\n",
    "\n",
    "앞서 배운 테크닉들을 활용해 문장 생성에 적합한 모양새로 데이터를 정제하세요!\n",
    "\n",
    "preprocess_sentence() 함수를 만든 것을 기억하시죠? 이를 활용해 데이터를 정제하도록 하겠습니다.\n",
    "\n",
    "추가로 지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거합니다. 너무 긴 문장은 노래 가사 작사하기에 어울리지 않을 수도 있겠죠.\n",
    "그래서 이번에는 문장을 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외하기 를 권합니다.\n",
    "\n",
    "그래서, tf.keras.preprocessing.sequence.pad_sequences()메소드의 maxlen=15 할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a0469c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You ever want something \n",
      "that you know you shouldn't have \n",
      "The more you know you shouldn't have it, \n",
      "The more you want it \n",
      "And then one day you get it, \n",
      "It's so good too \n",
      "But it's just like my girl \n",
      "When she's around me \n"
     ]
    }
   ],
   "source": [
    "# enumerate() 함수를 이용하여 raw_corpus list 내에 저장된 문장과 그 문장의 인덱스를 반환 (인덱스, 문장 순)\n",
    "# 원치않는 문장:화자가 표기된 문장,공백인 문장 제외\n",
    "import re \n",
    "\n",
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   # 길이가 0인 문장은 건너뜁니다.\n",
    "    if sentence[-2] == \":\" or sentence[-1] == \"]\":\n",
    "        continue  # 문장의 끝이 ], 끝에서 두번째가 : 인 문장은 건너뜁니다.\n",
    "    if idx > 10: break   # 일단 문장 10개만 확인해 볼 겁니다.\n",
    "        \n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6bbc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
    "#     2. 특수문자 양쪽에 공백을 넣고\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
    "#     5. 다시 양쪽 공백을 지웁니다\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
    "# 이 순서로 처리해주면 문제가 되는 상황을 방지할 수 있겠네요!\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2   # \\1 : 1~9사이가능,  숫자는 그룹을 나타냄 \n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보세요.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4869d83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> spoken intro <end>',\n",
       " '<start> you ever want something <end>',\n",
       " '<start> that you know you shouldn t have <end>',\n",
       " '<start> the more you know you shouldn t have it , <end>',\n",
       " '<start> the more you want it <end>',\n",
       " '<start> and then one day you get it , <end>',\n",
       " '<start> it s so good too <end>',\n",
       " '<start> but it s just like my girl <end>',\n",
       " '<start> when she s around me <end>',\n",
       " '<start> i just feel so good , so good <end>']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 정제된 문장을 모을겁니다\n",
    "corpus = []\n",
    "\n",
    "# raw_corpus list에 저장된 문장들을 순서대로 반환하여 sentence에 저장\n",
    "for sentence in raw_corpus:\n",
    "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
    "    if len(sentence) == 0: continue\n",
    "    if sentence[-1] == \":\": continue\n",
    "    \n",
    "    # 위에서 구현한 preprocess_sentence() 함수를 이용하여 문장을 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과를 10개만 확인해보죠\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dc74f0",
   "metadata": {},
   "source": [
    "### Step 4. 평가 데이터셋 분리\n",
    "\n",
    "훈련 데이터와 평가 데이터를 분리하세요!\n",
    "\n",
    "tokenize() 함수로 데이터를 Tensor로 변환한 후, sklearn 모듈의 train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 분리하도록 하겠습니다. 단어장의 크기는 12,000 이상 으로 설정하세요! 총 데이터의 20% 를 평가 데이터셋으로 사용해 주세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86a5a894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2 2701 2584 ...    0    0    0]\n",
      " [   2    7  156 ...    0    0    0]\n",
      " [   2   17    7 ...    0    0    0]\n",
      " ...\n",
      " [   2  311    1 ...    0    0    0]\n",
      " [   5   34   45 ... 1161  143    3]\n",
      " [   5   34   45 ... 1161  143    3]] <keras_preprocessing.text.Tokenizer object at 0x7f1581824e50>\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 할 때 텐서플로우의 Tokenizer와 pad_sequences를 사용합니다\n",
    "\n",
    "def tokenize(corpus):\n",
    "    # 15000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
    "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
    "    # 15000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=15000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
    "    # tokenizer.fit_on_texts(texts): 문자 데이터를 입력받아 리스트의 형태로 변환하는 메서드\n",
    "    \n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
    "    # tokenizer.texts_to_sequences(texts): 텍스트 안의 단어들을 숫자의 시퀀스 형태로 변환하는 메서드\n",
    "    \n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    \n",
    "    # maxlen = 15, 입력 데이터의 시퀀스 길이를  15개로 맞춰줍니다\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
    "    \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,maxlen=15, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff6cbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175749, 15) [[   2 2701 2584    3    0    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2    7  156   62  199    3    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2   17    7   34    7 1518   15   76    3    0    0    0    0    0\n",
      "     0]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor.shape, tensor[:3, :15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "283914ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : ,\n",
      "5 : i\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "# tokenizer.index_word: 현재 계산된 단어의 인덱스와 인덱스에 해당하는 단어를 dictionary 형대로 반환 (Ex. {index: '~~', index: '~~', ...})\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abbceaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2 2701 2584    3    0    0    0    0    0    0    0    0    0    0]\n",
      "[2701 2584    3    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
    "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "\n",
    "src_input = tensor[:, :-1]  \n",
    "\n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22a5b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140599, 14) (35150, 14) (140599, 14) (35150, 14)\n"
     ]
    }
   ],
   "source": [
    "# train, test 분리: 0.8:0.2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val= train_test_split(src_input,tgt_input, test_size=0.2, random_state=7)\n",
    "print(enc_train.shape, enc_val.shape, dec_train.shape, dec_val.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb7f144c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140599 1098 15001\n"
     ]
    }
   ],
   "source": [
    "### 하이퍼 파라메터들 설정\n",
    "\n",
    "BATCH_SIZE = 128 #256\n",
    "embedding_size = 1024 #1024 #512 # 256 \n",
    "hidden_size = 2048 #1024 \n",
    "lr = 0.001 #0.001 \n",
    "\n",
    "BUFFER_SIZE = len(enc_train)\n",
    "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
    "VOCAB_SIZE = tokenizer.num_words + 1  \n",
    "print(BUFFER_SIZE,steps_per_epoch,VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8cde2",
   "metadata": {},
   "source": [
    "### Step 5. 인공지능 만들기\n",
    "\n",
    "모델의 Embedding Size와 Hidden Size를 조절하며 10 Epoch 안에 val_loss 값을 2.2 수준으로 줄일 수 있는 모델을 설계하세요!\n",
    "\n",
    "잘 설계한 모델을 학습하려면, model.fit() 함수를 사용해야 합니다. model.fit() 함수에는 다양한 인자를 넣어주어야 하는데, 가장 기본적인 인자로는 데이터셋과 epochs가 있습니다. '5. 실습 (2) 인공지능 학습시키기'에서의 예시와 같이 말이죠.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "628df5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성되어 있다.\n",
    "        # Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
    "        # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다. \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
    "        self.batchnormal_0 = tf.keras.layers.BatchNormalization()\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True) \n",
    "        self.batchnormal_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.batchnormal_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        #out = self.batchnormal_0(out)\n",
    "        out = self.rnn_1(out)\n",
    "        #out = self.batchnormal_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        #out = self.batchnormal_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b863cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 14, 15001), dtype=float32, numpy=\n",
       "array([[[-8.3756713e-05, -3.7794863e-04,  5.1459003e-05, ...,\n",
       "         -3.3421817e-05,  1.4434472e-05, -1.3647269e-04],\n",
       "        [ 9.9452875e-05, -8.5770484e-04, -1.8902957e-04, ...,\n",
       "          8.7153858e-06, -4.7316196e-05, -2.3816411e-04],\n",
       "        [ 3.4091121e-04, -1.1964323e-03, -3.0462371e-04, ...,\n",
       "         -5.3052965e-04,  3.5155041e-04,  3.3987648e-04],\n",
       "        ...,\n",
       "        [ 2.0194899e-03,  2.2676219e-03, -1.6849788e-03, ...,\n",
       "         -1.1314331e-03, -1.1915958e-04,  8.7994558e-04],\n",
       "        [ 2.1806210e-03,  2.8568129e-03, -2.1170930e-03, ...,\n",
       "         -9.4553147e-04, -3.3915110e-04,  1.0571892e-03],\n",
       "        [ 2.2428269e-03,  3.4472137e-03, -2.5356647e-03, ...,\n",
       "         -7.4828556e-04, -5.5131776e-04,  1.1510400e-03]],\n",
       "\n",
       "       [[-8.3756713e-05, -3.7794863e-04,  5.1459003e-05, ...,\n",
       "         -3.3421817e-05,  1.4434472e-05, -1.3647269e-04],\n",
       "        [-2.3874566e-04, -8.1688326e-05, -2.9921832e-06, ...,\n",
       "          2.5945759e-04,  8.0013087e-05, -1.5564967e-04],\n",
       "        [-3.9290776e-04,  1.4695634e-04, -5.2559207e-04, ...,\n",
       "          7.3359930e-05,  2.8934007e-04, -2.4700264e-04],\n",
       "        ...,\n",
       "        [ 2.6794762e-04,  1.5186711e-03,  2.0843693e-04, ...,\n",
       "         -1.8310437e-03,  1.1844828e-03, -1.2407388e-04],\n",
       "        [ 7.2943821e-04,  1.9204638e-03, -9.2124188e-05, ...,\n",
       "         -1.8279802e-03,  9.1638905e-04,  3.3045211e-04],\n",
       "        [ 1.1438753e-03,  2.3777869e-03, -4.9116218e-04, ...,\n",
       "         -1.7472402e-03,  6.2402309e-04,  7.1370759e-04]],\n",
       "\n",
       "       [[-8.3756713e-05, -3.7794863e-04,  5.1459003e-05, ...,\n",
       "         -3.3421817e-05,  1.4434472e-05, -1.3647269e-04],\n",
       "        [ 8.6006570e-05, -6.7612203e-04,  7.2335992e-05, ...,\n",
       "         -5.5030308e-04,  5.2419351e-04,  3.2621669e-04],\n",
       "        [ 8.5771567e-04, -7.4412359e-04,  1.2259764e-04, ...,\n",
       "         -9.3669491e-04,  5.5901293e-04,  2.5770057e-04],\n",
       "        ...,\n",
       "        [ 3.1370230e-03,  1.2575444e-03, -2.0701871e-03, ...,\n",
       "         -1.8143011e-03, -8.6590135e-04,  1.6302145e-03],\n",
       "        [ 3.1699685e-03,  1.8494083e-03, -2.4042164e-03, ...,\n",
       "         -1.5498283e-03, -1.1112520e-03,  1.7513698e-03],\n",
       "        [ 3.1158142e-03,  2.4885575e-03, -2.7454079e-03, ...,\n",
       "         -1.2846007e-03, -1.3247266e-03,  1.7783181e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-8.3756713e-05, -3.7794863e-04,  5.1459003e-05, ...,\n",
       "         -3.3421817e-05,  1.4434472e-05, -1.3647269e-04],\n",
       "        [-1.5283436e-04, -6.1691058e-04,  1.7428400e-04, ...,\n",
       "          1.0708377e-04, -3.2155189e-05, -2.7466693e-04],\n",
       "        [-2.2597730e-04, -5.5498449e-04, -2.4429339e-04, ...,\n",
       "          4.3841945e-05, -4.4219254e-04, -8.1776467e-05],\n",
       "        ...,\n",
       "        [ 2.9208526e-04,  1.9493524e-03, -6.2313018e-04, ...,\n",
       "         -2.2007362e-03, -9.0950978e-04,  8.2681590e-04],\n",
       "        [ 7.5585046e-04,  2.1016726e-03, -4.5721856e-04, ...,\n",
       "         -1.8588903e-03, -1.2324287e-03,  8.4507733e-04],\n",
       "        [ 1.0663624e-03,  2.3591111e-03, -3.5943533e-04, ...,\n",
       "         -1.8893874e-03, -1.4842642e-03,  7.3819887e-04]],\n",
       "\n",
       "       [[-8.3756713e-05, -3.7794863e-04,  5.1459003e-05, ...,\n",
       "         -3.3421817e-05,  1.4434472e-05, -1.3647269e-04],\n",
       "        [-2.3604427e-04, -6.6836656e-04, -2.4658407e-04, ...,\n",
       "          2.5355223e-05, -1.4114050e-04, -9.3367504e-05],\n",
       "        [-5.6534872e-04, -8.2646491e-04, -4.6139304e-04, ...,\n",
       "          1.4608161e-04, -3.3335233e-05, -1.5876928e-04],\n",
       "        ...,\n",
       "        [ 1.5934848e-03,  3.4928750e-03, -2.9435907e-03, ...,\n",
       "         -1.2155686e-03, -7.8347983e-04,  1.7383692e-03],\n",
       "        [ 1.6675369e-03,  4.0831417e-03, -3.3462655e-03, ...,\n",
       "         -9.8588539e-04, -1.0061209e-03,  1.6237807e-03],\n",
       "        [ 1.6710010e-03,  4.6707056e-03, -3.7178183e-03, ...,\n",
       "         -7.6428079e-04, -1.2065881e-03,  1.4660750e-03]],\n",
       "\n",
       "       [[-8.3756713e-05, -3.7794863e-04,  5.1459003e-05, ...,\n",
       "         -3.3421817e-05,  1.4434472e-05, -1.3647269e-04],\n",
       "        [ 1.8105256e-06, -3.8817609e-04, -1.2825758e-04, ...,\n",
       "         -3.2516418e-04,  2.0644061e-04, -8.2827049e-05],\n",
       "        [ 9.2996524e-05, -2.5628236e-04, -6.3223834e-04, ...,\n",
       "         -3.5115681e-04,  9.2013722e-04,  4.3408156e-04],\n",
       "        ...,\n",
       "        [ 2.5689865e-03,  1.2996348e-03, -1.5364824e-03, ...,\n",
       "         -1.8673207e-03,  8.1035891e-04,  2.2894160e-03],\n",
       "        [ 2.7605260e-03,  1.7839897e-03, -1.8707974e-03, ...,\n",
       "         -1.6630326e-03,  4.3184054e-04,  2.2967071e-03],\n",
       "        [ 2.8361196e-03,  2.3224114e-03, -2.2299394e-03, ...,\n",
       "         -1.4342366e-03,  7.6283162e-05,  2.2285446e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 배치1개로 모델 입력해봄\n",
    "enc_train_sample = enc_train[:BATCH_SIZE]\n",
    "lyricist(enc_train_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5b0fa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  15361024  \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  0 (unused)\n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  25174016  \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch multiple                  0 (unused)\n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch multiple                  0 (unused)\n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  30737049  \n",
      "=================================================================\n",
      "Total params: 104,834,713\n",
      "Trainable params: 104,834,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델의 구조를 확인합니다.\n",
    "lyricist.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39a2f17",
   "metadata": {},
   "source": [
    "하지만 model.fit() 함수의 epochs를 아무리 크게 넣는다 해도 val_loss 값은 2.2 아래로 떨어지지 않습니다. 이럴 경우는 batch size를 변경하는 것과 같이 model.fit() 함수에 다양한 인자를 넣어주면 해결될 수도 있습니다. 자세한 내용은 https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit 를 참고하세요!\n",
    "\n",
    "Loss는 아래 제시된 Loss 함수를 그대로 사용하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e904dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1099/1099 [==============================] - 357s 321ms/step - loss: 3.2927 - val_loss: 2.9167\n",
      "Epoch 2/5\n",
      "1099/1099 [==============================] - 342s 311ms/step - loss: 2.6627 - val_loss: 2.6156\n",
      "Epoch 3/5\n",
      "1099/1099 [==============================] - 341s 311ms/step - loss: 2.2123 - val_loss: 2.4361\n",
      "Epoch 4/5\n",
      "1099/1099 [==============================] - 341s 310ms/step - loss: 1.8119 - val_loss: 2.3362\n",
      "Epoch 5/5\n",
      "1099/1099 [==============================] - 354s 322ms/step - loss: 1.4869 - val_loss: 2.2923\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr) #0.01) # 0.001\n",
    "#Loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none') # 클래스 분류 문제에서 softmax 함수를 거치면 from_logits = False(default값),그렇지 않으면 from_logits = True.\n",
    "\n",
    "\n",
    "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
    "lyricist.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
    "history = lyricist.fit(enc_train, dec_train, batch_size=BATCH_SIZE,  validation_data = (enc_val, dec_val), epochs=5) \n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "278a3201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 훈련 과정 시각화 (loss): train, valid\n",
    "plt.plot(history.history['loss'],'blue')\n",
    "plt.plot(history.history['val_loss'],'cyan')\n",
    "plt.title('Model loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Valid'], loc='upper left')\n",
    "plt.show()     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12e0f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#문장생성 함수 정의\n",
    "#모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start> you\", max_len=20): #시작 문자열을 init_sentence 로 받으며 디폴트값은 <start> 를 받는다\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence]) #텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    while True: #루프를 돌면서 init_sentence에 단어를 하나씩 생성성\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4 \n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated #최종적으로 모델이 생성한 문장을 반환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2962603b",
   "metadata": {},
   "source": [
    "데이터가 커서 훈련하는 데 시간이 제법 걸릴 겁니다. 여유를 가지고 작업하시면 좋아요 :)\n",
    "\n",
    "마지막으로 멋진 모델이 생성한 가사 한 줄을 제출하시길 바랍니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b7a493c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you so much <end> '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)\n",
    "# generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2aa46c",
   "metadata": {},
   "source": [
    "### Q4. 모델이 생성한 가사 한 줄을 제출하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37115740",
   "metadata": {},
   "outputs": [],
   "source": [
    "'<start> i love you so much <end> '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d817c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "401b5280",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f8948",
   "metadata": {},
   "source": [
    "본 프로젝트는 Text 데이터를 가지고,tokeninzing시킨후, embedding과정을 거쳐, lstm 모델에 입력하여 학습시켜서, 가사문장을 생성하게하는 프로젝트입니다.\n",
    "\n",
    "##### Step 1~ 2에서, 데이터 다운로드 및 데이터 읽어와서,raw_corpus 리스트에 문장 단위로 저장했읍니다.\n",
    "\n",
    "##### Step 3에서  데이터정제\n",
    "preprocess_sentence() 함수를 활용해 데이터를 정제했는데,소문자로 바꾸고,화자나 공백과 빈도낮은 특수문자들은 제거했고,\n",
    "문장 시작에는 <start>, 끝에는 <end>를 추가했습니다\n",
    "그리고, 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외했습니다.(tf.keras.preprocessing.sequence.pad_sequences()메소드의 maxlen=15 로 입력).\n",
    "    \n",
    "##### Step 4. 평가 데이터셋 분리: 훈련 데이터와 평가 데이터를 분리\n",
    "Tokenizer와 pad_sequences를 사용한 tokenize() 함수에서, 단어장의 크기는 15,000 으로 설정했고,tokenizer.fit_on_texts(corpus)로 문자 데이터를 입력받아 리스트의 형태로 변환, tokenizer.texts_to_sequences(corpus)로 텍스트 안의 단어들을 숫자의 시퀀스 형태로 변환 및 tf.keras.preprocessing.sequence.pad_sequences(tensor,maxlen=15, padding='post')로 데이터를 Tensor로 변환했습니다.\n",
    "그리고, 마지막 문장과 첫문장 <start>를 잘라내어, 소스문장과 타겟문장을 만들었습니다.\n",
    "그런후,  train_test_split() 함수를 사용해 훈련 데이터와 평가 데이터를 8:2로 분리했습니다\n",
    "\n",
    "     \n",
    "##### Step 5. 인공지능모델만들고, 학습하기, \n",
    "하이퍼파람을 여러번에 걸쳐 변경해 보며 얻은 설정은 다음과 같습니다.\n",
    "BATCH_SIZE = 128    # 128,256,512 중 128이 제일 좋았슴\n",
    "embedding_size = 1024 # 256,512,1024 중 1024 제일 좋았슴\n",
    "hidden_size = 2048  #1024,2048중 2048좋았슴\n",
    "lr = 0.001          # 0.01,0.001,0.0001 중 0.001이 제일 좋았슴\n",
    "epoch: 5            # 5,10 중 5가 좋았슴 \n",
    "\n",
    "하이퍼파람 튜닝모델을 for loop로 쓰려다가, 약식으로 하더라도 시간이 많이 걸릴것같아서, 몇개만 1개씩 바꿔가며,\n",
    "시간날때마다 돌려봤습니다.    \n",
    "\n",
    "lyricis 모델은 수업중 배운 모델을 그대로 쓰되,(embedding layer 1개, lstm 2개, Dense layer 1개), \n",
    "BatchNormalization layer를 써 봤는데, 시간만 더 소요되고, 성능향상이 안되어, 빼고 학습시켰는데,아마도,데이터가 \n",
    "embedding layer를 거치며, 어느 정도 정규화가 되어있었던 것 같습니다. \n",
    "옵티마이저는 adam,손실함수는 SparseCategoricalCrossentropy를 그대로 썼는데,회고하면서 드는 생각이 target이 많으니, CategoricalCrossentropy를 써볼걸 하는 생각이 들었습니다.    \n",
    "    \n",
    "학습결과는 loss: 1.4869,  val_loss: 2.2923 이었습니다.\n",
    "    \n",
    "history를 통해 loss, valid loss를 시각화시켰습니다.\n",
    "    \n",
    "그리고, loss측면에서 부족한 모델일테지만, 완성된 lyricis 모델로  generate_text()함수를 통해 문장을 생성시켜 봤는데,\n",
    "맘에드는 문장을 생성했습니다.    \n",
    "    \n",
    "'<start> i love you so much <end> '   \n",
    "    \n",
    "    \n",
    "##### 결론적으로, 모델구성dl lstm 2개로 shallow 하고, 하이퍼파라메터도 몇개 않돌려보고, val loss도 2.2923으로 낮지않은데도, 좋은 문장을 생성하는데, transformer는 또 어떨까하는 궁금증, 그리고 자연어처리에서의 딥러닝의 역할이 많이 기대됩니다.자연어뿐 아니라,다른 시계열 데이터에서도 유용한 성능을 보일것을 기대하게 됩니다.  좋은 강의안 감사합니다.    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad25a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0971ef17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
