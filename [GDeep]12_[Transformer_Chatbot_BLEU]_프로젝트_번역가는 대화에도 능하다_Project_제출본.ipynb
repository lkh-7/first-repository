{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "695e26e1",
   "metadata": {},
   "source": [
    "## 12-7. Project: 멋진 챗봇 만들기\n",
    "#### 라이브러리 버전을 확인해 봅니다\n",
    "사용할 라이브러리 버전을 둘러봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6adb0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade gensim==3.8.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31651760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.21.4\n",
      "1.3.3\n",
      "2.6.0\n",
      "3.6.5\n",
      "3.8.3\n"
     ]
    }
   ],
   "source": [
    "import numpy \n",
    "import pandas \n",
    "import tensorflow \n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "print(numpy.__version__)\n",
    "print(pandas.__version__)\n",
    "print(tensorflow.__version__)\n",
    "print(nltk.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d52c713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "import re\n",
    "import os,copy,time\n",
    "import random\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1907554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sed 고정\n",
    "seed = 119\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04176b5",
   "metadata": {},
   "source": [
    "지난 노드에서 **챗봇과 번역기는 같은 집안**이라고 했던 말을 기억하시나요?\n",
    "앞서 배운 Seq2seq번역기와 Transfomer번역기에 적용할 수도 있겠지만, 이번 노드에서 배운 번역기 성능 측정법을 챗봇에도 적용해 봅시다. 배운 지식을 다양하게 활용할 수 있는 것도 중요한 능력이겠죠. 이번 프로젝트를 통해서 챗봇과 번역기가 같은 집안인지 확인해 보세요!\n",
    "\n",
    "#### Step 1. 데이터 다운로드\n",
    "준비하기 단계에서 심볼릭 링크를 생성했다면 아래 파일이 ChatbotData .csv라는 이름으로 저장되어 있을거예요. csv 파일을 읽는 데에는 pandas 라이브러리가 적합합니다. 읽어 온 데이터의 질문과 답변을 각각 questions, answers 변수에 나눠서 저장하세요!\n",
    "\n",
    "* [songys/Chatbot_data](https://github.com/songys/Chatbot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5992b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11823, 3)               Q            A  label\n",
      "0        12시 땡!   하루가 또 가네요.      0\n",
      "1   1지망 학교 떨어졌어    위로해 드립니다.      0\n",
      "2  3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0                              Q                         A  label\n",
      "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
      "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
      "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2 Index(['Q', 'A', 'label'], dtype='object')\n",
      "data.isnull().sum() Q        0\n",
      "A        0\n",
      "label    0\n",
      "dtype: int64\n",
      "convers_pair_series (11823,) 0              12시 땡!    하루가 또 가네요.\n",
      "1          1지망 학교 떨어졌어    위로해 드립니다.\n",
      "2       3박4일 놀러가고 싶다    여행은 언제나 좋죠.\n",
      "3    3박4일 정도 놀러가고 싶다    여행은 언제나 좋죠.\n",
      "4             PPL 심하네    눈살이 찌푸려지죠.\n",
      "dtype: object\n",
      "결측치여부체크: 0\n",
      "questions 11823 ['12시 땡!', '1지망 학교 떨어졌어', '3박4일 놀러가고 싶다', '3박4일 정도 놀러가고 싶다', 'PPL 심하네']\n",
      "answers 11823 ['하루가 또 가네요.', '위로해 드립니다.', '여행은 언제나 좋죠.', '여행은 언제나 좋죠.', '눈살이 찌푸려지죠.']\n",
      "convers_pair_series (11823,) 0              12시 땡!    하루가 또 가네요.\n",
      "1          1지망 학교 떨어졌어    위로해 드립니다.\n",
      "2       3박4일 놀러가고 싶다    여행은 언제나 좋죠.\n",
      "3    3박4일 정도 놀러가고 싶다    여행은 언제나 좋죠.\n",
      "4             PPL 심하네    눈살이 찌푸려지죠.\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path_to_dataset = '/aiffel/aiffel/transformer_chatbot/data/ChatbotData.csv'\n",
    "#!ls '/aiffel/aiffel/transformer_chatbot/data'\n",
    "data = pd.read_csv(path_to_dataset)\n",
    "print(data.shape, data.head(3), data.tail(3), data.columns)\n",
    "\n",
    "# 데이터 Nan 여부체크: Nan 없슴\n",
    "print(\"data.isnull().sum()\", data.isnull().sum())\n",
    "\n",
    "# questions, answers, label 로 분리\n",
    "questions = data['Q'].values.tolist()\n",
    "answers = data['A'].values.tolist()\n",
    "\n",
    "# questions, answers 쌍(pair)만 별도 df\n",
    "convers_pair_series = data['Q'] + '    ' + data['A']\n",
    "print(\"convers_pair_series\", convers_pair_series.shape, convers_pair_series.head())\n",
    "print(\"결측치여부체크:\", convers_pair_series.isnull().sum())\n",
    "\n",
    "print(\"questions\",len(questions), questions[:5])\n",
    "print(\"answers\",len(answers), answers[:5])\n",
    "print(\"convers_pair_series\",convers_pair_series.shape, convers_pair_series.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcc3236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9babf221",
   "metadata": {},
   "source": [
    "#### Step 2. 데이터 정제\n",
    "아래 조건을 만족하는 preprocess_sentence() 함수를 구현하세요.\n",
    "\n",
    "영문자의 경우, **모두 소문자로 변환**합니다.    \n",
    "영문자와 한글, 숫자, 그리고 주요 특수문자를 제외하곤 **정규식을 활용하여 모두 제거**합니다.    \n",
    "문장부호 양옆에 공백을 추가하는 등 이전과 다르게 생략된 기능들은 우리가 사용할 토크나이저가 지원하기 때문에 굳이 구현하지 않아도 괜찮습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "865b816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence): \n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = sentence.replace(\"\\.{2,30}\",\" \") \n",
    "    sentence = sentence.replace(\"[^ㄱ-힣a-zA-Z0-9!?,.^\\s]\",\"\")  \n",
    "    sentence = sentence.lower().strip()             \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac44763b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5da3305",
   "metadata": {},
   "source": [
    "#### Step 3. 데이터 토큰화\n",
    "토큰화에는 KoNLPy의 mecab 클래스를 사용합니다.\n",
    "\n",
    "아래 조건을 만족하는 build_corpus() 함수를 구현하세요!\n",
    "\n",
    "1. **소스 문장 데이터와 타겟 문장 데이터**를 입력으로 받습니다.    \n",
    "2. 데이터를 앞서 정의한 preprocess_sentence() 함수로 **정제하고, 토큰화**합니다.      \n",
    "3. 토큰화는 **전달받은 토크나이즈 함수**를 사용합니다. 이번엔 mecab.morphs 함수를 전달하시면 됩니다.        \n",
    "4. 토큰의 개수가 일정 길이 이상인 문장은 **데이터에서 제외**합니다.    \n",
    "8. **중복되는 문장은 데이터에서 제외**합니다. 소스 : 타겟 쌍을 비교하지 않고 소스는 소스대로 타겟은 타겟대로 검사합니다. 중복 쌍이 흐트러지지 않도록 유의하세요!   \n",
    "구현한 함수를 활용하여 questions 와 answers 를 각각 que_corpus , ans_corpus 에 토큰화하여 저장합니다.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe04d66",
   "metadata": {},
   "source": [
    "**build_corpus() 함수를 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2ea9e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_corpus ['내일 기대하게 되네    좋은 일이 생길 거예요.\\n', '고시원에서 나가고 싶어    더 좋은 곳에서 살 수 있을 거예요.\\n'] 11750\n",
      "que_corpus_noMax [['내일', '기대', '하', '게', '되', '네'], ['고시원', '에서', '나가', '고', '싶', '어'], ['무서운', '주말'], ['반', '배정', '부터', '올해', '끝', '났', '다', '.'], ['자꾸', '지각', '하', '네']] 11750\n",
      "ans_corpus_noMax [['좋', '은', '일', '이', '생길', '거', '예요', '.'], ['더', '좋', '은', '곳', '에서', '살', '수', '있', '을', '거', '예요', '.'], ['즐거운', '주말', '이', '되', '시', '길', '바랄게요', '.'], ['1', '년', '힘내', '요', '.'], ['더', '일찍', '일어나', '세요', '.']] 11750\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab \n",
    "\n",
    "tokenizer = Mecab()\n",
    "\n",
    "def build_corpus(src, tgt, tokenizer, maxlen= 100):\n",
    "    \n",
    "    que_corpus = []\n",
    "    ans_corpus = []\n",
    "    \n",
    "    # 중복문장제거: 튜플을 str로 전환,한개 문장내 src vs tgt는 공백4칸으로 구분, 문장별 구분은 '\\n'으로 구분\n",
    "    cleaned_corpus = [line[0] + ' '*4 + line[1] +'\\n' for line in list(set(zip(src,tgt)))]\n",
    "    print(\"cleaned_corpus\",cleaned_corpus[:2], len(cleaned_corpus))     \n",
    "    \n",
    "    for i, pair in enumerate(cleaned_corpus):\n",
    "        \n",
    "        # pair 분리\n",
    "        src_sentence = pair.split(' '*4)[0]\n",
    "        tgt_sentence = pair.split(' '*4)[1]\n",
    "        \n",
    "        # 전처리\n",
    "        src_sentence = preprocess_sentence(src_sentence)\n",
    "        tgt_sentence = preprocess_sentence(tgt_sentence)\n",
    "\n",
    "        # 형태소분석기로 단어 토큰화\n",
    "        src_token = tokenizer.morphs(src_sentence) \n",
    "        tgt_token = tokenizer.morphs(tgt_sentence) \n",
    "        \n",
    "        # maxlen 이하 단어갖은 문장만 append\n",
    "        if len(src_token) <= maxlen and len(tgt_token) <= maxlen:\n",
    "            que_corpus.append(src_token)\n",
    "            ans_corpus.append(tgt_token)\n",
    "        \"\"\"\n",
    "        if maxlen !=None and len(src_token) <= maxlen and len(tgt_token) <= maxlen:\n",
    "            que_corpus.append(src_token)\n",
    "            ans_corpus.append(tgt_token)\n",
    "        else:\n",
    "            que_corpus.append(src_token)\n",
    "            ans_corpus.append(tgt_token)\n",
    "        \"\"\"    \n",
    "    return que_corpus , ans_corpus\n",
    "\n",
    "## 임의의 maxlen 으로 1차 토큰화진행 \n",
    "que_corpus_noMax , ans_corpus_noMax = build_corpus(questions, answers, tokenizer, maxlen=100)        \n",
    "        \n",
    "print(\"que_corpus_noMax\",que_corpus_noMax[:5], len(que_corpus_noMax))  \n",
    "print(\"ans_corpus_noMax\",ans_corpus_noMax[:5], len(ans_corpus_noMax))  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55c52d",
   "metadata": {},
   "source": [
    "**max_length 설정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "318d0370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "questions 길이 평균, 표준편차, 최대,최소:  7.037276595744681 3.5226159627991147 32 1\n",
      "answers 길이 평균, 표준편차, 최대,최소:  8.377191489361703 3.574356508896885 40 1\n",
      "maxlen 14.804206514249191\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# length list\n",
    "lenq = [len(x) for x in que_corpus_noMax]\n",
    "lena = [len(x) for x in ans_corpus_noMax]\n",
    "\n",
    "# 데이터 길이 분포 파악\n",
    "max_length_q = np.max(lenq)\n",
    "min_length_q = np.min(lenq)\n",
    "mean_length_q = np.mean(lenq)\n",
    "std_length_q = np.std(lenq)\n",
    "print(\"questions 길이 평균, 표준편차, 최대,최소: \", mean_length_q, std_length_q, max_length_q, min_length_q)\n",
    "\n",
    "max_length_a = np.max(lena)\n",
    "min_length_a = np.min(lena)\n",
    "mean_length_a = np.mean(lena)\n",
    "std_length_a = np.std(lena)\n",
    "print(\"answers 길이 평균, 표준편차, 최대,최소: \", mean_length_a, std_length_a, max_length_a, min_length_a)\n",
    "\n",
    "# maxlen 계산 공식: mean + 2*std 기준으로, 분포도를 보고서, 재량껏 조정\n",
    "maxlen = (mean_length_q + mean_length_a)/2 + 2*((std_length_q + std_length_a)/2)\n",
    "print(\"maxlen\", maxlen)\n",
    "\n",
    "# 분포를 히스토그램으로 보기 plot\n",
    "plt.hist(lenq)\n",
    "plt.title(\"que_corpus_noMax_length\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(lena)\n",
    "plt.title(\"ans_corpus_noMaxwers_length\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afff0572",
   "metadata": {},
   "source": [
    "**max_length 설정: 15개**   \n",
    "question, answer 공히 평균 7.5 내외, 표준편차 3.5내외, 최대길이는 각 32개, 40개인데,\n",
    "max 산정에는 공식에의한 14.8 및 분포도형태상 15개이면 충분할 것으로 판단됨\n",
    "\n",
    "**maxlen == 15 로 2차 토큰화진행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "244c60f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_corpus ['내일 기대하게 되네    좋은 일이 생길 거예요.\\n', '고시원에서 나가고 싶어    더 좋은 곳에서 살 수 있을 거예요.\\n'] 11750\n",
      "que_corpus [['내일', '기대', '하', '게', '되', '네'], ['고시원', '에서', '나가', '고', '싶', '어'], ['무서운', '주말'], ['반', '배정', '부터', '올해', '끝', '났', '다', '.'], ['자꾸', '지각', '하', '네']] 10960\n",
      "ans_corpus [['좋', '은', '일', '이', '생길', '거', '예요', '.'], ['더', '좋', '은', '곳', '에서', '살', '수', '있', '을', '거', '예요', '.'], ['즐거운', '주말', '이', '되', '시', '길', '바랄게요', '.'], ['1', '년', '힘내', '요', '.'], ['더', '일찍', '일어나', '세요', '.']] 10960\n"
     ]
    }
   ],
   "source": [
    "## maxlen==15,  2차 토큰화진행 \n",
    "que_corpus , ans_corpus = build_corpus(questions, answers, tokenizer, maxlen=15)        \n",
    "        \n",
    "print(\"que_corpus\",que_corpus[:5], len(que_corpus))  \n",
    "print(\"ans_corpus\",ans_corpus[:5], len(ans_corpus))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef07d4e",
   "metadata": {},
   "source": [
    "#### Step 4. Augmentation\n",
    "우리에게 주어진 데이터는 **1만 개가량으로 적은 편**에 속합니다. 이럴 때에 사용할 수 있는 테크닉을 배웠으니 활용해 봐야겠죠? **Lexical Substitution을 실제로 적용**해 보도록 하겠습니다.\n",
    "\n",
    "아래 링크를 참고하여 **한국어로 사전 훈련된 Embedding 모델을 다운로드**합니다. Korean (w) 가 Word2Vec으로 학습한 모델이며 용량도 적당하므로 사이트에서 Korean (w)를 찾아 다운로드하고, ko.bin 파일을 얻으세요!\n",
    "\n",
    "* [Kyubyong/wordvectors](https://github.com/Kyubyong/wordvectors)\n",
    "\n",
    "다운로드한 모델을 활용해 데이터를 **Augmentation** 하세요! 앞서 정의한 lexical_sub() 함수를 참고하면 도움이 많이 될 겁니다.\n",
    "\n",
    "Augmentation된 que_corpus 와 원본 ans_corpus 가 병렬을 이루도록, 이후엔 반대로 원본 que_corpus 와 Augmentation된 ans_corpus 가 병렬을 이루도록 하여 **전체 데이터가 원래의 3배가량**으로 늘어나도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938ed034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "983666df",
   "metadata": {},
   "source": [
    "**pre_trained word2vec 다운로드후 모델 load:** gensim 3.8.x에서만 가능하여, 원래의 4.1.2에서 3.8.3으로 down grade했슴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4618d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('고양이', 0.7290452718734741), ('거위', 0.7185635566711426), ('토끼', 0.7056223154067993), ('멧돼지', 0.6950401067733765), ('엄마', 0.6934334635734558), ('난쟁이', 0.6806551218032837), ('한마리', 0.6770296096801758), ('아가씨', 0.6750352382659912), ('아빠', 0.6729634404182434), ('목걸이', 0.6512460708618164)]\n"
     ]
    }
   ],
   "source": [
    "wv_kor = gensim.models.Word2Vec.load('/aiffel/aiffel/transformer_chatbot/model/ko.bin') #'./model/ko.bin')\n",
    "a = wv_kor.wv.most_similar(\"강아지\")\n",
    "print(a)\n",
    "# import gensim.downloader as api: wv = api.load('~/model/ko.bin') ==> 모델 로드 않됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a90b0c7",
   "metadata": {},
   "source": [
    "**데이터 Augmentation: lexical_sub() 함수 및 data_augmentation 및  Make_CleanAugmenetDataSet_and_Remove_Nan함수 구현 및 사용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b36f5df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lexical Substitution 구현하기\n",
    "def lexical_sub(token_sentence, word2vec):\n",
    "    #res = \"\"\n",
    "    #toks = token_sentence\n",
    "    res = []\n",
    "    \n",
    "    try:  \n",
    "        _from = random.choice(token_sentence)\n",
    "        _to = word2vec.most_similar(_from)[0][0]   # 유사도점수순으로 (단어,유사도점수) 튜플중 제일 높은 점수쌍중 단어만 고름 \n",
    "               \n",
    "    except:   # 단어장에 없는 단어\n",
    "        return None\n",
    "\n",
    "    for tok in token_sentence:\n",
    "        #if tok is _from: res += _to + \" \"  #원래코드\n",
    "        #else: res += tok + \" \"             #원래코드\n",
    "        if tok is _from: res.append(_to)\n",
    "        else: res.append(tok)\n",
    "    #print(\"res\",res)        \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3c00b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1150c8fff8d04a7ca491f70d5617567f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_531/1941403359.py:9: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  _to = word2vec.most_similar(_from)[0][0]   # 유사도점수순으로 (단어,유사도점수) 튜플중 제일 높은 점수쌍중 단어만 고름\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_src ['내일', '기대', '하', '게', '되', '네'] new_src ['내일', '기대', '시키', '게', '되', '네']\n",
      "old_src ['고시원', '에서', '나가', '고', '싶', '어'] new_src ['고시원', '오세아니아', '나가', '고', '싶', '어']\n",
      "old_src ['무서운', '주말'] new_src ['무서운', '토요일']\n",
      "old_src ['반', '배정', '부터', '올해', '끝', '났', '다', '.'] new_src ['반', '할당', '부터', '올해', '끝', '났', '다', '.']\n",
      "[['내일', '기대', '시키', '게', '되', '네'], ['내일', '기대', '하', '게', '되', '네'], ['고시원', '오세아니아', '나가', '고', '싶', '어'], ['고시원', '에서', '나가', '고', '싶', '어'], ['무서운', '토요일'], ['무서운', '주말'], ['반', '할당', '부터', '올해', '끝', '났', '다', '.'], ['반', '배정', '부터', '올해', '끝', '났', '다', '.'], ['그럼', '지각', '하', '네'], ['자꾸', '지각', '하', '네']]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "935e8ef9af8142dd85bcf29445a254f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10960 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_src ['좋', '은', '일', '이', '생길', '거', '예요', '.'] new_src ['좋', '은', '일', '이', '생길', '것', '예요', '.']\n",
      "old_src ['더', '좋', '은', '곳', '에서', '살', '수', '있', '을', '거', '예요', '.'] new_src ['더', '좋', '은', '곳', '에서', '살', '수', '있', '을', '것', '예요', '.']\n",
      "old_src ['즐거운', '주말', '이', '되', '시', '길', '바랄게요', '.'] new_src ['즐거운', '주말', '그러', '되', '시', '길', '바랄게요', '.']\n",
      "old_src ['1', '년', '힘내', '요', '.'] new_src ['1', '년', '힘내', '요', '는데']\n",
      "[['좋', '은', '일', '이', '생길', '것', '예요', '.'], ['좋', '은', '일', '이', '생길', '거', '예요', '.'], ['더', '좋', '은', '곳', '에서', '살', '수', '있', '을', '것', '예요', '.'], ['더', '좋', '은', '곳', '에서', '살', '수', '있', '을', '거', '예요', '.'], ['즐거운', '주말', '그러', '되', '시', '길', '바랄게요', '.'], ['즐거운', '주말', '이', '되', '시', '길', '바랄게요', '.'], ['1', '년', '힘내', '요', '는데'], ['1', '년', '힘내', '요', '.'], ['더', '빨리', '일어나', '세요', '.'], ['더', '일찍', '일어나', '세요', '.']]\n",
      "new_que_corpus[:10] 10960 [[['내일', '기대', '시키', '게', '되', '네'], ['내일', '기대', '하', '게', '되', '네']], [['고시원', '오세아니아', '나가', '고', '싶', '어'], ['고시원', '에서', '나가', '고', '싶', '어']], [['무서운', '토요일'], ['무서운', '주말']], [['반', '할당', '부터', '올해', '끝', '났', '다', '.'], ['반', '배정', '부터', '올해', '끝', '났', '다', '.']], [['그럼', '지각', '하', '네'], ['자꾸', '지각', '하', '네']], [['항상', '같', '애'], ['항상', '똑같', '애']], [['지루', '해서'], ['답답', '해서']], [nan, ['3', '박', '4', '일', '놀', '러', '가', '고', '싶', '다']], [['그만', '살', '기에', '싶', '어'], ['그만', '살', '고', '싶', '어']], [['나이', '들', '면서', '눈물', '그러', '많', '아', '졌', '어'], ['나이', '들', '면서', '눈물', '이', '많', '아', '졌', '어']]]\n",
      "new_ans_corpus[:10] 10960 [[['좋', '은', '일', '이', '생길', '것', '예요', '.'], ['좋', '은', '일', '이', '생길', '거', '예요', '.']], [['더', '좋', '은', '곳', '에서', '살', '수', '있', '을', '것', '예요', '.'], ['더', '좋', '은', '곳', '에서', '살', '수', '있', '을', '거', '예요', '.']], [['즐거운', '주말', '그러', '되', '시', '길', '바랄게요', '.'], ['즐거운', '주말', '이', '되', '시', '길', '바랄게요', '.']], [['1', '년', '힘내', '요', '는데'], ['1', '년', '힘내', '요', '.']], [['더', '빨리', '일어나', '세요', '.'], ['더', '일찍', '일어나', '세요', '.']], [['똑같', '은', '건', '없', '는데요', '.'], ['똑같', '은', '건', '없', '어요', '.']], [['좋', '은데', '생각', '만', '하', '세요', '.'], ['좋', '은', '생각', '만', '하', '세요', '.']], [['여행', '은데', '언제나', '좋', '죠', '.'], ['여행', '은', '언제나', '좋', '죠', '.']], [['당신', '을', '소중', '하', '게', '판단', '하', '세요', '.'], ['당신', '을', '소중', '하', '게', '생각', '하', '세요', '.']], [nan, ['세상', '걱정', '혼자', '다', '해서', '그래요', '.']]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 데이터 augmentation 함수 구현\n",
    "def data_augmentation(corpus, wv):\n",
    "    new_corpus = []\n",
    "    count = 0\n",
    "    for old_src in tqdm(corpus):\n",
    "        new_src = lexical_sub(old_src, wv_kor)\n",
    "\n",
    "        count += 1\n",
    "        if count < 5:\n",
    "            print(\"old_src\", old_src, \"new_src\", new_src)\n",
    "        \n",
    "        # None있는 곳에 np.nan 대체입력: pd.isna()로 쉽게 제거가능\n",
    "        if new_src is None:\n",
    "            new_corpus.append(np.nan)    \n",
    "        else:\n",
    "            new_corpus.append(new_src)  \n",
    "        # Augmentation이 없더라도 원본 문장을 포함시킵니다\n",
    "        new_corpus.append(old_src)\n",
    "    print(new_corpus[:10])\n",
    "    return new_corpus\n",
    "   \n",
    "new_que_corpus = data_augmentation(que_corpus, wv_kor)\n",
    "new_ans_corpus = data_augmentation(ans_corpus, wv_kor)\n",
    "\n",
    "# new_que_corpus,new_ans_corpus 데이터를  각각 new_corpus, old_corpus 병렬쌍으로 전환\n",
    "new_que_corpus = np.array(new_que_corpus,dtype=object).reshape(-1,2).tolist()\n",
    "new_ans_corpus = np.array(new_ans_corpus,dtype=object).reshape(-1,2).tolist()\n",
    "\n",
    "# 병렬쌍 여부 체크: OK\n",
    "print(\"new_que_corpus[:10]\",len(new_que_corpus),new_que_corpus[:10])\n",
    "print(\"new_ans_corpus[:10]\",len(new_ans_corpus),new_ans_corpus[:10])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0848d5f2",
   "metadata": {},
   "source": [
    "**augmentation data pair(쌍)정렬및 통합데이터완성: 원본데이터pair + que원본및ans증강 +  que증강및ans원본 + que증강및ans증강**    \n",
    "원본 questions, answers 각각 11750개 문장 ===> 중복제거,15단어이상제거등으로 10960개==>  증강 완성 questions, answers 각각 35347개 문장을 만들어서 약 3.4배정도의 데이터를 생성."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c4f8176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape (10960, 4)\n",
      "Nan있는 문장개수 nan_chk1    1715\n",
      "nan_chk2    1312\n",
      "augment1       0\n",
      "augment2       0\n",
      "dtype: int64\n",
      "Nan 제거후 문장개수 nan_chk1    0\n",
      "nan_chk2    0\n",
      "augment1    0\n",
      "augment2    0\n",
      "dtype: int64\n",
      "shape (8129, 4)\n",
      "통합된 clean Augment data 최종 문장개수 total_augment1_clean 35347 total_augment2_clean 35347\n",
      "new_que_corpus_cleaned 35347 [['내일', '기대', '하', '게', '되', '네'], ['고시원', '에서', '나가', '고', '싶', '어'], ['무서운', '주말'], ['반', '배정', '부터', '올해', '끝', '났', '다', '.'], ['자꾸', '지각', '하', '네']]\n",
      "new_ans_corpus_cleaned 35347 [['좋', '은', '일', '이', '생길', '거', '예요', '.'], ['더', '좋', '은', '곳', '에서', '살', '수', '있', '을', '거', '예요', '.'], ['즐거운', '주말', '이', '되', '시', '길', '바랄게요', '.'], ['1', '년', '힘내', '요', '.'], ['더', '일찍', '일어나', '세요', '.']]\n",
      "shape (35347, 2)\n",
      "Nan있는 문장개수 augment1    0\n",
      "augment2    0\n",
      "dtype: int64\n",
      "Nan 제거후 Nan 잔존 여부 augment1    0\n",
      "augment2    0\n",
      "dtype: int64\n",
      "shape (35347, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_531/2083757178.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  df = pd.DataFrame({'nan_chk1':np.array(augment1)[:,0],'nan_chk2':np.array(augment2)[:,0],\"augment1\":augment1,\n",
      "/tmp/ipykernel_531/2083757178.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  augment1_without_nan= np.array(df['augment1'].values.tolist())\n",
      "/tmp/ipykernel_531/2083757178.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  augment2_without_nan= np.array(df['augment2'].values.tolist())\n"
     ]
    }
   ],
   "source": [
    "# Augmentation data pair(쌍)정렬및 통합데이터 완성함수 구현: 문장내의 np.nan 제거 코드 포함 OK\n",
    "def Make_CleanAugmenetDataSet_and_Remove_Nan(augment1, augment2):\n",
    "    \n",
    "    df = pd.DataFrame({'nan_chk1':np.array(augment1)[:,0],'nan_chk2':np.array(augment2)[:,0],\"augment1\":augment1,\n",
    "                 \"augment2\":augment2})\n",
    "    print(\"shape\",df.shape)   \n",
    "    print(\"Nan있는 문장개수\", df.isnull().sum())\n",
    "    # nan있는 문장 통합제거: \n",
    "    df.dropna(axis=0, inplace=True)\n",
    "    print(\"Nan 제거후 문장개수\", df.isnull().sum())\n",
    "    print(\"shape\",df.shape)\n",
    "    \n",
    "    # np.array 전환\n",
    "    augment1_np= np.array(augment1, dtype=object)\n",
    "    augment2_np= np.array(augment2, dtype=object)\n",
    "    augment1_without_nan= np.array(df['augment1'].values.tolist())\n",
    "    augment2_without_nan= np.array(df['augment2'].values.tolist())\n",
    "    # data별 pair 순서대로 문장통합 및 완성: 원본데이터pair + que원본및ans증강 +  que증강및ans원본 + que증강및ans증강\n",
    "    total_augment1_clean = np.concatenate(\n",
    "        [augment1_np[:,1],augment1_without_nan[:,0],augment1_without_nan[:,1],augment1_without_nan[:,0]], axis=0)    \n",
    "    total_augment2_clean = np.concatenate(\n",
    "        [augment2_np[:,1],augment2_without_nan[:,1],augment2_without_nan[:,0],augment2_without_nan[:,0]], axis=0)    \n",
    "           \n",
    "    # numpy.array ==> list 재전환\n",
    "    total_augment1_clean = total_augment1_clean.tolist()\n",
    "    total_augment2_clean = total_augment2_clean.tolist()\n",
    "    print(\"통합된 clean Augment data 최종 문장개수\",\"total_augment1_clean\", len(total_augment1_clean),\n",
    "          \"total_augment2_clean\", len(total_augment1_clean))\n",
    "    return  total_augment1_clean,total_augment2_clean\n",
    "       \n",
    "# 완성된 Augment Data Set\n",
    "new_que_corpus_cleaned,new_ans_corpus_cleaned = Make_CleanAugmenetDataSet_and_Remove_Nan(new_que_corpus,new_ans_corpus)\n",
    "print(\"new_que_corpus_cleaned\",len(new_que_corpus_cleaned),new_que_corpus_cleaned[:5])\n",
    "print(\"new_ans_corpus_cleaned\",len(new_ans_corpus_cleaned),new_ans_corpus_cleaned[:5])\n",
    "\n",
    "## nan 존재여부 재확인: 없슴 \n",
    "df = pd.DataFrame({\"augment1\":new_que_corpus_cleaned,\n",
    "                 \"augment2\":new_ans_corpus_cleaned})\n",
    "print(\"shape\",df.shape)   \n",
    "print(\"Nan있는 문장개수\", df.isnull().sum())\n",
    "# nan있는 문장 통합제거: np.where(pd.isna())\n",
    "df.dropna(axis=0, inplace=True)\n",
    "print(\"Nan 제거후 Nan 잔존 여부\", df.isnull().sum())\n",
    "print(\"shape\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21696b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ni = 8177\\nidx= i  #10960#8193\\nprint(new_que_corpus_cleaned[idx],new_ans_corpus_cleaned[idx])\\nidx= 10960 + i\\nprint(new_que_corpus_cleaned[idx],new_ans_corpus_cleaned[idx])\\nidx= 10960 + 8178+ i\\nprint(new_que_corpus_cleaned[idx],new_ans_corpus_cleaned[idx])\\nidx= 10961 + 8178*2 + i-1\\nprint(new_que_corpus_cleaned[idx],new_ans_corpus_cleaned[idx])\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "i = 8177\n",
    "idx= i  #10960#8193\n",
    "print(new_que_corpus_cleaned[idx],new_ans_corpus_cleaned[idx])\n",
    "idx= 10960 + i\n",
    "print(new_que_corpus_cleaned[idx],new_ans_corpus_cleaned[idx])\n",
    "idx= 10960 + 8178+ i\n",
    "print(new_que_corpus_cleaned[idx],new_ans_corpus_cleaned[idx])\n",
    "idx= 10961 + 8178*2 + i-1\n",
    "print(new_que_corpus_cleaned[idx],new_ans_corpus_cleaned[idx])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc48b87b",
   "metadata": {},
   "source": [
    "#### Step 5. 데이터 벡터화\n",
    "타겟 데이터인 ans_corpus 에 <start> 토큰과 <end> 토큰이 추가되지 않은 상태이니 이를 먼저 해결한 후 벡터화를 진행합니다. 우리가 구축한 ans_corpus 는 list 형태이기 때문에 아주 쉽게 이를 해결할 수 있답니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33dea8b",
   "metadata": {},
   "source": [
    "1. 위 소스를 참고하여 타겟 데이터 전체에 <start> 토큰과 <end> 토큰을 추가해 주세요!    \n",
    "    \n",
    "챗봇 훈련 데이터의 가장 큰 특징 중 하나라고 하자면 바로 **소스 데이터와 타겟 데이터가 같은 언어를 사용한다는 것** 이겠죠. 앞서 배운 것처럼 이는 Embedding 층을 공유했을 때 많은 이점을 얻을 수 있습니다.\n",
    "\n",
    "2. 특수 토큰을 더함으로써 ans_corpus 또한 완성이 되었으니, que_corpus 와 결합하여 **전체 데이터에 대한 단어 사전을 구축하고 벡터화**하여 enc_train 과 dec_train 을 얻으세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b045c0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_ans_corpus_cleaned_add 35347 [['<start>', '좋', '은', '일', '이', '생길', '거', '예요', '.', '<end>'], ['<start>', '더', '좋', '은', '곳', '에서', '살', '수', '있', '을', '거', '예요', '.', '<end>'], ['<start>', '즐거운', '주말', '이', '되', '시', '길', '바랄게요', '.', '<end>']]\n"
     ]
    }
   ],
   "source": [
    "# ansers 데이터에 \"<start>\",\"<end>\" 추가\n",
    "new_ans_corpus_cleaned_add=[]\n",
    "for tok_sen in new_ans_corpus_cleaned:\n",
    "    #print(tok_sen)\n",
    "    tok_sen1= [\"<start>\"] + tok_sen + [\"<end>\"]\n",
    "    #print(tok_sen1)\n",
    "    new_ans_corpus_cleaned_add.append(tok_sen1)\n",
    "    \n",
    "print(\"new_ans_corpus_cleaned_add\", len(new_ans_corpus_cleaned_add), new_ans_corpus_cleaned_add[:3])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c16902f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보정전 단어사전 길이: 5969 5969\n",
      "보정전 tokenizer.index_word[0~10] [(1, '<unk>'), (2, '는'), (3, '이'), (4, '.'), (5, '하'), (6, '어'), (7, '가'), (8, '?'), (9, '고'), (10, '아')]\n",
      "tokenizer.index_word <pad> <unk> 는\n",
      "tokenizer.word_index 0 3\n",
      "보정후 단어사전 길이: 5970 5970\n",
      "보정전 단어사전 길이: 4306 4306\n",
      "보정전 tokenizer.index_word[0~10] [(1, '<unk>'), (2, '<start>'), (3, '<end>'), (4, '.'), (5, '세요'), (6, '이'), (7, '하'), (8, '을'), (9, '는'), (10, '보'), (11, '거'), (12, '은'), (13, '있'), (14, '해'), (15, '예요'), (16, '좋'), (17, '가'), (18, '도'), (19, '지'), (20, '어요'), (21, '죠')]\n",
      "tokenizer.index_word <pad> <start> <end> <unk>\n",
      "tokenizer.word_index 0 1 2 3\n",
      "보정후 tokenizer.index_word[0~10] [(7, '.'), (8, '세요'), (9, '이'), (10, '하'), (11, '을'), (12, '는'), (13, '보'), (14, '거'), (15, '은'), (16, '있'), (17, '해'), (18, '예요'), (19, '좋'), (20, '가'), (0, '<pad>'), (1, '<start>'), (2, '<end>'), (3, '<unk>')]\n",
      "보정후 단어사전 길이: 4307 4307\n",
      "enc_tensor 35347 [[ 231  538    8   28   48   19    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [1531   66  286   12   18    9    0    0    0    0    0    0    0    0\n",
      "     0]] [[4473   46   12   32   16    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 290   78  164  191    5   78  176   11    0    0    0    0    0    0\n",
      "     0]]\n",
      "dec_tensor 35347 [[  1  19  15  55   9 508  14  18   7   2   0   0   0   0   0   0   0]\n",
      " [  1  47  19  15 143 109 134  34  16  11  14  18   7   2   0   0   0]] [[   1   95   21   13   27   74   23    7    2    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   1 1237  378   15   41   23    7    2    0    0    0    0    0    0\n",
      "     0    0    0]]\n",
      "enc_tensor 35347 [[1931  380   66   80   26 4333   81    5  150    0    0    0    0    0\n",
      "     0]\n",
      " [1186  679   26 1051   17    0    0    0    0    0    0    0    0    0\n",
      "     0]] [[1569  164 2672  176  113    0    0    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [ 160  342  132   23   19    0    0    0    0    0    0    0    0    0\n",
      "     0]]\n",
      "dec_tensor 35347 [[   1 1141 4027   10    8    7    2    0    0    0    0    0    0    0\n",
      "     0    0    0]\n",
      " [   1 1609  652   15  693   10   24    7    2    0    0    0    0    0\n",
      "     0    0    0]] [[   1  271  132   48   10   45 1071    9   24    7    2    0    0    0\n",
      "     0    0    0]\n",
      " [   1   39  564   10   63   19   15  191    9   25    7    2    0    0\n",
      "     0    0    0]]\n",
      "enc_train, enc_val 31812 3535\n",
      "dec_train, dec_val 31812 3535\n"
     ]
    }
   ],
   "source": [
    "#### 정수인덱스 토큰화하기, 보정처리 및 padding\n",
    "def tokenize(corpus,maxlen=20, que_token= False): \n",
    "    ## 정수인덱스 토큰화\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', oov_token= '<unk>')  #lower 또하면 'BOS''EOS'도 소문자됨      \n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    #[주의!!] 보정처리할 경우에는 texts_to_sequences(corpus)를 보정처리후 padding전에  해야함\n",
    "    \n",
    "    ## 보정처리, texts_to_sequences 및 패딩: \n",
    "    print(\"보정전 단어사전 길이:\", len(tokenizer.index_word), len(tokenizer.word_index))\n",
    "    if que_token == True:\n",
    "        # quetions 보정처리\n",
    "        print(\"보정전 tokenizer.index_word[0~10]\",[(k,v) for (k,v) in tokenizer.index_word.items() if k <=10])\n",
    "        \n",
    "        tokenizer.index_word = {k + 3: v for k,v in tokenizer.index_word.items()}\n",
    "        tokenizer.index_word.update({0:'<pad>',1:'', 2:'', 3:'<unk>'}) \n",
    "        # 중복있을 경우 제거: '<unk>','',''\n",
    "        tokenizer.index_word={k:v for k,v in tokenizer.index_word.items() if (k in [0,3]) or  v not in ['<unk>','','']}\n",
    "       \n",
    "        tokenizer.word_index = {v: k for k,v in tokenizer.index_word.items()}\n",
    "        print(\"tokenizer.index_word\",tokenizer.index_word[0],tokenizer.index_word[3],tokenizer.index_word[5])\n",
    "        print(\"tokenizer.word_index\",tokenizer.word_index['<pad>'],tokenizer.word_index['<unk>'])\n",
    "               \n",
    "        # 보정처리완료후texts_to_sequences(corpus)\n",
    "        tensor = tokenizer.texts_to_sequences(corpus)\n",
    "        # 패딩\n",
    "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post') #maxlen = maxlen,#maxlen = 50,\n",
    "        \n",
    "    else:\n",
    "        # ansers 보정처리\n",
    "        print(\"보정전 tokenizer.index_word[0~10]\",[(k,v) for i,(k,v) in enumerate(tokenizer.index_word.items()) if i <=20])\n",
    "        \n",
    "        tokenizer.index_word = {k + 3: v for k,v in tokenizer.index_word.items()}\n",
    "        tokenizer.index_word.update({0:'<pad>',1: '<start>', 2:'<end>', 3:'<unk>'}) \n",
    "        # 중복있을 경우 제거: '<unk>','<start>','<end>\n",
    "        tokenizer.index_word={k:v for k,v in tokenizer.index_word.items() if k < 4 or  v not in ['<unk>','<start>','<end>']}\n",
    "        \n",
    "        tokenizer.word_index = {v: k for k,v in tokenizer.index_word.items()}\n",
    "        print(\"tokenizer.index_word\",tokenizer.index_word[0],tokenizer.index_word[1],tokenizer.index_word[2],\n",
    "             tokenizer.index_word[3])\n",
    "        print(\"tokenizer.word_index\",tokenizer.word_index['<pad>'],tokenizer.word_index['<start>'],\n",
    "              tokenizer.word_index['<end>'],tokenizer.word_index['<unk>'])    \n",
    "        print(\"보정후 tokenizer.index_word[0~10]\",[(k,v) for (k,v) in tokenizer.index_word.items() if k<=20])\n",
    "        \n",
    "        # 보정처리완료후texts_to_sequences(corpus)\n",
    "        tensor = tokenizer.texts_to_sequences(corpus)\n",
    "        # 패딩\n",
    "        tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post') #maxlen = maxlen,maxlen\n",
    "        \n",
    "    \n",
    "    print(\"보정후 단어사전 길이:\", len(tokenizer.index_word), len(tokenizer.word_index))\n",
    "    \n",
    "    return tensor, tokenizer\n",
    "\n",
    "# 정수인덱스 토큰화및 패딩처리를 완료하여 학습용 데이터를 완성. \n",
    "enc_tensor, enc_tokenizer = tokenize(new_que_corpus_cleaned, maxlen= 20, que_token= True)\n",
    "dec_tensor, dec_tokenizer = tokenize(new_ans_corpus_cleaned_add, maxlen= 20 )\n",
    "\n",
    "print(\"enc_tensor\", len(enc_tensor), enc_tensor[:2],enc_tensor[-2:])\n",
    "print(\"dec_tensor\", len(dec_tensor), dec_tensor[:2],dec_tensor[-2:])\n",
    "\n",
    "# train_data  permutation(shuffle): train_data == numpy.array\n",
    "indices_permutation = np.random.permutation(len(enc_tensor))\n",
    "\n",
    "enc_tensor = enc_tensor[indices_permutation]\n",
    "dec_tensor = dec_tensor[indices_permutation]\n",
    "print(\"enc_tensor\", len(enc_tensor), enc_tensor[:2],enc_tensor[-2:])\n",
    "print(\"dec_tensor\", len(dec_tensor), dec_tensor[:2],dec_tensor[-2:])\n",
    "\n",
    "# train_data  valid data 분리:  0.9 \n",
    "splitlen = int(len(enc_tensor)*0.9)\n",
    "\n",
    "enc_train = enc_tensor[:splitlen]\n",
    "enc_val =  enc_tensor[splitlen:]\n",
    "print(\"enc_train, enc_val\", len(enc_train), len(enc_val))\n",
    "\n",
    "dec_train = dec_tensor[:splitlen]\n",
    "dec_val =  dec_tensor[splitlen:]\n",
    "print(\"dec_train, dec_val\", len(dec_train), len(dec_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4344d24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answers 길이 평균, 표준편차, 최대,최소:  17.0 0.0 17 17\n"
     ]
    }
   ],
   "source": [
    "# length list\n",
    "lenq = [len(x) for x in enc_train]\n",
    "lena = [len(x) for x in dec_train]\n",
    "\n",
    "# 데이터 길이 분포 파악\n",
    "max_length_a = np.max(lena)\n",
    "min_length_a = np.min(lena)\n",
    "mean_length_a = np.mean(lena)\n",
    "std_length_a = np.std(lena)\n",
    "print(\"answers 길이 평균, 표준편차, 최대,최소: \", mean_length_a, std_length_a, max_length_a, min_length_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc7540e",
   "metadata": {},
   "source": [
    "#### max_length 재설정: 15개 --> 17개로 증가 반영\n",
    "step2 에서 일정길이 문장이상 제외위해 설정한 maxlen 15에서, step5에서 'start', 'end' 토큰추가등 보정처리후\n",
    "padding 작업결과 maxlen 증가됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f148b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maxlen 17\n"
     ]
    }
   ],
   "source": [
    "maxlen = 17\n",
    "print(\"maxlen\", maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0e6026",
   "metadata": {},
   "source": [
    "#### Step 6. 훈련하기\n",
    "앞서 번역 모델을 훈련하며 정의한 Transformer 를 그대로 사용하시면 됩니다! 대신 데이터의 크기가 작으니 하이퍼파라미터를 튜닝해야 과적합을 피할 수 있습니다. 모델을 훈련하고 아래 예문에 대한 답변을 생성하세요! **가장 멋진 답변과 모델의 하이퍼파라미터를 제출**하시면 됩니다.\n",
    "\n",
    "```\n",
    "# 예문\n",
    "1. 지루하다, 놀러가고 싶어.\n",
    "2. 오늘 일찍 일어났더니 피곤하다.\n",
    "3. 간만에 여자친구랑 데이트 하기로 했어.\n",
    "4. 집에 있는다는 소리야.\n",
    "\n",
    "---\n",
    "\n",
    "# 제출\n",
    "\n",
    "Translations\n",
    "> 1. 잠깐 쉬 어도 돼요 . <end>\n",
    "> 2. 맛난 거 드세요 . <end>\n",
    "> 3. 떨리 겠 죠 . <end>\n",
    "> 4. 좋 아 하 면 그럴 수 있 어요 . <end>\n",
    "\n",
    "Hyperparameters\n",
    "> n_layers: 1\n",
    "> d_model: 368\n",
    "> n_heads: 8\n",
    "> d_ff: 1024\n",
    "> dropout: 0.2\n",
    "\n",
    "Training Parameters\n",
    "> Warmup Steps: 1000\n",
    "> Batch Size: 64\n",
    "> Epoch At: 10\n",
    "```\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4267ab",
   "metadata": {},
   "source": [
    "#### 모델구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1c00041",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    print(sinusoid_table)\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    return sinusoid_table\n",
    "\n",
    "#print(positional_encoding(10, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59df29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads  \n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model) # Linear Layer\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "\n",
    "        \"\"\"\n",
    "        Scaled QK 값 구하기\n",
    "        \"\"\"\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        \"\"\"\n",
    "        1. Attention Weights 값 구하기 -> attentions\n",
    "        2. Attention 값을 V에 곱하기 -> out\n",
    "        \"\"\" \n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        \"\"\"\n",
    "        Embedding을 Head의 수로 분할하는 함수\n",
    "\n",
    "        x: [ batch x length x emb ]\n",
    "        return: [ batch x length x heads x self.depth ]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        \"\"\"\n",
    "        분할된 Embedding을 하나로 결합하는 함수\n",
    "        x: [ batch x length x heads x self.depth ]\n",
    "        return: [ batch x length x emb ]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "          \n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        \"\"\"\n",
    "        아래 순서에 따라 소스를 작성하세요.\n",
    "\n",
    "        Step 1: Linear_in(Q, K, V) -> WQ, WK, WV\n",
    "        Step 2: Split Heads(WQ, WK, WV) -> WQ_split, WK_split, WV_split\n",
    "        Step 3: Scaled Dot Product Attention(WQ_split, WK_split, WV_split)\n",
    "                 -> out, attention_weights\n",
    "        Step 4: Combine Heads(out) -> out\n",
    "        Step 5: Linear_out(out) -> out\n",
    "\n",
    "        \"\"\"\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "            \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "       \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "       \n",
    "        return out, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ffb8f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd4b2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f7219f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecoderLayer 클래스를 작성하세요.\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, n_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout) \n",
    "                \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        \n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)  # padding_mask == dec_mask == tf.maximum(dec_mask,dec_causal_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)  # causal_mask==tf.maxi(enc_mas,dec_enc_causal_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, dec_attn, dec_enc_attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "285d0a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "534b31cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "                            \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "621e81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 pos_len,\n",
    "                 dropout=0.2,\n",
    "                 shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        #self.d_model = tf.cast(d_model, tf.float32)  ==> float로 할 경우 dimension 오류발생됨\n",
    "        self.d_model = d_model   \n",
    "        \"\"\"\n",
    "        1. Embedding Layer 정의\n",
    "        2. Positional Encoding 정의\n",
    "        3. Encoder / Decoder 정의\n",
    "        4. Output Linear 정의\n",
    "        5. Shared Weights\n",
    "        6. Dropout 정의\n",
    "        \"\"\"\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, self.d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, self.d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)   # int(n_heads)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)   # int(n_heads)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        \"\"\"\n",
    "        입력된 정수 배열을 Embedding + Pos Encoding\n",
    "        + Shared일 경우 Scaling 작업 포함\n",
    "\n",
    "        x: [ batch x length ]\n",
    "        return: [ batch x length x emb ]\n",
    "        \"\"\"      \n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared: out *= tf.math.sqrt(tf.cast(d_model, tf.float32)) #self.d_model)   # int ???  self.d_model\n",
    "       \n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        \"\"\"\n",
    "        아래 순서에 따라 소스를 작성하세요.\n",
    "\n",
    "        Step 1: Embedding(enc_in, dec_in) -> enc_in, dec_in\n",
    "        Step 2: Encoder(enc_in, enc_mask) -> enc_out, enc_attns\n",
    "        Step 3: Decoder(dec_in, enc_out, mask)\n",
    "                -> dec_out, dec_attns, dec_enc_attns\n",
    "        Step 4: Out Linear(dec_out) -> logits\n",
    "        \"\"\"\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14d9aeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    #print(\"enc_mask\",enc_mask.shape,enc_mask,\"dec_enc_causality_mask\",dec_enc_causality_mask.shape,dec_enc_causality_mask)\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "    #print(\"dec_enc_mask\",dec_enc_mask.shape,dec_enc_mask)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "    #print(\"dec_mask\",dec_mask.shape, dec_mask,\"dec_causality_mask\",dec_causality_mask.shape,dec_causality_mask)\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c796331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  LearningRateScheduler 클래스 함수정의\n",
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "#learning_rate = LearningRateScheduler(d_model = 512, warmup_steps = 4000)\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa89fc2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 9.75282507e-01 9.51175969e-01 ... 1.07797502e-04\n",
      "  1.05133018e-04 1.02534393e-04]\n",
      " [2.00000000e+00 1.95056501e+00 1.90235194e+00 ... 2.15595003e-04\n",
      "  2.10266035e-04 2.05068786e-04]\n",
      " ...\n",
      " [1.40000000e+01 1.36539551e+01 1.33164636e+01 ... 1.50916502e-03\n",
      "  1.47186225e-03 1.43548150e-03]\n",
      " [1.50000000e+01 1.46292376e+01 1.42676395e+01 ... 1.61696252e-03\n",
      "  1.57699527e-03 1.53801590e-03]\n",
      " [1.60000000e+01 1.56045201e+01 1.52188155e+01 ... 1.72476003e-03\n",
      "  1.68212828e-03 1.64055029e-03]]\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "n_layers= 1\n",
    "d_model= 368\n",
    "n_heads= 8\n",
    "d_ff= 1024\n",
    "pos_len = 17\n",
    "dropout= 0.3   \n",
    "src_vocab_size = len(enc_tokenizer.word_index) #6167\n",
    "tgt_vocab_size = len(dec_tokenizer.word_index) #7187\n",
    "shared=True\n",
    "\n",
    "#Training Parameters\n",
    "warmup_steps = 1000\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10 \n",
    "\n",
    "\n",
    "# 트랜스포머 모델설정\n",
    "transformer = Transformer(n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 pos_len,\n",
    "                 dropout=dropout,\n",
    "                 shared=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "444e1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e870ec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    #[주의} real data는 transformer model 내에서는 마스크가 씌워지는 절차없으니,여기서 씌움,모델내에서는 enc_train,dec_train 만 씌움\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))   # 여기선 마스크씌울 부분이 0 이됨, \"곱해주는 마스크\"라서, 0이됨 \n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask         # 여기선 마스크씌울 부분이 0 이므로, 곱해주어야 패딩부분이 0이되어 무시됨,즉, loss의 합계에서 제외됨 \n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c89f0936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step 함수 정의\n",
    "\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    # 최종적으로 optimizer.apply_gradients()가 사용됩니다. \n",
    "    # [[YOUR CODE]]\n",
    "    variables = model.encoder.trainable_variables + model.decoder.trainable_variables \n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "        \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e2b37a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid Step 함수 정의\n",
    "\n",
    "@tf.function()\n",
    "def valid_step(src, tgt, model):\n",
    "    gold = tgt[:, 1:]\n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask, training=False)\n",
    "    val_loss = loss_function(gold, predictions[:, :-1])\n",
    "    \n",
    "    return val_loss    #, enc_attns, dec_attns, dec_enc_attns\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "dca924a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 9.82171889e-01 9.64661620e-01 ... 1.05544960e-04\n",
      "  1.03663293e-04 1.01815172e-04]\n",
      " [2.00000000e+00 1.96434378e+00 1.92932324e+00 ... 2.11089920e-04\n",
      "  2.07326586e-04 2.03630344e-04]\n",
      " ...\n",
      " [1.40000000e+01 1.37504064e+01 1.35052627e+01 ... 1.47762944e-03\n",
      "  1.45128610e-03 1.42541241e-03]\n",
      " [1.50000000e+01 1.47325783e+01 1.44699243e+01 ... 1.58317440e-03\n",
      "  1.55494939e-03 1.52722758e-03]\n",
      " [1.60000000e+01 1.57147502e+01 1.54345859e+01 ... 1.68871936e-03\n",
      "  1.65861269e-03 1.62904275e-03]]\n",
      "i 0 param 30\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 9.82171889e-01 9.64661620e-01 ... 1.05544960e-04\n",
      "  1.03663293e-04 1.01815172e-04]\n",
      " [2.00000000e+00 1.96434378e+00 1.92932324e+00 ... 2.11089920e-04\n",
      "  2.07326586e-04 2.03630344e-04]\n",
      " ...\n",
      " [1.40000000e+01 1.37504064e+01 1.35052627e+01 ... 1.47762944e-03\n",
      "  1.45128610e-03 1.42541241e-03]\n",
      " [1.50000000e+01 1.47325783e+01 1.44699243e+01 ... 1.58317440e-03\n",
      "  1.55494939e-03 1.52722758e-03]\n",
      " [1.60000000e+01 1.57147502e+01 1.54345859e+01 ... 1.68871936e-03\n",
      "  1.65861269e-03 1.62904275e-03]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f52cfb455b48cd81e27c10e2dedaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0 idx 0 batch_loss1 9.1367\n",
      "epoch 0 batch 250 idx 16000 batch_loss1 5.0468\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 0 epoch_val_loss1 4.0217\n",
      "Epoch 0 Epoch_변화시_학습율적용_step >> count_step 495 lr 0.0019566594\n",
      "epoch_loss 4.4156 epoch_val_loss 4.0217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03f9fb71e60749d4a9a624fc36dc30c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 batch 0 idx 0 batch_loss1 4.0795\n",
      "epoch 1 batch 250 idx 16000 batch_loss1 3.2013\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 1 epoch_val_loss1 2.4796\n",
      "Epoch 1 Epoch_변화시_학습율적용_step >> count_step 990 lr 0.0014045831\n",
      "epoch_loss 2.8226 epoch_val_loss 2.4796\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34f56311931c40c38229a01f89a3ab74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 batch 0 idx 0 batch_loss1 2.2695\n",
      "epoch 2 batch 250 idx 16000 batch_loss1 1.8152\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 2 epoch_val_loss1 1.711\n",
      "Epoch 2 Epoch_변화시_학습율적용_step >> count_step 1485 lr 0.0011468373\n",
      "epoch_loss 1.593 epoch_val_loss 1.711\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "305f5eef04404f8690149c36b2ef473a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 batch 0 idx 0 batch_loss1 1.2439\n",
      "epoch 3 batch 250 idx 16000 batch_loss1 1.0734\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 3 epoch_val_loss1 1.343\n",
      "Epoch 3 Epoch_변화시_학습율적용_step >> count_step 1980 lr 0.0009931902\n",
      "epoch_loss 0.9852 epoch_val_loss 1.343\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "993910c06e2d468fa69a493c1bbb4307",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 batch 0 idx 0 batch_loss1 0.9153\n",
      "epoch 4 batch 250 idx 16000 batch_loss1 0.7591\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 4 epoch_val_loss1 1.1829\n",
      "Epoch 4 Epoch_변화시_학습율적용_step >> count_step 2475 lr 0.0008883363\n",
      "epoch_loss 0.7175 epoch_val_loss 1.1829\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ace458bfa047148728729019f1a514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 batch 0 idx 0 batch_loss1 0.66\n",
      "epoch 5 batch 250 idx 16000 batch_loss1 0.5978\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 5 epoch_val_loss1 1.0904\n",
      "Epoch 5 Epoch_변화시_학습율적용_step >> count_step 2970 lr 0.0008109364\n",
      "epoch_loss 0.5724 epoch_val_loss 1.0904\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da24c947145947809828720cb8243e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 batch 0 idx 0 batch_loss1 0.6004\n",
      "epoch 6 batch 250 idx 16000 batch_loss1 0.5089\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 6 epoch_val_loss1 1.0468\n",
      "Epoch 6 Epoch_변화시_학습율적용_step >> count_step 3465 lr 0.0007507812\n",
      "epoch_loss 0.4912 epoch_val_loss 1.0468\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01dfe8d744ac43a0ae94e580fd0454b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 batch 0 idx 0 batch_loss1 0.488\n",
      "epoch 7 batch 250 idx 16000 batch_loss1 0.4427\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 7 epoch_val_loss1 1.0185\n",
      "Epoch 7 Epoch_변화시_학습율적용_step >> count_step 3960 lr 0.00070229155\n",
      "epoch_loss 0.4321 epoch_val_loss 1.0185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255800a978294ac88c56bbff2d462daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 batch 0 idx 0 batch_loss1 0.4822\n",
      "epoch 8 batch 250 idx 16000 batch_loss1 0.402\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 8 epoch_val_loss1 0.9791\n",
      "Epoch 8 Epoch_변화시_학습율적용_step >> count_step 4455 lr 0.00066212675\n",
      "epoch_loss 0.3924 epoch_val_loss 0.9791\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c610ec510642f4895bee74d2fea567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 batch 0 idx 0 batch_loss1 0.4285\n",
      "epoch 9 batch 250 idx 16000 batch_loss1 0.3709\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 9 epoch_val_loss1 0.9613\n",
      "Epoch 9 Epoch_변화시_학습율적용_step >> count_step 4950 lr 0.0006281486\n",
      "epoch_loss 0.3622 epoch_val_loss 0.9613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018fdf3640f146ba85dcf3d60dec4569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 batch 0 idx 0 batch_loss1 0.4273\n",
      "epoch 10 batch 250 idx 16000 batch_loss1 0.3415\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 10 epoch_val_loss1 0.9587\n",
      "Epoch 10 Epoch_변화시_학습율적용_step >> count_step 5445 lr 0.0005989162\n",
      "epoch_loss 0.3346 epoch_val_loss 0.9587\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c82ee7eb8584566b6b5642d91acb9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 batch 0 idx 0 batch_loss1 0.3767\n",
      "epoch 11 batch 250 idx 16000 batch_loss1 0.3176\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 11 epoch_val_loss1 0.9436\n",
      "Epoch 11 Epoch_변화시_학습율적용_step >> count_step 5940 lr 0.0005734186\n",
      "epoch_loss 0.3115 epoch_val_loss 0.9436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233ce1ece12b40c490b90f6f5ff88166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 batch 0 idx 0 batch_loss1 0.3759\n",
      "epoch 12 batch 250 idx 16000 batch_loss1 0.292\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 12 epoch_val_loss1 0.932\n",
      "Epoch 12 Epoch_변화시_학습율적용_step >> count_step 6435 lr 0.00055092276\n",
      "epoch_loss 0.2861 epoch_val_loss 0.932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb6808ed314a44d2a22f81b9eef91a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 batch 0 idx 0 batch_loss1 0.2959\n",
      "epoch 13 batch 250 idx 16000 batch_loss1 0.2733\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 13 epoch_val_loss1 0.935\n",
      "Epoch 13 Epoch_변화시_학습율적용_step >> count_step 6930 lr 0.0005308825\n",
      "epoch_loss 0.2683 epoch_val_loss 0.935\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3276cae2329345eabb5e90db50f1dc56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 batch 0 idx 0 batch_loss1 0.323\n",
      "epoch 14 batch 250 idx 16000 batch_loss1 0.2523\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 14 epoch_val_loss1 0.9676\n",
      "Epoch 14 Epoch_변화시_학습율적용_step >> count_step 7425 lr 0.0005128812\n",
      "epoch_loss 0.2476 epoch_val_loss 0.9676\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbdf42754d3e4cac89a49126a7eeeaeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 batch 0 idx 0 batch_loss1 0.2984\n",
      "epoch 15 batch 250 idx 16000 batch_loss1 0.2344\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 15 epoch_val_loss1 0.9611\n",
      "Epoch 15 Epoch_변화시_학습율적용_step >> count_step 7920 lr 0.0004965951\n",
      "epoch_loss 0.2327 epoch_val_loss 0.9611\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33558de1d4704d7c92e480146704a704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 batch 0 idx 0 batch_loss1 0.2948\n",
      "epoch 16 batch 250 idx 16000 batch_loss1 0.222\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 16 epoch_val_loss1 0.9722\n",
      "Epoch 16 Epoch_변화시_학습율적용_step >> count_step 8415 lr 0.00048176802\n",
      "epoch_loss 0.217 epoch_val_loss 0.9722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4434e9e2632d49fd8787ff026c239fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 batch 0 idx 0 batch_loss1 0.2502\n",
      "epoch 17 batch 250 idx 16000 batch_loss1 0.2057\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 17 epoch_val_loss1 0.9816\n",
      "Epoch 17 Epoch_변화시_학습율적용_step >> count_step 8910 lr 0.00046819434\n",
      "epoch_loss 0.2011 epoch_val_loss 0.9816\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f87d423c7524200b726f784f65353f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 batch 0 idx 0 batch_loss1 0.2194\n",
      "epoch 18 batch 250 idx 16000 batch_loss1 0.1895\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 18 epoch_val_loss1 1.0248\n",
      "Epoch 18 Epoch_변화시_학습율적용_step >> count_step 9405 lr 0.0004557069\n",
      "epoch_loss 0.1866 epoch_val_loss 1.0248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d6b454ef8046fa929a79b85b80f755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 batch 0 idx 0 batch_loss1 0.1734\n",
      "epoch 19 batch 250 idx 16000 batch_loss1 0.1785\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 19 epoch_val_loss1 1.0024\n",
      "Epoch 19 Epoch_변화시_학습율적용_step >> count_step 9900 lr 0.00044416814\n",
      "epoch_loss 0.1745 epoch_val_loss 1.0024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b826ac4958034043bf7bb4c53bea3e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 batch 0 idx 0 batch_loss1 0.21\n",
      "epoch 20 batch 250 idx 16000 batch_loss1 0.1655\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 20 epoch_val_loss1 1.0201\n",
      "Epoch 20 Epoch_변화시_학습율적용_step >> count_step 10395 lr 0.00043346375\n",
      "epoch_loss 0.1632 epoch_val_loss 1.0201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e3b2dd0307407980d491c5638d02df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 batch 0 idx 0 batch_loss1 0.2016\n",
      "epoch 21 batch 250 idx 16000 batch_loss1 0.1554\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 21 epoch_val_loss1 1.0107\n",
      "Epoch 21 Epoch_변화시_학습율적용_step >> count_step 10890 lr 0.0004234977\n",
      "epoch_loss 0.1532 epoch_val_loss 1.0107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edcd2e472104cf8b2362481ba15feb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 batch 0 idx 0 batch_loss1 0.1308\n",
      "epoch 22 batch 250 idx 16000 batch_loss1 0.1446\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 22 epoch_val_loss1 1.0091\n",
      "Epoch 22 Epoch_변화시_학습율적용_step >> count_step 11385 lr 0.00041418892\n",
      "epoch_loss 0.1416 epoch_val_loss 1.0091\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51eed7167f894d3c9ea73be3c6c77f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 batch 0 idx 0 batch_loss1 0.1283\n",
      "epoch 23 batch 250 idx 16000 batch_loss1 0.1361\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 23 epoch_val_loss1 1.0061\n",
      "Epoch 23 Epoch_변화시_학습율적용_step >> count_step 11880 lr 0.0004054682\n",
      "epoch_loss 0.1335 epoch_val_loss 1.0061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3687892d0de24b20bc0fc8799f86c9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 batch 0 idx 0 batch_loss1 0.1156\n",
      "epoch 24 batch 250 idx 16000 batch_loss1 0.1285\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 24 epoch_val_loss1 1.0197\n",
      "Epoch 24 Epoch_변화시_학습율적용_step >> count_step 12375 lr 0.00039727608\n",
      "epoch_loss 0.1279 epoch_val_loss 1.0197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16268f90c1c4ff28263b861c2a2babe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 batch 0 idx 0 batch_loss1 0.1375\n",
      "epoch 25 batch 250 idx 16000 batch_loss1 0.1232\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 25 epoch_val_loss1 1.0082\n",
      "Epoch 25 Epoch_변화시_학습율적용_step >> count_step 12870 lr 0.00038956126\n",
      "epoch_loss 0.1206 epoch_val_loss 1.0082\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b947b4408e654860af93895353b82fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 batch 0 idx 0 batch_loss1 0.1409\n",
      "epoch 26 batch 250 idx 16000 batch_loss1 0.1182\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 26 epoch_val_loss1 1.018\n",
      "Epoch 26 Epoch_변화시_학습율적용_step >> count_step 13365 lr 0.00038227907\n",
      "epoch_loss 0.1176 epoch_val_loss 1.018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24ef78ad9874837a3bc677ad0483135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 batch 0 idx 0 batch_loss1 0.143\n",
      "epoch 27 batch 250 idx 16000 batch_loss1 0.1117\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 27 epoch_val_loss1 1.0394\n",
      "Epoch 27 Epoch_변화시_학습율적용_step >> count_step 13860 lr 0.0003753906\n",
      "epoch_loss 0.1108 epoch_val_loss 1.0394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95bb347513a4888825ff42f1b5f1eb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 batch 0 idx 0 batch_loss1 0.1201\n",
      "epoch 28 batch 250 idx 16000 batch_loss1 0.1068\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 28 epoch_val_loss1 1.0255\n",
      "Epoch 28 Epoch_변화시_학습율적용_step >> count_step 14355 lr 0.00036886157\n",
      "epoch_loss 0.1068 epoch_val_loss 1.0255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6d48e4926c47b1936029effd9556a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 batch 0 idx 0 batch_loss1 0.1351\n",
      "epoch 29 batch 250 idx 16000 batch_loss1 0.1019\n",
      "val_batch 0\n",
      "val_batch 25\n",
      "val_batch 50\n",
      "epoch 29 epoch_val_loss1 1.035\n",
      "Epoch 29 Epoch_변화시_학습율적용_step >> count_step 14850 lr 0.00036266178\n",
      "epoch_loss 0.1019 epoch_val_loss 1.035\n",
      "history.keys() dict_keys(['epoch']) dict_keys(['30'])\n",
      "history[hpname][f'{param}']['loss'] [4.4156, 2.8226, 1.593, 0.9852, 0.7175, 0.5724, 0.4912, 0.4321, 0.3924, 0.3622, 0.3346, 0.3115, 0.2861, 0.2683, 0.2476, 0.2327, 0.217, 0.2011, 0.1866, 0.1745, 0.1632, 0.1532, 0.1416, 0.1335, 0.1279, 0.1206, 0.1176, 0.1108, 0.1068, 0.1019]\n",
      "history[hpname][f'{param}']['val_loss'] [4.0217, 2.4796, 1.711, 1.343, 1.1829, 1.0904, 1.0468, 1.0185, 0.9791, 0.9613, 0.9587, 0.9436, 0.932, 0.935, 0.9676, 0.9611, 0.9722, 0.9816, 1.0248, 1.0024, 1.0201, 1.0107, 1.0091, 1.0061, 1.0197, 1.0082, 1.018, 1.0394, 1.0255, 1.035]\n",
      "history[hpname][f'{param}']['lr'] [0.0019566594, 0.0014045831, 0.0011468373, 0.0009931902, 0.0008883363, 0.0008109364, 0.0007507812, 0.00070229155, 0.00066212675, 0.0006281486, 0.0005989162, 0.0005734186, 0.00055092276, 0.0005308825, 0.0005128812, 0.0004965951, 0.00048176802, 0.00046819434, 0.0004557069, 0.00044416814, 0.00043346375, 0.0004234977, 0.00041418892, 0.0004054682, 0.00039727608, 0.00038956126, 0.00038227907, 0.0003753906, 0.00036886157, 0.00036266178]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_Best_val_epoch_loss [[13, 0.932]]\n",
      "Best_hpname_param_list 1 [['epoch', []]]\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 튜닝_학습\n",
    "from tqdm import tqdm_notebook \n",
    "import tqdm\n",
    "\n",
    "\n",
    "#Hyperparameters\n",
    "n_layers= 2\n",
    "d_model= 512 #368 #512 #368\n",
    "n_heads= 8\n",
    "d_ff= 1024\n",
    "pos_len = 17\n",
    "dropout= 0.3 #0.2  #0.3 #0.2\n",
    "src_vocab_size = len(enc_tokenizer.word_index) #6167\n",
    "tgt_vocab_size = len(dec_tokenizer.word_index) #7187\n",
    "shared=True\n",
    "\n",
    "#Training Parameters\n",
    "warmup_steps = 500 #1000 #500  # 1000\n",
    "BATCH_SIZE = 64    # 건들지 말것\n",
    "EPOCHS = 30 #10 \n",
    "\n",
    "\n",
    "## Hyper param tuning : hparam 한개씩 해서,search space 구성후, loss가 제일 낮은 param을 1차 자동선택후,  번역수준을 눈으로 추가확인  \n",
    "# hpname list 설정\n",
    "hp_name_list = ['epoch'] #'EPOCHS'] \n",
    "\n",
    "# search space 설정: param 설정\n",
    "dropout_list = [0.1,0.2,0.3,0.4,0.5,0.7]\n",
    "optimizer_list = [tf.keras.optimizers.RMSprop(learning_rate),tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)]\n",
    "warmup_steps_list = [500, 2000] #2000,4000,6000]\n",
    "d_model_list = [128, 256, 368, 512]\n",
    "dff_list = [512, 768,1024]\n",
    "n_head_list = [4,8]\n",
    "#batchsize_list = [32,64,128]\n",
    "epoch_list= [EPOCHS]\n",
    "\n",
    "# 금번 Tuning 대상 설정\n",
    "total_hyperparam_list = [epoch_list]\n",
    "\n",
    "# 필요 list\n",
    "hyperparam_list = []\n",
    "Best_hpname_param_list = []\n",
    "\n",
    "# 학습 Histoty Dict 설정\n",
    "history={}\n",
    "\n",
    "# Hyper param Tuning 실행\n",
    "\n",
    "for ix, hpname in enumerate(hp_name_list):\n",
    "    history[hpname]={}\n",
    "    hyperparam_list = total_hyperparam_list[ix]    \n",
    "    for i, param in enumerate(hyperparam_list):\n",
    "        print(\"i\",i, \"param\",param)\n",
    "        history[hpname][f'{param}']= {'loss':[], 'val_loss':[], 'lr':[]}   #,'result':[]}\n",
    "\n",
    "        del transformer\n",
    "\n",
    "        # 트랜스포머 모델설정\n",
    "        transformer = Transformer(n_layers,\n",
    "                                  d_model,       \n",
    "                                  n_heads,\n",
    "                                  d_ff,\n",
    "                                  src_vocab_size,\n",
    "                                  tgt_vocab_size,\n",
    "                                  pos_len,\n",
    "                                  dropout,\n",
    "                                  shared=True)       \n",
    "\n",
    "        # 학습율 객체화 \n",
    "        learning_rate = LearningRateScheduler(d_model = d_model, warmup_steps = warmup_steps)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9) # 디폴트 beta_2=0.999,e=10−7\n",
    "        \n",
    "        # 별도 학습율 계산 함수 정의\n",
    "        def compute_lr(step,warmup_steps):\n",
    "            arg1 = step ** -0.5\n",
    "            arg2 = step * (warmup_steps ** -1.5)\n",
    "            lr= (d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "            lr = lr.numpy()\n",
    "            return lr\n",
    "     \n",
    "        @tf.function()\n",
    "        def train_step(src, tgt, model, optimizer):\n",
    "            gold = tgt[:, 1:]\n",
    "            enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "            # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "                loss = loss_function(gold, predictions[:, :-1])\n",
    "                \n",
    "            # 최종적으로 optimizer.apply_gradients()가 사용됩니다. \n",
    "            # [[YOUR CODE]]\n",
    "            variables = model.encoder.trainable_variables + model.decoder.trainable_variables \n",
    "            gradients = tape.gradient(loss, variables)\n",
    "            optimizer.apply_gradients(zip(gradients, variables))\n",
    "            \n",
    "            return loss, enc_attns, dec_attns, dec_enc_attns \n",
    "        \n",
    "        @tf.function()\n",
    "        def valid_step(src, tgt, model):\n",
    "            gold = tgt[:, 1:]\n",
    "            enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "            \n",
    "            predictions, _, _, _ = model(src, tgt, enc_mask, dec_enc_mask, dec_mask, training=False)\n",
    "            val_loss = loss_function(gold, predictions[:, :-1])\n",
    "            \n",
    "            return val_loss    #, enc_attns, dec_attns, dec_enc_attns\n",
    "       \n",
    "        count_step = 0\n",
    "        for epoch in range(param):  #EPOCHS):\n",
    "            total_loss = 0\n",
    "            total_val_loss = 0\n",
    "                      \n",
    "            idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "            #random.shuffle(idx_list)\n",
    "            t = tqdm.notebook.tqdm(idx_list)\n",
    "            \n",
    "            for (batch, idx) in enumerate(t):\n",
    "                        \n",
    "                if idx in [11456,12096,13888,]:  #random_seed=119 \n",
    "                    continue\n",
    "            \n",
    "                count_step+= 1\n",
    "                batch_loss, enc_attns, dec_attns, dec_enc_attns = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                           dec_train[idx:idx+BATCH_SIZE],transformer, optimizer) \n",
    "                              \n",
    "                total_loss += batch_loss   #batch_loss: 배치단위 손실이 loss function(트랜스포머는마스크않된단어수로 나눔)에서계산, \n",
    "                #===> s2s는 train_step내에서 enc_train.shape[1],즉, 단어수로 나뉘나, 트랜스포머는 마스크않된 단어수로 나뉨)\n",
    "                \n",
    "                batch_loss1 = round(total_loss.numpy() / (batch + 1),4)   # 총누적손실을 누적배치size로 나눈것,즉,배치별 평균\n",
    "                \n",
    "                ## loss 모니터\n",
    "                if batch%250 ==0:\n",
    "                    print(\"epoch\", epoch,\"batch\", batch, \"idx\", idx,\"batch_loss1\", batch_loss1)\n",
    "                               \n",
    "                t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "                t.set_postfix_str('Loss %.4f' % (batch_loss1))\n",
    "                              \n",
    "                # step기준 learning_rate\n",
    "                lr = compute_lr(count_step, warmup_steps) \n",
    "                \n",
    "                # step기준 batch 단위 loss 집계 \n",
    "                #history[hpname][f'{param}']['loss'].append(batch_loss1)\n",
    "                #history['lr'].append(optimizer.learning_rate)\n",
    "                #history['lr'].append(optimizer.learning_rate)\n",
    "                \n",
    "            # valid data \n",
    "            idx_list_val = list(range(0, enc_val.shape[0], BATCH_SIZE))\n",
    "            for (batch, idx) in enumerate(idx_list_val):    \n",
    "                \n",
    "                if batch%25 ==0:\n",
    "                    print(\"val_batch\", batch)\n",
    "                    \n",
    "                val_loss = valid_step(enc_val,dec_val,transformer)\n",
    "                \n",
    "                total_val_loss +=  val_loss      #batch_loss: 배치단위인데, 배치내에서, seq_len으로 나눈것,즉,배치내 단어별 평균손실\n",
    "                val_loss1 = round(total_val_loss.numpy() / (batch + 1),4) \n",
    "                \n",
    "                t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "                t.set_postfix_str('Loss %.4f' % (val_loss1))\n",
    "            \n",
    "            ## val_loss 모니터\n",
    "            print(\"epoch\", epoch,\"epoch_val_loss1\", val_loss1)\n",
    "                       \n",
    "            print(\"Epoch\",epoch, \"Epoch_변화시_학습율적용_step >> count_step\",count_step, \"lr\", lr)    \n",
    "            \n",
    "            # epoch기준 loss 및 lr 집계   \n",
    "            print('epoch_loss', batch_loss1, 'epoch_val_loss',val_loss1)\n",
    "            history[hpname][f'{param}']['loss'].append(batch_loss1)\n",
    "            history[hpname][f'{param}']['lr'].append(lr)\n",
    "            history[hpname][f'{param}']['val_loss'].append(val_loss1)\n",
    "                             \n",
    "        # loss 그래프 \n",
    "        print(\"history.keys()\",history.keys(), history[hpname].keys() ) \n",
    "        print(\"history[hpname][f'{param}']['loss']\", history[hpname][f'{param}']['loss'])\n",
    "        print(\"history[hpname][f'{param}']['val_loss']\",history[hpname][f'{param}']['val_loss'])\n",
    "        print(\"history[hpname][f'{param}']['lr']\", history[hpname][f'{param}']['lr'])\n",
    "               \n",
    "        loss = history[hpname][f'{param}']['loss']\n",
    "        val_loss = history[hpname][f'{param}']['val_loss']\n",
    "        \n",
    "        lr = history[hpname][f'{param}']['lr']\n",
    "        epochs = range(len(loss))\n",
    "\n",
    "        # LOSS\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(epochs, loss, label='Train loss')\n",
    "        plt.plot(epochs, val_loss, label='Val loss')\n",
    "        plt.title(hpname +'_'+  f'{param}_Transformer_loss graph')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        # Lr\n",
    "        #plt.clf()   # 그림을 초기화합니다\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(epochs, lr, label='lr')\n",
    "        plt.title(hpname +'_'+   f'{param}_Transformer_learning_rate graph')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('lr')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "       \n",
    "        \n",
    "    # Best_param 선택 \n",
    "    \n",
    "    #Best_loss =  [[k1,v1] for k1,v1 in history[hpname].items() if v1['loss'][-1] == np.min([v['loss'][-1] for k,v in history[hpname].items()])][0] \n",
    "    Best_val_epoch_loss = [[i+1,v] for i,v in enumerate(history[hpname][f'{param}']['val_loss']) if v == np.min(history[hpname][f'{param}']['val_loss'])] \n",
    "    print(hpname+\"_Best_val_epoch_loss\", Best_val_epoch_loss)   # epoch는 0부터시작하는 숫자\n",
    "   \n",
    "    # hpname별 Best_param 집계\n",
    "    Best_hpname_param_list.append([hpname, Best_val_loss])\n",
    "    \n",
    "print(\"Best_hpname_param_list\",len(Best_hpname_param_list),Best_hpname_param_list)\n",
    "                                   \n",
    "# 저장\n",
    "dfhistory = pd.DataFrame(history)\n",
    "dfhistory.to_pickle(f'/aiffel/aiffel/transformer/data/History_{hpname}')\n",
    "\n",
    "df = pd.DataFrame(Best_hpname_param_list)  \n",
    "df.to_pickle(f'/aiffel/aiffel/transformer/data/Best_hpname_param_list_{hpname}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9409bd86",
   "metadata": {},
   "source": [
    "   \n",
    "#### Step 7. 성능 측정하기\n",
    "챗봇의 경우, 올바른 대답을 하는지가 중요한 평가 지표입니다. 올바른 답변을 하는지 눈으로 확인할 수 있겠지만, 많은 데이터의 경우는 모든 결과를 확인할 수 없을 것입니다. 주어진 질문에 적절한 답변을 하는지 확인하고, BLEU Score를 계산하는 calculate_bleu() 함수도 적용해 보세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe28bb8",
   "metadata": {},
   "source": [
    "```\n",
    "# 예문\n",
    "1. 지루하다, 놀러가고 싶어.\n",
    "2. 오늘 일찍 일어났더니 피곤하다.\n",
    "3. 간만에 여자친구랑 데이트 하기로 했어.\n",
    "4. 집에 있는다는 소리야.\n",
    "\n",
    "---\n",
    "\n",
    "# 제출\n",
    "\n",
    "Translations\n",
    "> 1. 잠깐 쉬 어도 돼요 . <end>\n",
    "> 2. 맛난 거 드세요 . <end>\n",
    "> 3. 떨리 겠 죠 . <end>\n",
    "> 4. 좋 아 하 면 그럴 수 있 어요 . <end>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7edbf848",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = ['지루하다, 놀러가고 싶어.',\n",
    "            '오늘 일찍 일어났더니 피곤하다.',\n",
    "            '간만에 여자친구랑 데이트 하기로 했어.',\n",
    "            '집에 있는다는 소리야.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dd029740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = Mecab()\n",
    "\n",
    "def src_tokenize(src, tokenizer,  enc_tokenizer, dec_tokenizer, maxlen= 17):\n",
    "    \n",
    "    src_id_sentences = []    \n",
    "    \n",
    "    for i, sen in enumerate(src):\n",
    "        # 전처리\n",
    "        src_sentence = preprocess_sentence(sen)    \n",
    "        \n",
    "        # 형태소분석기로 단어 토큰화\n",
    "        src_token = tokenizer.morphs(src_sentence) \n",
    "        print(\"src_token\",src_token)\n",
    "        # 정수인덱스 벡터라이즈\n",
    "        src_id_token = [enc_tokenizer.word_index[word] for word in src_token]\n",
    "        print(\"src_id_token\",src_id_token)\n",
    "        # maxlen 이하 단어갖은 문장만 append\n",
    "        if len(src_id_token) <= maxlen:\n",
    "            src_id_sentences.append(src_id_token)\n",
    "          \n",
    "    return  src_id_sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f4fdf6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(tokens, model, enc_tokenizer, dec_tokenizer, maxlen = 17):\n",
    "    \n",
    "    padded_tokens = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=maxlen,\n",
    "                                                           padding='post')   #[tokens],\n",
    "    ids = []\n",
    "    output = tf.expand_dims([dec_tokenizer.word_index['<start>']], 0)   \n",
    "    for i in range(maxlen):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = generate_masks(padded_tokens, output)\n",
    "\n",
    "        predictions, _, _, _ = model(padded_tokens, \n",
    "                                      output,\n",
    "                                      enc_padding_mask,\n",
    "                                      combined_mask,\n",
    "                                      dec_padding_mask)\n",
    "\n",
    "        predicted_id = tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if dec_tokenizer.word_index['<end>'] == predicted_id:\n",
    "            result = [dec_tokenizer.index_word[id] for id in ids]  \n",
    "            return result\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result =  [dec_tokenizer.index_word[id] for id in ids]    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "297770e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(reference, candidate, weights=[0.25, 0.25, 0.25, 0.25]):\n",
    "    return sentence_bleu([reference],\n",
    "                         candidate,\n",
    "                         weights=weights,\n",
    "                         smoothing_function=SmoothingFunction().method1)  # smoothing_function 적용\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1169fe",
   "metadata": {},
   "source": [
    "#### 테스트문장으로 번역 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d823d31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src_token ['지루', '하', '다', ',', '놀', '러', '가', '고', '싶', '어', '.']\n",
      "src_id_token [900, 8, 16, 263, 185, 159, 10, 12, 18, 9, 7]\n",
      "src_token ['오늘', '일찍', '일어났', '더니', '피곤', '하', '다', '.']\n",
      "src_id_token [65, 752, 1199, 313, 567, 8, 16, 7]\n",
      "src_token ['간만에', '여자', '친구', '랑', '데이트', '하', '기', '로', '했', '어', '.']\n",
      "src_id_token [1619, 39, 24, 104, 233, 8, 61, 96, 43, 9, 7]\n",
      "src_token ['집', '에', '있', '는다는', '소리', '야', '.']\n",
      "src_id_token [156, 25, 23, 850, 586, 45, 7]\n",
      "que_id_sentences [[900, 8, 16, 263, 185, 159, 10, 12, 18, 9, 7], [65, 752, 1199, 313, 567, 8, 16, 7], [1619, 39, 24, 104, 233, 8, 61, 96, 43, 9, 7], [156, 25, 23, 850, 586, 45, 7]] 4\n",
      "\n",
      "answer_results [['저', '도', '당신', '이', '된다면', '그런', '것', '똑같', '아요', '.'], ['풀릴', '거', '예요', '.'], ['금상첨화', '네요', '.'], ['청소기', '은가요', '이', '요', '.']]\n"
     ]
    }
   ],
   "source": [
    "# 토크나이즈\n",
    "que_id_sentences = src_tokenize(test_sentence, tokenizer,  enc_tokenizer, dec_tokenizer, maxlen=17)      \n",
    "print(\"que_id_sentences\",que_id_sentences, len(que_id_sentences))  \n",
    "print()\n",
    "\n",
    "# 번역\n",
    "answer_results =[]\n",
    "for tokens in que_id_sentences:\n",
    "    ans_result = translate(tokens, transformer, enc_tokenizer, dec_tokenizer, maxlen=17)\n",
    "    answer_results.append(ans_result)\n",
    "print(\"answer_results\", answer_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf0f353",
   "metadata": {},
   "source": [
    "#### BLEU : calculate_bleu\n",
    "\n",
    "#### 대화챗봇의 응답에대한 BLUE 평가에대한 의문점: \n",
    "**1. 챗봇의 응답은 다양한데, 그 다양한 응답의 reference를 question으로 할수도 없고, answer reference를 주관적으로 만들어야한다는 것인데, 번역문도 아니고, reference를 어떻게 구하나요???**\n",
    "\n",
    "**2. 주관적으로 창작한 응답 reference 를 각자 몇 문장 만들어서 객관적 일반화, 정량화하기위한 BLEU를 계산한다는 것이 타당한가요????, BLEU는 번역시에 해당되는 평가아닌가요???**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b10c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BLEU-1:\", calculate_bleu(reference, candidate, weights=[1, 0, 0, 0]))\n",
    "print(\"BLEU-2:\", calculate_bleu(reference, candidate, weights=[0, 1, 0, 0]))\n",
    "print(\"BLEU-3:\", calculate_bleu(reference, candidate, weights=[0, 0, 1, 0]))\n",
    "print(\"BLEU-4:\", calculate_bleu(reference, candidate, weights=[0, 0, 0, 1]))\n",
    "\n",
    "print(\"\\nBLEU-Total:\", calculate_bleu(reference, candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf11d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be0bd60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02293244",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d17152",
   "metadata": {},
   "source": [
    "본 프로젝트는 한글데이터로 대화할수 있도록 transformer를 학습시켜서 chatBot을 만드는 프로젝트입니다.\n",
    "\n",
    "#### Step 1. 데이터 다운로드\n",
    "songys/Chatbot_data 를 다운받아서,  pandas를 통해서, 읽어 온후, 11823개의 질문과 답변을 각각 questions, answers 변수에 나눠서 \n",
    "저장하였습니다.\n",
    "\n",
    "#### Step 2. 데이터 정제\n",
    "영문자와 한글, 숫자, 그리고 주요 특수문자를 제외하곤 정규식을 활용하여 모두 제거하는등 전처리를 위한  preprocess_sentence() 함수를 만들었습니다.\n",
    "\n",
    "#### Step 3. 데이터 토큰화\n",
    "build_corpus() 함수를 만들었는데, 이것은 데이터를 preprocess_sentence() 함수로 정제하고, Mecab으로 형태소분석을 하여 \n",
    "단어토큰화를 하고,일정길이 이하 문장만 선택할수 있는 기능을 위한 함수입니다.\n",
    "maxlen을 구하기 위한 데이터 분포분석을 통하여, 문장당 평균 단어수가 7.5개, 표준편차 3.5로서, \n",
    "평균에 표준편차의 2배를 더해서 얻은 값 15를 maxlen으로 정하고서, build_corpus() 함수를 통해서,1차적으로 정제된 데이터를 구했습니다. \n",
    "\n",
    "#### Step 4. Augmentation\n",
    "주어진 데이터는 1만 개가량으로 적은 편이라서,데이터를 증강하였습니다.\n",
    "한국어로 사전 훈련된 Embedding 모델을 다운로드해서, 동의어및 유의어로 기존 단어를 대체할수 있는 Lexical Substitution을 \n",
    "실제로 적용해서 데이터를 Augmentation 했습니다.   \n",
    "이를 위해서, data_augmentation 함수와 Make_CleanAugmenetDataSet_and_Remove_Nan함수를 만들었고, 이것을 통하여,\n",
    "augmentation data pair(쌍)정렬 및 ans원본+ que원본, ans증강 + que증강, ans원본 + que증강,ans증강 + que원본의 데이터를 각각만들고서,\n",
    "통합데이터완성하여, 각각 최초 11823개를 ===> 중복제거,15단어이상제거등으로 10960개 ==> 증강 완성으로 questions, answers \n",
    "각각 35347개 문장으로 만들어서 약 3.4배정도의 데이터를 생성했습니다\n",
    "\n",
    "#### Step 5. 데이터 벡터화\n",
    "ans_corpus 에 start토큰과 end토큰을 추가하고서,tokenize함수를 만들었는데, 이는 이미 단어토큰화된question, answer data를\n",
    "tf.keras.preprocessing.text.Tokenizer를 통해서, 정수인덱스로 벡터화하고, 단어사전을 만들어서, pad,start,end,unk를 보정처리하고서,\n",
    "전체적으로 벡터화된 문장들을 pad_sequence를 통해서, padding처리를 끝으로 벡터화가 완료되었습니다.\n",
    "\n",
    "벡터화후 maxlen은 15개에서 17개로 증가되었습니다. 이는 Trandformer 모델의 인자인 pos_len에 적용할 예정입니다.\n",
    "\n",
    "이 데이터들을 que,ans 각각 train data와 valid data로 9:1의 비율로 나누었습니다. 나누기전에 랜덤 셔플(퍼뮤테이션)해서, 증강된 데이터가 \n",
    "   골고루 섞이도록 하였습니다.\n",
    "\n",
    "#### Step 6. 훈련하기\n",
    "앞서 고잉딥 12에서 만든 번역기 모델인 Transformer 를 그대로 사용해도 되어서, 그대로 사용하여, 모델구성은 쉽게\n",
    "처리되었습니다.\n",
    "\n",
    "해당모델로 train data, valid데이터로 검증을 하며 학습을 시켰는데, 하이퍼파라메터는 전체적으로 튜닝을 했는데,\n",
    "warmup_steps, dropout, d_model에서, LMS교재의 Hyper param보다 Loss가 축소되어서, 변경해서, 학습시켰습니다.\n",
    "학습결과는 30회 학습후에 train loss 0.1019, valid loss 1.035 였습니다. val_loss는 Plot을 보면 12~16 epoch 사이에서\n",
    "0.9 까지 내려갔으나, 이후 횡보하여, 30epoch를 최종 epoch로 선택하였습니다.\n",
    "\n",
    "loss가 Nan이 난 원인 찾기위해 다양한 시도를 해볼수 있었으나, 시간이 많이 소요되어 커리큘럼상 진도따라잡기에 빡빡한 시간이었습니다.\n",
    "\n",
    "#### step 7. 성능평가\n",
    "학습결과를 평가해보면, LMS교재상의 예문을 사용하였는데,\n",
    "\n",
    "입력 Question: ['지루', '하', '다', ',', '놀', '러', '가', '고', '싶', '어', '.']\n",
    "답변 Answer: ['저', '도', '당신', '이', '된다면', '그런', '것', '똑같', '아요', '.'] \n",
    "    \n",
    "입력 Question: ['오늘', '일찍', '일어났', '더니', '피곤', '하', '다', '.']\n",
    "답변 Answer:  ['풀릴', '거', '예요', '.']\n",
    "    \n",
    "입력 Question: ['간만에', '여자', '친구', '랑', '데이트', '하', '기', '로', '했', '어', '.']\n",
    "답변 Answer:   ['금상첨화', '네요', '.']\n",
    "    \n",
    "입력 Question: ['집', '에', '있', '는다는', '소리', '야', '.']\n",
    "답변 Answer:   ['청소기', '은가요', '이', '요', '.']\n",
    "    \n",
    "질문에 대한 트랜스포머챗봇의 응답이 앞의 3가지는 그런대로 괜찮습니다, 4번째는 청소기를 가지고 문장을 만들려다가 잘않된 모양새인데,\n",
    "그런대로 괜찮은 듯 싶습니다.\n",
    "\n",
    "그런데, 챗봇의 응답에대한 평가를 BLEU로 하기는 타당해보이지를 않습니다. 번역시에 번역한 문장이 사람번역가가 한 번역과 n gram기준\n",
    "으로 겹치는 단어를 찾는 평가가 챗봇이 응답한 것에 적용한다는 것은 기준없는 정량화로 보여, 타당해 보이지 않습니다.\n",
    "BLEU는 비교기준(reference)이 객관적이라야 하는데, 챗봇응답은  n gram으로 비교할 대상이 범위가 너무 넓습니다.\n",
    "BLEU는 번역기 성능평가에 적합한것 같습니다.\n",
    "\n",
    "종합적으로 볼때,  트랜스포머로 인해 GPT가 만들어졌다는 것이 이해가 되었고, 이 모델의 핵심적 아이디어 구조의 틀을 유지한채로\n",
    "내부의 부족한 부분들을 더 많은 시간을 투자하며 바꾸어 나간다면, 자연어처리분야외의 분야에서도, 잘 적용되는 좋은 모델을\n",
    "만들어 응용해 나갈수 있을 것 같습니다.\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46976a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71e1ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cfea0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "루브릭\n",
    "\n",
    "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
    "\n",
    "평가문항\t상세기준\n",
    "1. 챗봇 훈련데이터 전처리 과정이 체계적으로 진행되었는가?\n",
    "\n",
    "챗봇 훈련데이터를 위한 전처리와 augmentation이 적절히 수행되어 3만개 가량의 훈련데이터셋이 구축되었다.\n",
    "2. transformer 모델을 활용한 챗봇 모델이 과적합을 피해 안정적으로 훈련되었는가?\n",
    "\n",
    "과적합을 피할 수 있는 하이퍼파라미터 셋이 적절히 제시되었다.\n",
    "3. 챗봇이 사용자의 질문에 그럴듯한 형태로 답하는 사례가 있는가?\n",
    "\n",
    "주어진 예문을 포함하여 챗봇에 던진 질문에 적절히 답하는 사례가 제출되었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db91c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39424c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
