{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12f91477",
   "metadata": {},
   "source": [
    "## 4-9. 프로젝트: Vocabulary Size를 변경해서 시도해보기\n",
    "지금까지는 모델을 변경하고, 모델을 조합해서 성능을 올리는 일에 힘썼습니다. 그런데 어쩌면 성능을 높이는 방법은 단순히 모델을 조정하는 일에 한정되지 않을 수 있습니다. 데이터의 전처리는 모델의 성능에 영향을 직접적으로 줍니다. 특히나 Bag of Words를 기반으로 하는 DTM이나 TF-IDF의 경우, 사용하는 단어의 수를 어떻게 결정하느냐에 따라서 성능에 영향을 줄 수 있겠죠.\n",
    "\n",
    "중요도가 낮은 단어들까지 포함해 너무 많은 단어를 사용하는 경우에도 성능이 저하될 수 있고, 반대로 너무 적은 단어들을 사용해도 성능이 저하될 수 있습니다. 이렇게 변화된 단어의 수는 또 어떤 모델을 사용하느냐에 따라 유리할 수도, 불리할 수도 있습니다.\n",
    "\n",
    "단어의 수에 따라서 모델의 성능이 어떻게 변하는지 테스트해 봅시다.\n",
    "\n",
    "```\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)\n",
    "```\n",
    "\n",
    "앞서 num_words로 사용할 단어의 수를 조정할 수 있다는 것을 배웠습니다. 빈도수가 많은 순서대로 나열했을 때, num_words의 인자로 준 정숫값만큼의 단어를 사용하고 나머지 단어는 전부 <unk>로 처리하는 원리였었죠.\n",
    "\n",
    "아래의 두 가지 경우에 대해서 지금까지 사용했던 모델들의 정확도를 직접 확인해 보세요.\n",
    "\n",
    "#### 라이브러리 버전을 확인해 봅니다    \n",
    "사용할 라이브러리 버전을 둘러봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "106bc739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "3.4.3\n",
      "0.11.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import matplotlib\n",
    "import seaborn \n",
    "import numpy \n",
    "import pandas\n",
    "import sklearn\n",
    "from tensorflow.keras.datasets import reuters\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(matplotlib.__version__)\n",
    "print(seaborn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d2d1108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9140e846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import accuracy_score #정확도 계산\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa14bd29",
   "metadata": {},
   "source": [
    "#### 1. 모든 단어 사용: 시간소요 많은 관계로 아래 3번의 20000개로 대체\n",
    "```\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0595a",
   "metadata": {},
   "source": [
    "#### 2. 빈도수 상위 5,000개의 단어만 사용: 실행소요시간 감안하여,비교편의상 아래 3번에서 5,000개 실행으로 대체\n",
    "```\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=5000, test_split=0.2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49326239",
   "metadata": {},
   "source": [
    "# 3. 직접 단어 개수를 설정해서 사용\n",
    "\n",
    "위 단계에서 5000으로 제시된 num_words를 다양하게 바꾸어 가며 성능을 확인해보세요. 변화된 단어 수에 따른 모델의 성능을 연구해 보세요. 최소 3가지 경우 이상을 실험해 보기를 권합니다.\n",
    ">\n",
    "> 사용할 모델\n",
    ">\n",
    "> 나이브 베이즈 분류기, CNB, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리, 보팅\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c58e28",
   "metadata": {},
   "source": [
    "## (1) num_word 개수: 20,000 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0d44c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n",
      "2121728/2110848 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words= 20000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b6044f",
   "metadata": {},
   "source": [
    "#### 1-1) 데이터 벡터화의 전과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666b5e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "(8982,)\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 18292, 159, 9, 1084, 363, 13, 19231, 71, 9, 16273, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 16273, 7, 748, 48, 9, 19231, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
      "클래스의 수 : 46\n",
      "훈련용 뉴스의 최대 길이 :2376\n",
      "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n",
      "565248/550378 [==============================] - 0s 0us/step\n",
      "=3\n",
      "30979\n",
      "=3\n",
      "30979\n",
      "=3\n",
      "=3\n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "8982\n",
      "2246\n",
      "(8982, 18479)\n",
      "(8982, 18479)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "print(x_train.shape)\n",
    "#print(dir(reuters))\n",
    "#print(len(reuters.get_word_index()))\n",
    "\n",
    "print(x_train[0])\n",
    "print(x_test[0])\n",
    "\n",
    "num_classes = max(y_train) + 1\n",
    "print('클래스의 수 : {}'.format(num_classes))\n",
    "\n",
    "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
    "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
    "\n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(11,5)\n",
    "sns.countplot(x=y_train)\n",
    "plt.show()\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print('=3')\n",
    "print(len(word_index))\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print('=3')\n",
    "print(len(word_index))\n",
    "\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "print('=3')\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "print('=3')\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "\n",
    "## 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "# train data\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))\n",
    "# test data\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))\n",
    "\n",
    "# 변환여부 확인\n",
    "x_train[:5]\n",
    "x_test[:5]\n",
    "\n",
    "## DTM을 생성하고, DTM의 크기를 확인\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)\n",
    "\n",
    "## TF-IDF Matrix 생성하고,크기를 확인\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129d73b5",
   "metadata": {},
   "source": [
    "#### 1-2) 모델별 학습및 성능테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a27d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB 정확도: 0.6193232413178985\n",
      "MultinomialNB_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.11      0.08      0.08      2246\n",
      "weighted avg       0.52      0.62      0.53      2246\n",
      "\n",
      "소요시간1: 0 분\n",
      "ComplementNB 정확도: 0.7671415850400712\n",
      "ComplementNB_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.11      0.08      0.08      2246\n",
      "weighted avg       0.52      0.62      0.53      2246\n",
      "\n",
      "소요시간2: 0 분\n",
      "LogisticRegression 정확도: 0.8156723063223509\n",
      "LogisticRegression_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.82      2246\n",
      "   macro avg       0.79      0.63      0.67      2246\n",
      "weighted avg       0.82      0.82      0.81      2246\n",
      "\n",
      "소요시간3: 14 분\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Support Vector Machine 정확도: 0.7876224398931434\n",
      "LinearSVC_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.79      2246\n",
      "   macro avg       0.68      0.61      0.62      2246\n",
      "weighted avg       0.79      0.79      0.78      2246\n",
      "\n",
      "소요시간4: 15 분\n",
      "Decision Tree 정확도: 0.6211041852181657\n",
      "DecisionTree_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.23      0.15      0.16      2246\n",
      "weighted avg       0.62      0.62      0.58      2246\n",
      "\n",
      "소요시간5: 15 분\n",
      "Random Forest 정확도: 0.6714158504007124\n",
      "RandomForest_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.67      2246\n",
      "   macro avg       0.44      0.26      0.29      2246\n",
      "weighted avg       0.65      0.67      0.64      2246\n",
      "\n",
      "소요시간6: 15 분\n",
      "GradientBoostingClassifier 정확도: 0.7702582368655387\n",
      "GradientBoosting_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.62      0.58      0.58      2246\n",
      "weighted avg       0.77      0.77      0.76      2246\n",
      "\n",
      "소요시간7: 30 분\n",
      "Voting 정확도: 0.8192341941228851\n",
      "Voting_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.82      2246\n",
      "   macro avg       0.74      0.65      0.66      2246\n",
      "weighted avg       0.82      0.82      0.82      2246\n",
      "\n",
      "소요시간8: 58 분\n"
     ]
    }
   ],
   "source": [
    "import os, time, copy\n",
    "\n",
    "## 혼동 행렬(confusion matrix) 시각화함수 생성\n",
    "def graph_confusion_matrix(model, x_test, y_test):#, classes_name):\n",
    "  df_cm = pd.DataFrame(confusion_matrix(y_test, model.predict(x_test)))#, index=classes_name, columns=classes_name)\n",
    "  fig = plt.figure(figsize=(12,12))\n",
    "  heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "  heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n",
    "  heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "  plt.ylabel('label')\n",
    "  plt.xlabel('predicted value')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "## 3-1) 나이브 베이즈 분류기(Multinomial Naive Bayes Classifier)\n",
    "# 학습\n",
    "model = MultinomialNB()\n",
    "model.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "MultinomialNB_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"MultinomialNB 정확도:\", MultinomialNB_accuracy)\n",
    "MultinomialNB_report = classification_report(y_test, predicted, zero_division=0)\n",
    "MultinomialNB_report_summary = MultinomialNB_report[:50] + MultinomialNB_report[-163:]\n",
    "print(\"MultinomialNB_report_summary\",MultinomialNB_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time1 = (end - start) /60\n",
    "print(\"소요시간1:\", int(need_time1),\"분\")\n",
    "\n",
    "## 3-2) Complement Naive Bayes Classifier(CNB)\n",
    "# 학습\n",
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "ComplementNB_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"ComplementNB 정확도:\", ComplementNB_accuracy)\n",
    "ComplementNB_report = classification_report(y_test, predicted, zero_division=0)\n",
    "ComplementNB_report_summary = ComplementNB_report[:50] + ComplementNB_report[-163:]  \n",
    "print(\"ComplementNB_report_summary\",ComplementNB_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time2 = (end - start) /60\n",
    "print(\"소요시간2:\", int(need_time2),\"분\")\n",
    "\n",
    "## 3-3) 로지스틱 회귀(Logistic Regression)\n",
    "# 학습: 10분 정도 소요됩니다.\n",
    "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
    "lr.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "LogisticRegression_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"LogisticRegression 정확도:\", LogisticRegression_accuracy)\n",
    "LogisticRegression_report = classification_report(y_test, predicted, zero_division=0)\n",
    "LogisticRegression_report_summary = LogisticRegression_report[:50] + LogisticRegression_report[-163:]  \n",
    "print(\"LogisticRegression_report_summary\",LogisticRegression_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time3 = (end - start) /60\n",
    "print(\"소요시간3:\", int(need_time3),\"분\")\n",
    "\n",
    "## 3-4) 선형 서포트 벡터 머신(Linear Support Vector Machine)\n",
    "# 학습: \n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "LinearSVC_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Linear Support Vector Machine 정확도:\", LinearSVC_accuracy)\n",
    "LinearSVC_report = classification_report(y_test, predicted, zero_division=0)\n",
    "LinearSVC_report_summary = LinearSVC_report[:50] + LinearSVC_report[-163:]\n",
    "print(\"LinearSVC_report_summary\",LinearSVC_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time4 = (end - start) /60\n",
    "print(\"소요시간4:\", int(need_time4),\"분\")\n",
    "\n",
    "## 3-5) 결정 트리(Decision Tree)\n",
    "# 학습: \n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "DecisionTreeClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Decision Tree 정확도:\", DecisionTreeClassifier_accuracy)\n",
    "DecisionTree_report = classification_report(y_test, predicted, zero_division=0)\n",
    "DecisionTree_report_summary = DecisionTree_report[:50] + DecisionTree_report[-163:]  \n",
    "print(\"DecisionTree_report_summary\",DecisionTree_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time5 = (end - start) /60\n",
    "print(\"소요시간5:\", int(need_time5),\"분\")\n",
    "\n",
    "## 3-6) 랜덤 포레스트(Random Forest)\n",
    "# 학습: \n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "RandomForestClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Random Forest 정확도:\", RandomForestClassifier_accuracy)\n",
    "RandomForest_report = classification_report(y_test, predicted, zero_division=0)\n",
    "RandomForest_report_summary = RandomForest_report[:50] + RandomForest_report[-163:]  \n",
    "print(\"RandomForest_report_summary\",RandomForest_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time6 = (end - start) /60\n",
    "print(\"소요시간6:\", int(need_time6),\"분\")\n",
    "\n",
    "## 3-7) 그래디언트 부스팅 트리(GradientBoostingClassifier)\n",
    "# 학습: 15분 정도 소요\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "GradientBoostingClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"GradientBoostingClassifier 정확도:\", GradientBoostingClassifier_accuracy)\n",
    "GradientBoosting_report = classification_report(y_test, predicted, zero_division=0)\n",
    "GradientBoosting_report_summary = GradientBoosting_report[:50] + GradientBoosting_report[-163:]  \n",
    "print(\"GradientBoosting_summary\",GradientBoosting_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time7 = (end - start) /60\n",
    "print(\"소요시간7:\", int(need_time7),\"분\")\n",
    "\n",
    "## 3-8) 보팅(Voting)\n",
    "# 학습:  20분 이상 소요\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, max_iter=3000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft')\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "VotingClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Voting 정확도:\", VotingClassifier_accuracy)\n",
    "Voting_report = classification_report(y_test, predicted, zero_division=0)\n",
    "Voting_report_summary = Voting_report[:50] + Voting_report[-163:]  \n",
    "print(\"Voting_report_summary\",Voting_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "# 소요시간\n",
    "end = time.time()\n",
    "need_time8 = (end - start) /60\n",
    "print(\"소요시간8:\", int(need_time8),\"분\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73ba52bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ComplementNB 정확도: 0.7671415850400712\n",
      "ComplementNB_report_summary_수정분               precision    recall  f1-score   supp\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.61      0.42      0.46      2246\n",
      "weighted avg       0.75      0.77      0.74      2246\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## [정정 ] classification 오류있는 모델1개 만 다시 실행\n",
    "## 3-2) Complement Naive Bayes Classifier(CNB)\n",
    "# 학습\n",
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "ComplementNB_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"ComplementNB 정확도:\", ComplementNB_accuracy)\n",
    "ComplementNB_report = classification_report(y_test, predicted, zero_division=0)\n",
    "ComplementNB_report_summary = ComplementNB_report[:50] + ComplementNB_report[-163:]  \n",
    "print(\"ComplementNB_report_summary_수정분\",ComplementNB_report_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbed8f",
   "metadata": {},
   "source": [
    "#### 1-3) 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a722546a",
   "metadata": {},
   "source": [
    "**성능 평가**   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.7671415850400712/weighted avg f1 0.74/   \n",
    "LogisticRegression 정확도: 0.8156723063223509/ 0.81/   \n",
    "Linear Support Vector Machine 정확도: 0.7876224398931434/0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.7702582368655387/0.76/       \n",
    "Voting 정확도: 0.8192341941228851/0.82/   \n",
    ">\n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.8156723063223509// weighted avg f1 0.81              \n",
    "> **Voting** 정확도: 0.8192341941228851// weighted avg f1  0.82   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df0843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9345a97e",
   "metadata": {},
   "source": [
    "## (2) num_word 개수: 5,000 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05195c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words= 5000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e23fb3f",
   "metadata": {},
   "source": [
    "#### 2-1) 데이터 벡터화의 전과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d392957a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "(8982,)\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
      "클래스의 수 : 46\n",
      "훈련용 뉴스의 최대 길이 :2376\n",
      "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZuUlEQVR4nO3df7RldXnf8ffHEdBGGoZAWMgPB3WSqI0SvCpZoSlqBcS0aGsU24QRiUQLEVu1GaIVNGUFmqipJiEOgThaI2VFDVOh4kggxvqDGXAEBkIYBcpMEEZRfmhEgad/7O+tx8u9s8/cmXPvufe+X2vtdfZ59o/z7MO587D3/u7vN1WFJEk78rj5TkCSNP4sFpKkXhYLSVIvi4UkqZfFQpLU6/HzncAo7LfffrVixYr5TkOSFpRrr732m1W1/3TLFmWxWLFiBRs3bpzvNCRpQUlyx0zLRnYZKskTklyT5KtJNid5V4sfluTLSbYk+Z9J9mzxvdr7LW35ioF9ndnityQ5dlQ5S5KmN8p7Fg8BL6qq5wCHA8clORI4D3hfVT0d+DZwSlv/FODbLf6+th5JngmcCDwLOA74kyTLRpi3JGmKkRWL6jzY3u7RpgJeBPxli68FXt7mT2jvactfnCQtfnFVPVRVtwFbgOePKm9J0mONtDVUkmVJNgH3AOuBrwHfqaqH2ypbgYPa/EHAnQBt+X3ATw3Gp9lm8LNOTbIxycbt27eP4GgkaekaabGoqkeq6nDgYLqzgZ8b4WetqaqJqprYf/9pb+ZLkmZpTp6zqKrvAFcBvwjsk2SyFdbBwLY2vw04BKAt/0ngW4PxabaRJM2BUbaG2j/JPm3+icBLgJvpisYr22qrgEvb/Lr2nrb8r6vrEncdcGJrLXUYsBK4ZlR5S5Iea5TPWRwIrG0tlx4HXFJVn0pyE3Bxkv8KfAW4sK1/IfCRJFuAe+laQFFVm5NcAtwEPAycVlWPjDBvSdIUWYzjWUxMTJQP5UnSzklybVVNTLdsUT7BPSorVl82bfz2c182x5lI0tyyI0FJUi+LhSSpl8VCktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqReFgtJUi+LhSSpl8VCktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqReFgtJUi+LhSSpl8VCktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqReFgtJUq+RFYskhyS5KslNSTYnOaPFz06yLcmmNh0/sM2ZSbYkuSXJsQPx41psS5LVo8pZkjS9x49w3w8Db6mq65LsDVybZH1b9r6q+oPBlZM8EzgReBbwZOCzSX6mLf5j4CXAVmBDknVVddMIc5ckDRhZsaiqu4C72vwDSW4GDtrBJicAF1fVQ8BtSbYAz2/LtlTV1wGSXNzWtVhI0hyZk3sWSVYAvwB8uYVOT3J9kouSLG+xg4A7Bzbb2mIzxad+xqlJNibZuH379t19CJK0pI28WCR5EvBx4M1VdT9wPvA04HC6M4/37I7Pqao1VTVRVRP777//7tilJKkZ5T0LkuxBVyg+WlWfAKiquweWXwB8qr3dBhwysPnBLcYO4pKkOTDK1lABLgRurqr3DsQPHFjtFcCNbX4dcGKSvZIcBqwErgE2ACuTHJZkT7qb4OtGlbck6bFGeWbxS8CvAzck2dRivwO8JsnhQAG3A78JUFWbk1xCd+P6YeC0qnoEIMnpwBXAMuCiqto8wrwlSVOMsjXU54FMs+jyHWxzDnDONPHLd7SdJGm0fIJbktTLYiFJ6mWxkCT1slhIknpZLCRJvSwWkqReFgtJUi+LhSSpl8VCktRrpB0JLlQrVl823ylI0ljxzEKS1MtiIUnqZbGQJPWyWEiSelksJEm9LBaSpF4WC0lSr95ikeRXk+zd5t+R5BNJjhh9apKkcTHMmcV/qaoHkhwF/EvgQuD80aYlSRonwxSLR9rry4A1VXUZsOfoUpIkjZthisW2JB8EXg1cnmSvIbeTJC0Sw/yj/yrgCuDYqvoOsC/wtlEmJUkaL73Foqq+B9wDHNVCDwO3jjIpSdJ4GaY11FnAbwNnttAewP8YZVKSpPEyzGWoVwD/GvguQFX9A7D3KJOSJI2XYYrFD6qqgAJI8hOjTUmSNG6GKRaXtNZQ+yR5PfBZ4ILRpiVJGifD3OD+A+AvgY8DPwu8s6o+0LddkkOSXJXkpiSbk5zR4vsmWZ/k1va6vMWT5P1JtiS5fvAp8SSr2vq3Jlk124OVJM3OUMOqVtV6YP1O7vth4C1VdV3rLuTaJOuB1wJXVtW5SVYDq+luoL8UWNmmF9A9Jf6CJPsCZwETdJfCrk2yrqq+vZP5SJJmacYziyQPJLl/mumBJPf37biq7qqq69r8A8DNwEHACcDattpa4OVt/gTgw9X5Et1lrwOBY4H1VXVvKxDrgeNmd7iSpNmY8cyiqnZbi6ckK4BfAL4MHFBVd7VF3wAOaPMHAXcObLa1xWaKT/2MU4FTAQ499NDdlbokiSEvQ7X7B0fRXQb6fFV9ZdgPSPIkuvsdb66q+5P8/2VVVUlq51KeXlWtAdYATExM7JZ9SpI6wzyU9066y0U/BewHfCjJO4bZeZI96ArFR6vqEy18d7u8RHu9p8W3AYcMbH5wi80UlyTNkWGazv574HlVdVZVnQUcCfx630bpTiEuBG6uqvcOLFoHTLZoWgVcOhA/qbWKOhK4r12uugI4Jsny1nLqmBaTJM2RYS5D/QPwBOD77f1eDPd/9r9EV1RuSLKpxX4HOJfu2Y1TgDvoOioEuBw4HtgCfA84GaCq7k3yu8CGtt67q+reIT5fkrSbDFMs7gM2t2avBbwEuCbJ+wGq6k3TbVRVnwcy3TLgxdOsX8BpM+zrIuCiIXKVJI3AMMXik22adPVoUpEkjaveYlFVa/vWkSQtbsO0hvqVJF9Jcu/OPJQnSVo8hrkM9YfAvwFuaPcVJElLzDBNZ+8EbrRQSNLSNcyZxX8GLk/yN8BDk8Epz05IkhaxYYrFOcCDdM9a7DnadCRJ42iYYvHkqvpnI89EkjS2hrlncXmSY0aeiSRpbA1TLN4IfDrJP9p0VpKWpmEeyttt41pIkhamYcezWE433OkTJmNV9blRJSVJGi+9xSLJbwBn0I0jsYmui/IvAi8aaWaSpLExzD2LM4DnAXdU1Qvphkf9ziiTkiSNl2GKxfer6vsASfaqqr8Dfna0aUmSxskw9yy2JtkH+CtgfZJv0w1aJElaIoZpDfWKNnt2kquAnwQ+PdKsJEljZZguyp+WZK/Jt8AK4J+MMilJ0ngZ5p7Fx4FHkjwdWAMcAvzFSLOSJI2VYYrFo1X1MPAK4ANV9TbgwNGmJUkaJ8MUix8meQ2wCvhUi+0xupQkSeNmmGJxMvCLwDlVdVuSw4CPjDYtSdI4GaY11E3Amwbe3wacN8qkJEnjZZgzC0nSEmexkCT1mrFYJPlIez1j7tKRJI2jHZ1ZPDfJk4HXJVmeZN/BqW/HSS5Kck+SGwdiZyfZlmRTm44fWHZmki1Jbkly7ED8uBbbkmT1bA9UkjR7O7rB/afAlcBTgWvpnt6eVC2+Ix8C/gj48JT4+6rqDwYDSZ4JnAg8C3gy8NkkP9MW/zHwEmArsCHJunbTXZI0R2Y8s6iq91fVM4CLquqpVXXYwNRXKCYHR7p3yDxOAC6uqodaa6stwPPbtKWqvl5VPwAubutKkuZQ7w3uqnpjkuckOb1Nz97Fzzw9yfXtMtXyFjsIuHNgna0tNlP8MZKcmmRjko3bt2/fxRQlSYOG6UjwTcBHgZ9u00eT/NYsP+984GnA4cBdwHtmuZ/HqKo1VTVRVRP777//7tqtJInhxrP4DeAFVfVdgCTn0Q2r+oGd/bCquntyPskF/Kj7kG10HRROOrjF2EFckjRHhnnOIsAjA+8f4cdvdg8tyWAHhK8AJltKrQNOTLJX605kJXANsAFYmeSwJHvS3QRfN5vPliTN3jBnFn8OfDnJJ9v7lwMX9m2U5GPA0cB+SbYCZwFHJzmcrjXV7cBvAlTV5iSXADcBDwOnVdUjbT+nA1cAy+hutm8e8tgkSbvJMH1DvTfJ1cBRLXRyVX1liO1eM014xiJTVecA50wTvxy4vO/zJEmjM8yZBVV1HXDdiHORJI0p+4aSJPWyWEiSeu2wWCRZluSquUpGkjSedlgsWoukR5P85BzlI0kaQ8Pc4H4QuCHJeuC7k8GqetPMm0iSFpNhisUn2iRJWqKGec5ibZInAodW1S1zkJMkacwM05HgvwI2AZ9u7w9PYpcbkrSEDNN09my6cSW+A1BVm+gf+EiStIgMUyx+WFX3TYk9OopkJEnjaZgb3JuT/DtgWZKVwJuAL4w2LUnSOBnmzOK36MbGfgj4GHA/8OYR5iRJGjPDtIb6HvD2NuhRVdUDo09LkjROhmkN9bwkNwDX0z2c99Ukzx19apKkcTHMPYsLgf9QVX8LkOQougGRnj3KxCRJ42OYexaPTBYKgKr6PN1odpKkJWLGM4skR7TZv0nyQbqb2wW8Grh69KlJksbFji5DvWfK+7MG5msEuUiSxtSMxaKqXjiXiUiSxlfvDe4k+wAnASsG17eLcklaOoZpDXU58CXgBuzmQ5KWpGGKxROq6j+NPBNJ0tgaplh8JMnrgU/RdfkBQFXdO7KsFpgVqy+bNn77uS+b40wkaTSGKRY/AH4feDs/agVV2E25JC0ZwxSLtwBPr6pvjjoZSdJ4GuYJ7i3A90adiCRpfA1TLL4LbErywSTvn5z6NkpyUZJ7ktw4ENs3yfokt7bX5S2ett8tSa4feHqcJKva+rcmWTWbg5Qk7ZphisVfAefQDXh07cDU50PAcVNiq4Erq2olcGV7D/BSYGWbTgXOh6640D05/gK6oV3PmiwwkqS5M8x4Fmtns+Oq+lySFVPCJwBHt/m1dH1M/XaLf7iqCvhSkn2SHNjWXT/Z8irJeroC9LHZ5CRJmp1hnuC+jWn6gqqq2bSGOqCq7mrz3wAOaPMHAXcOrLe1xWaKT5fnqXRnJRx66KGzSE2SNJNhWkNNDMw/AfhVYN9d/eCqqiS7rUPCqloDrAGYmJiwo0NJ2o1671lU1bcGpm1V9YfAbJ82u7tdXqK93tPi24BDBtY7uMVmikuS5tAww6oeMTBNJHkDw52RTGcdMNmiaRVw6UD8pNYq6kjgvna56grgmCTL243tY1pMkjSHhvlHf3Bci4eB24FX9W2U5GN0N6j3S7KVrlXTucAlSU4B7hjYz+XA8fzomY6ToetSJMnvAhvaeu+2mxFJmnvDtIaa1bgWVfWaGRa9eJp1Czhthv1cBFw0mxwkSbvHMK2h9gL+LY8dz+Ldo0tLkjROhrkMdSlwH92DeA/1rCtJWoSGKRYHV9XUJ7ElSUvIMN19fCHJz488E0nS2BrmzOIo4LXtSe6HgNDdk372SDOTJI2NYYrFS0eehSRprA3TdPaOuUhkMXK4VUmLxTD3LCRJS5zFQpLUy2IhSeplsZAk9bJYSJJ6WSwkSb0sFpKkXhYLSVIvi4UkqZfFQpLUy2IhSeplsZAk9bJYSJJ6WSwkSb0sFpKkXhYLSVIvi4UkqZfFQpLUy2IhSeo1L8Uiye1JbkiyKcnGFts3yfokt7bX5S2eJO9PsiXJ9UmOmI+cJWkpm88zixdW1eFVNdHerwaurKqVwJXtPcBLgZVtOhU4f84zlaQlbpwuQ50ArG3za4GXD8Q/XJ0vAfskOXAe8pOkJWu+ikUBn0lybZJTW+yAqrqrzX8DOKDNHwTcObDt1hb7MUlOTbIxycbt27ePKm9JWpIeP0+fe1RVbUvy08D6JH83uLCqKkntzA6rag2wBmBiYmKntp1rK1ZfNm389nNfNseZSNJw5uXMoqq2tdd7gE8Czwfunry81F7vaatvAw4Z2PzgFpMkzZE5LxZJfiLJ3pPzwDHAjcA6YFVbbRVwaZtfB5zUWkUdCdw3cLlKkjQH5uMy1AHAJ5NMfv5fVNWnk2wALklyCnAH8Kq2/uXA8cAW4HvAyXOfsiQtbXNeLKrq68Bzpol/C3jxNPECTpuD1CRJMxinprOSpDFlsZAk9bJYSJJ6WSwkSb0sFpKkXhYLSVKv+eruQ9OwGxBJ48ozC0lSL4uFJKmXxUKS1MtiIUnqZbGQJPWyNdQCYCspSfPNMwtJUi+LhSSpl8VCktTLYiFJ6mWxkCT1sjXUAmYrKUlzxTMLSVIvi4UkqZeXoZaQmS5bgZeuJO2YxWIR2lFRkKTZ8DKUJKmXZxYCbFklaccsFpoVi4u0tFgstEO76/6HxUVa2BZMsUhyHPDfgWXAn1XVufOckqbhzXVpcVoQxSLJMuCPgZcAW4ENSdZV1U3zm5l21c4WF89EpPmxIIoF8HxgS1V9HSDJxcAJgMViibG4SPNjoRSLg4A7B95vBV4wuEKSU4FT29sHk9wyi8/ZD/jmrDJcHBbd8ee8nd5k0X0HO2mpHz8s7e/gKTMtWCjFoldVrQHW7Mo+kmysqondlNKCs9SPH/wOlvrxg9/BTBbKQ3nbgEMG3h/cYpKkObBQisUGYGWSw5LsCZwIrJvnnCRpyVgQl6Gq6uEkpwNX0DWdvaiqNo/go3bpMtYisNSPH/wOlvrxg9/BtFJV852DJGnMLZTLUJKkeWSxkCT1sljQdSWS5JYkW5Ksnu98RinJ7UluSLIpycYW2zfJ+iS3ttflLZ4k72/fy/VJjpjf7HdekouS3JPkxoHYTh9vklVt/VuTrJqPY5mtGb6Ds5Nsa7+DTUmOH1h2ZvsObkly7EB8Qf6dJDkkyVVJbkqyOckZLb6kfge7rKqW9ER3w/xrwFOBPYGvAs+c77xGeLy3A/tNif03YHWbXw2c1+aPB/43EOBI4Mvznf8sjveXgSOAG2d7vMC+wNfb6/I2v3y+j20Xv4OzgbdOs+4z29/AXsBh7W9j2UL+OwEOBI5o83sDf9+Oc0n9DnZ18sxioCuRqvoBMNmVyFJyArC2za8FXj4Q/3B1vgTsk+TAechv1qrqc8C9U8I7e7zHAuur6t6q+jawHjhu5MnvJjN8BzM5Abi4qh6qqtuALXR/Iwv276Sq7qqq69r8A8DNdL1CLKnfwa6yWEzflchB85TLXCjgM0mubV2kABxQVXe1+W8AB7T5xfrd7OzxLtbv4fR2meWiyUswLPLvIMkK4BeAL+PvYKdYLJaeo6rqCOClwGlJfnlwYXXn20umPfVSO94B5wNPAw4H7gLeM6/ZzIEkTwI+Dry5qu4fXLaEfwdDs1gssa5Eqmpbe70H+CTd5YW7Jy8vtdd72uqL9bvZ2eNddN9DVd1dVY9U1aPABXS/A1ik30GSPegKxUer6hMtvOR/BzvDYrGEuhJJ8hNJ9p6cB44BbqQ73smWHauAS9v8OuCk1jrkSOC+gdP2hWxnj/cK4Jgky9vlmmNabMGacu/pFXS/A+i+gxOT7JXkMGAlcA0L+O8kSYALgZur6r0Di5b872CnzPcd9nGY6Fo//D1da4+3z3c+IzzOp9K1YvkqsHnyWIGfAq4EbgU+C+zb4qEbdOprwA3AxHwfwyyO+WN0l1l+SHeN+ZTZHC/wOrqbvVuAk+f7uHbDd/CRdozX0/3jeODA+m9v38EtwEsH4gvy7wQ4iu4S0/XApjYdv9R+B7s62d2HJKmXl6EkSb0sFpKkXhYLSVIvi4UkqZfFQpLUy2KhBS/JgyPY5+FTemI9O8lbd2F/v5rk5iRX7Z4MZ53H7Un2m88ctDBZLKTpHU7XFn93OQV4fVW9cDfuU5ozFgstKknelmRD6yDvXS22ov1f/QVtPIPPJHliW/a8tu6mJL+f5Mb2hPK7gVe3+Kvb7p+Z5OokX0/yphk+/zXpxgu5Mcl5LfZOugfDLkzy+1PWPzDJ59rn3Jjkn7f4+Uk2tnzfNbD+7Ul+r62/MckRSa5I8rUkb2jrHN32eVm68Sf+NMlj/taT/FqSa9q+PphkWZs+1HK5Icl/3MX/JFos5vupQCenXZ2AB9vrMcAauidwHwd8im4shxXAw8Dhbb1LgF9r8zcCv9jmz6WN+QC8Fvijgc84G/gC3TgP+wHfAvaYkseTgf8L7A88Hvhr4OVt2dVM8wQ88BZ+9CT9MmDvNr/vQOxq4Nnt/e3AG9v8++ieSt67febdLX408H26J/aX0XWl/cqB7fcDngH8r8ljAP4EOAl4Ll033JP57TPf/32dxmPyzEKLyTFt+gpwHfBzdH0bAdxWVZva/LXAiiT70P3j/MUW/4ue/V9W3TgP36TrdO6AKcufB1xdVdur6mHgo3TFakc2ACcnORv4+erGWwB4VZLr2rE8i26wnkmTfTLdQDcwzwNVtR14qB0TwDXVjT3xCF13H0dN+dwX0xWGDUk2tfdPpRvQ56lJPpDkOOB+JLr/+5EWiwC/V1Uf/LFgN4bBQwOhR4AnzmL/U/exy38/VfW51k38y4APJXkv8LfAW4HnVdW3k3wIeMI0eTw6JadHB3Ka2o/P1PcB1lbVmVNzSvIcuoF+3gC8iq4/JC1xnlloMbkCeF0bt4AkByX56ZlWrqrvAA8keUELnTiw+AG6yzs74xrgXyTZL8ky4DXA3+xogyRPobt8dAHwZ3TDn/5T4LvAfUkOoBt7ZGc9v/UQ+zjg1cDnpyy/Enjl5PeTbjzqp7SWUo+rqo8D72j5SJ5ZaPGoqs8keQbwxa5Xah4Efo3uLGAmpwAXJHmU7h/2+1r8KmB1u0Tze0N+/l1JVrdtQ3fZ6tKezY4G3pbkhy3fk6rqtiRfAf6ObmS2/zPM50+xAfgj4Oktn09OyfWmJO+gGzXxcXQ90p4G/CPw5wM3xB9z5qGlyV5ntaQleVJVPdjmV9N11X3GPKe1S5IcDby1qn5lnlPRIuKZhZa6lyU5k+5v4Q66VlCSpvDMQpLUyxvckqReFgtJUi+LhSSpl8VCktTLYiFJ6vX/AHunIAk82uh/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n",
      "=3\n",
      "30979\n",
      "=3\n",
      "30979\n",
      "=3\n",
      "=3\n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "8982\n",
      "2246\n",
      "(8982, 4867)\n",
      "(8982, 4867)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "print(x_train.shape)\n",
    "#print(dir(reuters))\n",
    "#print(len(reuters.get_word_index()))\n",
    "\n",
    "print(x_train[0])\n",
    "print(x_test[0])\n",
    "\n",
    "num_classes = max(y_train) + 1\n",
    "print('클래스의 수 : {}'.format(num_classes))\n",
    "\n",
    "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
    "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
    "\n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(11,5)\n",
    "sns.countplot(x=y_train)\n",
    "plt.show()\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print('=3')\n",
    "print(len(word_index))\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print('=3')\n",
    "print(len(word_index))\n",
    "\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "print('=3')\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "print('=3')\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "\n",
    "## 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "# train data\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))\n",
    "# test data\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))\n",
    "\n",
    "# 변환여부 확인\n",
    "x_train[:5]\n",
    "x_test[:5]\n",
    "\n",
    "## DTM을 생성하고, DTM의 크기를 확인\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)\n",
    "\n",
    "## TF-IDF Matrix 생성하고,크기를 확인\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905fda0b",
   "metadata": {},
   "source": [
    "#### 2-2) 모델별 학습및 성능테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd1297f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB 정확도: 0.6731967943009796\n",
      "MultinomialNB_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.67      2246\n",
      "   macro avg       0.16      0.12      0.11      2246\n",
      "weighted avg       0.60      0.67      0.60      2246\n",
      "\n",
      "소요시간1: 0 분\n",
      "ComplementNB 정확도: 0.7707034728406055\n",
      "ComplementNB_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.63      0.44      0.48      2246\n",
      "weighted avg       0.76      0.77      0.75      2246\n",
      "\n",
      "소요시간2: 0 분\n",
      "LogisticRegression 정확도: 0.8036509349955476\n",
      "LogisticRegression_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.80      2246\n",
      "   macro avg       0.76      0.61      0.65      2246\n",
      "weighted avg       0.80      0.80      0.80      2246\n",
      "\n",
      "소요시간3: 7 분\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Support Vector Machine 정확도: 0.7733748886910062\n",
      "LinearSVC_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.70      0.60      0.62      2246\n",
      "weighted avg       0.77      0.77      0.77      2246\n",
      "\n",
      "소요시간4: 9 분\n",
      "Decision Tree 정확도: 0.6179875333926982\n",
      "DecisionTree_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.24      0.17      0.18      2246\n",
      "weighted avg       0.61      0.62      0.57      2246\n",
      "\n",
      "소요시간5: 9 분\n",
      "Random Forest 정확도: 0.701246660730187\n",
      "RandomForest_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.70      2246\n",
      "   macro avg       0.54      0.31      0.36      2246\n",
      "weighted avg       0.69      0.70      0.68      2246\n",
      "\n",
      "소요시간6: 9 분\n",
      "GradientBoostingClassifier 정확도: 0.767586821015138\n",
      "GradientBoosting_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.60      0.59      0.58      2246\n",
      "weighted avg       0.77      0.77      0.77      2246\n",
      "\n",
      "소요시간7: 23 분\n",
      "Voting 정확도: 0.8103294746215495\n",
      "Voting_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.71      0.64      0.65      2246\n",
      "weighted avg       0.81      0.81      0.81      2246\n",
      "\n",
      "소요시간8: 44 분\n"
     ]
    }
   ],
   "source": [
    "import os, time, copy\n",
    "\n",
    "## 혼동 행렬(confusion matrix) 시각화함수 생성\n",
    "def graph_confusion_matrix(model, x_test, y_test):#, classes_name):\n",
    "  df_cm = pd.DataFrame(confusion_matrix(y_test, model.predict(x_test)))#, index=classes_name, columns=classes_name)\n",
    "  fig = plt.figure(figsize=(12,12))\n",
    "  heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "  heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n",
    "  heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "  plt.ylabel('label')\n",
    "  plt.xlabel('predicted value')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "## 3-1) 나이브 베이즈 분류기(Multinomial Naive Bayes Classifier)\n",
    "# 학습\n",
    "model = MultinomialNB()\n",
    "model.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "MultinomialNB_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"MultinomialNB 정확도:\", MultinomialNB_accuracy)\n",
    "MultinomialNB_report = classification_report(y_test, predicted, zero_division=0)\n",
    "MultinomialNB_report_summary = MultinomialNB_report[:50] + MultinomialNB_report[-163:]\n",
    "print(\"MultinomialNB_report_summary\",MultinomialNB_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time1 = (end - start) /60\n",
    "print(\"소요시간1:\", int(need_time1),\"분\")\n",
    "\n",
    "## 3-2) Complement Naive Bayes Classifier(CNB)\n",
    "# 학습\n",
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "ComplementNB_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"ComplementNB 정확도:\", ComplementNB_accuracy)\n",
    "ComplementNB_report = classification_report(y_test, predicted, zero_division=0)\n",
    "ComplementNB_report_summary = ComplementNB_report[:50] + ComplementNB_report[-163:]  \n",
    "print(\"ComplementNB_report_summary\",ComplementNB_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time2 = (end - start) /60\n",
    "print(\"소요시간2:\", int(need_time2),\"분\")\n",
    "\n",
    "## 3-3) 로지스틱 회귀(Logistic Regression)\n",
    "# 학습: 10분 정도 소요됩니다.\n",
    "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
    "lr.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "LogisticRegression_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"LogisticRegression 정확도:\", LogisticRegression_accuracy)\n",
    "LogisticRegression_report = classification_report(y_test, predicted, zero_division=0)\n",
    "LogisticRegression_report_summary = LogisticRegression_report[:50] + LogisticRegression_report[-163:]  \n",
    "print(\"LogisticRegression_report_summary\",LogisticRegression_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time3 = (end - start) /60\n",
    "print(\"소요시간3:\", int(need_time3),\"분\")\n",
    "\n",
    "## 3-4) 선형 서포트 벡터 머신(Linear Support Vector Machine)\n",
    "# 학습: \n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "LinearSVC_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Linear Support Vector Machine 정확도:\", LinearSVC_accuracy)\n",
    "LinearSVC_report = classification_report(y_test, predicted, zero_division=0)\n",
    "LinearSVC_report_summary = LinearSVC_report[:50] + LinearSVC_report[-163:]\n",
    "print(\"LinearSVC_report_summary\",LinearSVC_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time4 = (end - start) /60\n",
    "print(\"소요시간4:\", int(need_time4),\"분\")\n",
    "\n",
    "## 3-5) 결정 트리(Decision Tree)\n",
    "# 학습: \n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "DecisionTreeClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Decision Tree 정확도:\", DecisionTreeClassifier_accuracy)\n",
    "DecisionTree_report = classification_report(y_test, predicted, zero_division=0)\n",
    "DecisionTree_report_summary = DecisionTree_report[:50] + DecisionTree_report[-163:]  \n",
    "print(\"DecisionTree_report_summary\",DecisionTree_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time5 = (end - start) /60\n",
    "print(\"소요시간5:\", int(need_time5),\"분\")\n",
    "\n",
    "## 3-6) 랜덤 포레스트(Random Forest)\n",
    "# 학습: \n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "RandomForestClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Random Forest 정확도:\", RandomForestClassifier_accuracy)\n",
    "RandomForest_report = classification_report(y_test, predicted, zero_division=0)\n",
    "RandomForest_report_summary = RandomForest_report[:50] + RandomForest_report[-163:]  \n",
    "print(\"RandomForest_report_summary\",RandomForest_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time6 = (end - start) /60\n",
    "print(\"소요시간6:\", int(need_time6),\"분\")\n",
    "\n",
    "## 3-7) 그래디언트 부스팅 트리(GradientBoostingClassifier)\n",
    "# 학습: 15분 정도 소요\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "GradientBoostingClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"GradientBoostingClassifier 정확도:\", GradientBoostingClassifier_accuracy)\n",
    "GradientBoosting_report = classification_report(y_test, predicted, zero_division=0)\n",
    "GradientBoosting_report_summary = GradientBoosting_report[:50] + GradientBoosting_report[-163:]  \n",
    "print(\"GradientBoosting_summary\",GradientBoosting_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time7 = (end - start) /60\n",
    "print(\"소요시간7:\", int(need_time7),\"분\")\n",
    "\n",
    "## 3-8) 보팅(Voting)\n",
    "# 학습:  20분 이상 소요\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, max_iter=3000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft')\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "VotingClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Voting 정확도:\", VotingClassifier_accuracy)\n",
    "Voting_report = classification_report(y_test, predicted, zero_division=0)\n",
    "Voting_report_summary = Voting_report[:50] + Voting_report[-163:]  \n",
    "print(\"Voting_report_summary\",Voting_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "# 소요시간\n",
    "end = time.time()\n",
    "need_time8 = (end - start) /60\n",
    "print(\"소요시간8:\", int(need_time8),\"분\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fc7a0c",
   "metadata": {},
   "source": [
    "#### 2-3) 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f98d6",
   "metadata": {},
   "source": [
    "**성능 평가**   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.75/   \n",
    "LogisticRegression 정확도: 0.80/ 0.80/   \n",
    "Linear Support Vector Machine 정확도: 0.77/0.77/   \n",
    "GradientBoostingClassifier 정확도: 0.77/0.77/       \n",
    "Voting 정확도: 0.81/0.81/   \n",
    ">\n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.80// weighted avg f1 0.80             \n",
    "> **Voting** 정확도: 0.81// weighted avg f1  0.81   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617935e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "524aff7c",
   "metadata": {},
   "source": [
    "## (3) num_word 개수: 10000 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03af9038",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words= 10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cabc8e",
   "metadata": {},
   "source": [
    "#### 3-1) 데이터 벡터화의 전과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e085a52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "(8982,)\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
      "클래스의 수 : 46\n",
      "훈련용 뉴스의 최대 길이 :2376\n",
      "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n",
      "=3\n",
      "30979\n",
      "=3\n",
      "30979\n",
      "=3\n",
      "=3\n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "8982\n",
      "2246\n",
      "(8982, 9670)\n",
      "(8982, 9670)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "print(x_train.shape)\n",
    "#print(dir(reuters))\n",
    "#print(len(reuters.get_word_index()))\n",
    "\n",
    "print(x_train[0])\n",
    "print(x_test[0])\n",
    "\n",
    "num_classes = max(y_train) + 1\n",
    "print('클래스의 수 : {}'.format(num_classes))\n",
    "\n",
    "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
    "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
    "\n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(11,5)\n",
    "sns.countplot(x=y_train)\n",
    "plt.show()\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print('=3')\n",
    "print(len(word_index))\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print('=3')\n",
    "print(len(word_index))\n",
    "\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "print('=3')\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "print('=3')\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "\n",
    "## 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "# train data\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))\n",
    "# test data\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))\n",
    "\n",
    "# 변환여부 확인\n",
    "x_train[:5]\n",
    "x_test[:5]\n",
    "\n",
    "## DTM을 생성하고, DTM의 크기를 확인\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)\n",
    "\n",
    "## TF-IDF Matrix 생성하고,크기를 확인\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c5e93",
   "metadata": {},
   "source": [
    "#### 3-2) 모델별 학습및 성능테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c017b9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB 정확도: 0.6567230632235085\n",
      "MultinomialNB_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.66      2246\n",
      "   macro avg       0.17      0.10      0.10      2246\n",
      "weighted avg       0.59      0.66      0.58      2246\n",
      "\n",
      "소요시간1: 0 분\n",
      "ComplementNB 정확도: 0.7707034728406055\n",
      "ComplementNB_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.63      0.44      0.48      2246\n",
      "weighted avg       0.75      0.77      0.75      2246\n",
      "\n",
      "소요시간2: 0 분\n",
      "LogisticRegression 정확도: 0.8107747105966162\n",
      "LogisticRegression_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.78      0.63      0.67      2246\n",
      "weighted avg       0.81      0.81      0.81      2246\n",
      "\n",
      "소요시간3: 10 분\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Support Vector Machine 정확도: 0.7871772039180766\n",
      "LinearSVC_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.79      2246\n",
      "   macro avg       0.73      0.62      0.64      2246\n",
      "weighted avg       0.79      0.79      0.78      2246\n",
      "\n",
      "소요시간4: 11 분\n",
      "Decision Tree 정확도: 0.6202137132680321\n",
      "DecisionTree_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.23      0.18      0.18      2246\n",
      "weighted avg       0.61      0.62      0.58      2246\n",
      "\n",
      "소요시간5: 12 분\n",
      "Random Forest 정확도: 0.674087266251113\n",
      "RandomForest_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.67      2246\n",
      "   macro avg       0.46      0.27      0.31      2246\n",
      "weighted avg       0.66      0.67      0.64      2246\n",
      "\n",
      "소요시간6: 12 분\n",
      "GradientBoostingClassifier 정확도: 0.7662511130899377\n",
      "GradientBoosting_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.63      0.58      0.58      2246\n",
      "weighted avg       0.77      0.77      0.76      2246\n",
      "\n",
      "소요시간7: 26 분\n",
      "Voting 정확도: 0.8165627782724845\n",
      "Voting_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.82      2246\n",
      "   macro avg       0.73      0.65      0.65      2246\n",
      "weighted avg       0.82      0.82      0.81      2246\n",
      "\n",
      "소요시간8: 50 분\n"
     ]
    }
   ],
   "source": [
    "import os, time, copy\n",
    "\n",
    "## 혼동 행렬(confusion matrix) 시각화함수 생성\n",
    "def graph_confusion_matrix(model, x_test, y_test):#, classes_name):\n",
    "  df_cm = pd.DataFrame(confusion_matrix(y_test, model.predict(x_test)))#, index=classes_name, columns=classes_name)\n",
    "  fig = plt.figure(figsize=(12,12))\n",
    "  heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "  heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n",
    "  heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "  plt.ylabel('label')\n",
    "  plt.xlabel('predicted value')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "## 3-1) 나이브 베이즈 분류기(Multinomial Naive Bayes Classifier)\n",
    "# 학습\n",
    "model = MultinomialNB()\n",
    "model.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "MultinomialNB_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"MultinomialNB 정확도:\", MultinomialNB_accuracy)\n",
    "MultinomialNB_report = classification_report(y_test, predicted, zero_division=0)\n",
    "MultinomialNB_report_summary = MultinomialNB_report[:50] + MultinomialNB_report[-163:]\n",
    "print(\"MultinomialNB_report_summary\",MultinomialNB_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time1 = (end - start) /60\n",
    "print(\"소요시간1:\", int(need_time1),\"분\")\n",
    "\n",
    "## 3-2) Complement Naive Bayes Classifier(CNB)\n",
    "# 학습\n",
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "ComplementNB_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"ComplementNB 정확도:\", ComplementNB_accuracy)\n",
    "ComplementNB_report = classification_report(y_test, predicted, zero_division=0)\n",
    "ComplementNB_report_summary = ComplementNB_report[:50] + ComplementNB_report[-163:]  \n",
    "print(\"ComplementNB_report_summary\",ComplementNB_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time2 = (end - start) /60\n",
    "print(\"소요시간2:\", int(need_time2),\"분\")\n",
    "\n",
    "## 3-3) 로지스틱 회귀(Logistic Regression)\n",
    "# 학습: 10분 정도 소요됩니다.\n",
    "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
    "lr.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "LogisticRegression_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"LogisticRegression 정확도:\", LogisticRegression_accuracy)\n",
    "LogisticRegression_report = classification_report(y_test, predicted, zero_division=0)\n",
    "LogisticRegression_report_summary = LogisticRegression_report[:50] + LogisticRegression_report[-163:]  \n",
    "print(\"LogisticRegression_report_summary\",LogisticRegression_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time3 = (end - start) /60\n",
    "print(\"소요시간3:\", int(need_time3),\"분\")\n",
    "\n",
    "## 3-4) 선형 서포트 벡터 머신(Linear Support Vector Machine)\n",
    "# 학습: \n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "LinearSVC_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Linear Support Vector Machine 정확도:\", LinearSVC_accuracy)\n",
    "LinearSVC_report = classification_report(y_test, predicted, zero_division=0)\n",
    "LinearSVC_report_summary = LinearSVC_report[:50] + LinearSVC_report[-163:]\n",
    "print(\"LinearSVC_report_summary\",LinearSVC_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time4 = (end - start) /60\n",
    "print(\"소요시간4:\", int(need_time4),\"분\")\n",
    "\n",
    "## 3-5) 결정 트리(Decision Tree)\n",
    "# 학습: \n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "DecisionTreeClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Decision Tree 정확도:\", DecisionTreeClassifier_accuracy)\n",
    "DecisionTree_report = classification_report(y_test, predicted, zero_division=0)\n",
    "DecisionTree_report_summary = DecisionTree_report[:50] + DecisionTree_report[-163:]  \n",
    "print(\"DecisionTree_report_summary\",DecisionTree_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time5 = (end - start) /60\n",
    "print(\"소요시간5:\", int(need_time5),\"분\")\n",
    "\n",
    "## 3-6) 랜덤 포레스트(Random Forest)\n",
    "# 학습: \n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "RandomForestClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Random Forest 정확도:\", RandomForestClassifier_accuracy)\n",
    "RandomForest_report = classification_report(y_test, predicted, zero_division=0)\n",
    "RandomForest_report_summary = RandomForest_report[:50] + RandomForest_report[-163:]  \n",
    "print(\"RandomForest_report_summary\",RandomForest_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time6 = (end - start) /60\n",
    "print(\"소요시간6:\", int(need_time6),\"분\")\n",
    "\n",
    "## 3-7) 그래디언트 부스팅 트리(GradientBoostingClassifier)\n",
    "# 학습: 15분 정도 소요\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "GradientBoostingClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"GradientBoostingClassifier 정확도:\", GradientBoostingClassifier_accuracy)\n",
    "GradientBoosting_report = classification_report(y_test, predicted, zero_division=0)\n",
    "GradientBoosting_report_summary = GradientBoosting_report[:50] + GradientBoosting_report[-163:]  \n",
    "print(\"GradientBoosting_summary\",GradientBoosting_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time7 = (end - start) /60\n",
    "print(\"소요시간7:\", int(need_time7),\"분\")\n",
    "\n",
    "## 3-8) 보팅(Voting)\n",
    "# 학습:  20분 이상 소요\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, max_iter=3000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft')\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "VotingClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Voting 정확도:\", VotingClassifier_accuracy)\n",
    "Voting_report = classification_report(y_test, predicted, zero_division=0)\n",
    "Voting_report_summary = Voting_report[:50] + Voting_report[-163:]  \n",
    "print(\"Voting_report_summary\",Voting_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "# 소요시간\n",
    "end = time.time()\n",
    "need_time8 = (end - start) /60\n",
    "print(\"소요시간8:\", int(need_time8),\"분\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c51fa4",
   "metadata": {},
   "source": [
    "#### 3-3) 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e29de1",
   "metadata": {},
   "source": [
    "**성능 평가**   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.75/   \n",
    "LogisticRegression 정확도: 0.81 / 0.81/   \n",
    "Linear Support Vector Machine 정확도: 0.79 /0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.77 /0.76/       \n",
    "Voting 정확도: 0.82/0.81/   \n",
    ">\n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.81 // weighted avg f1 0.81              \n",
    "> **Voting** 정확도: 0.82// weighted avg f1  0.81   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901575a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee4273d6",
   "metadata": {},
   "source": [
    "## (4) num_word 개수: 15,000 개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5ab4452",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words= 15000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148260a4",
   "metadata": {},
   "source": [
    "#### 4-1) 데이터 벡터화의 전과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7851e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "(8982,)\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
      "클래스의 수 : 46\n",
      "훈련용 뉴스의 최대 길이 :2376\n",
      "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n",
      "=3\n",
      "30979\n",
      "=3\n",
      "30979\n",
      "=3\n",
      "=3\n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "8982\n",
      "2246\n",
      "(8982, 14227)\n",
      "(8982, 14227)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "print(x_train.shape)\n",
    "#print(dir(reuters))\n",
    "#print(len(reuters.get_word_index()))\n",
    "\n",
    "print(x_train[0])\n",
    "print(x_test[0])\n",
    "\n",
    "num_classes = max(y_train) + 1\n",
    "print('클래스의 수 : {}'.format(num_classes))\n",
    "\n",
    "print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
    "print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
    "\n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(11,5)\n",
    "sns.countplot(x=y_train)\n",
    "plt.show()\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print('=3')\n",
    "print(len(word_index))\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print('=3')\n",
    "print(len(word_index))\n",
    "\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "print('=3')\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "print('=3')\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "\n",
    "## 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "# train data\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))\n",
    "# test data\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))\n",
    "\n",
    "# 변환여부 확인\n",
    "x_train[:5]\n",
    "x_test[:5]\n",
    "\n",
    "## DTM을 생성하고, DTM의 크기를 확인\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "print(x_train_dtm.shape)\n",
    "\n",
    "## TF-IDF Matrix 생성하고,크기를 확인\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "print(tfidfv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b072fe5",
   "metadata": {},
   "source": [
    "#### 4-2) 모델별 학습및 성능테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aae9ed3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB 정확도: 0.6331255565449688\n",
      "MultinomialNB_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.63      2246\n",
      "   macro avg       0.13      0.09      0.09      2246\n",
      "weighted avg       0.55      0.63      0.55      2246\n",
      "\n",
      "소요시간1: 0 분\n",
      "ComplementNB 정확도: 0.7720391807658059\n",
      "ComplementNB_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.61      0.43      0.47      2246\n",
      "weighted avg       0.75      0.77      0.74      2246\n",
      "\n",
      "소요시간2: 0 분\n",
      "LogisticRegression 정확도: 0.8147818343722173\n",
      "LogisticRegression_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.78      0.63      0.67      2246\n",
      "weighted avg       0.82      0.81      0.81      2246\n",
      "\n",
      "소요시간3: 12 분\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/svm/_base.py:1199: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Support Vector Machine 정확도: 0.7889581478183437\n",
      "LinearSVC_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.79      2246\n",
      "   macro avg       0.67      0.61      0.62      2246\n",
      "weighted avg       0.79      0.79      0.78      2246\n",
      "\n",
      "소요시간4: 14 분\n",
      "Decision Tree 정확도: 0.6193232413178985\n",
      "DecisionTree_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.62      2246\n",
      "   macro avg       0.23      0.17      0.18      2246\n",
      "weighted avg       0.61      0.62      0.58      2246\n",
      "\n",
      "소요시간5: 14 분\n",
      "Random Forest 정확도: 0.6714158504007124\n",
      "RandomForest_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.67      2246\n",
      "   macro avg       0.43      0.26      0.30      2246\n",
      "weighted avg       0.65      0.67      0.64      2246\n",
      "\n",
      "소요시간6: 14 분\n",
      "GradientBoostingClassifier 정확도: 0.7707034728406055\n",
      "GradientBoosting_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.77      2246\n",
      "   macro avg       0.60      0.58      0.57      2246\n",
      "weighted avg       0.77      0.77      0.77      2246\n",
      "\n",
      "소요시간7: 29 분\n",
      "Voting 정확도: 0.8143365983971504\n",
      "Voting_report_summary               precision    recall  f1-score   supp\n",
      "    accuracy                           0.81      2246\n",
      "   macro avg       0.72      0.64      0.65      2246\n",
      "weighted avg       0.82      0.81      0.81      2246\n",
      "\n",
      "소요시간8: 55 분\n"
     ]
    }
   ],
   "source": [
    "import os, time, copy\n",
    "\n",
    "## 혼동 행렬(confusion matrix) 시각화함수 생성\n",
    "def graph_confusion_matrix(model, x_test, y_test):#, classes_name):\n",
    "  df_cm = pd.DataFrame(confusion_matrix(y_test, model.predict(x_test)))#, index=classes_name, columns=classes_name)\n",
    "  fig = plt.figure(figsize=(12,12))\n",
    "  heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "  heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n",
    "  heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "  plt.ylabel('label')\n",
    "  plt.xlabel('predicted value')\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "## 3-1) 나이브 베이즈 분류기(Multinomial Naive Bayes Classifier)\n",
    "# 학습\n",
    "model = MultinomialNB()\n",
    "model.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "predicted = model.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "MultinomialNB_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"MultinomialNB 정확도:\", MultinomialNB_accuracy)\n",
    "MultinomialNB_report = classification_report(y_test, predicted, zero_division=0)\n",
    "MultinomialNB_report_summary = MultinomialNB_report[:50] + MultinomialNB_report[-163:]\n",
    "print(\"MultinomialNB_report_summary\",MultinomialNB_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time1 = (end - start) /60\n",
    "print(\"소요시간1:\", int(need_time1),\"분\")\n",
    "\n",
    "## 3-2) Complement Naive Bayes Classifier(CNB)\n",
    "# 학습\n",
    "cb = ComplementNB()\n",
    "cb.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = cb.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "ComplementNB_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"ComplementNB 정확도:\", ComplementNB_accuracy)\n",
    "ComplementNB_report = classification_report(y_test, predicted, zero_division=0)\n",
    "ComplementNB_report_summary = ComplementNB_report[:50] + ComplementNB_report[-163:]  \n",
    "print(\"ComplementNB_report_summary\",ComplementNB_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time2 = (end - start) /60\n",
    "print(\"소요시간2:\", int(need_time2),\"분\")\n",
    "\n",
    "## 3-3) 로지스틱 회귀(Logistic Regression)\n",
    "# 학습: 10분 정도 소요됩니다.\n",
    "lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
    "lr.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = lr.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "LogisticRegression_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"LogisticRegression 정확도:\", LogisticRegression_accuracy)\n",
    "LogisticRegression_report = classification_report(y_test, predicted, zero_division=0)\n",
    "LogisticRegression_report_summary = LogisticRegression_report[:50] + LogisticRegression_report[-163:]  \n",
    "print(\"LogisticRegression_report_summary\",LogisticRegression_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time3 = (end - start) /60\n",
    "print(\"소요시간3:\", int(need_time3),\"분\")\n",
    "\n",
    "## 3-4) 선형 서포트 벡터 머신(Linear Support Vector Machine)\n",
    "# 학습: \n",
    "lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False)\n",
    "lsvc.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = lsvc.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "LinearSVC_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Linear Support Vector Machine 정확도:\", LinearSVC_accuracy)\n",
    "LinearSVC_report = classification_report(y_test, predicted, zero_division=0)\n",
    "LinearSVC_report_summary = LinearSVC_report[:50] + LinearSVC_report[-163:]\n",
    "print(\"LinearSVC_report_summary\",LinearSVC_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time4 = (end - start) /60\n",
    "print(\"소요시간4:\", int(need_time4),\"분\")\n",
    "\n",
    "## 3-5) 결정 트리(Decision Tree)\n",
    "# 학습: \n",
    "tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "tree.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = tree.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "DecisionTreeClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Decision Tree 정확도:\", DecisionTreeClassifier_accuracy)\n",
    "DecisionTree_report = classification_report(y_test, predicted, zero_division=0)\n",
    "DecisionTree_report_summary = DecisionTree_report[:50] + DecisionTree_report[-163:]  \n",
    "print(\"DecisionTree_report_summary\",DecisionTree_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time5 = (end - start) /60\n",
    "print(\"소요시간5:\", int(need_time5),\"분\")\n",
    "\n",
    "## 3-6) 랜덤 포레스트(Random Forest)\n",
    "# 학습: \n",
    "forest = RandomForestClassifier(n_estimators=5, random_state=0)\n",
    "forest.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = forest.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "RandomForestClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Random Forest 정확도:\", RandomForestClassifier_accuracy)\n",
    "RandomForest_report = classification_report(y_test, predicted, zero_division=0)\n",
    "RandomForest_report_summary = RandomForest_report[:50] + RandomForest_report[-163:]  \n",
    "print(\"RandomForest_report_summary\",RandomForest_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time6 = (end - start) /60\n",
    "print(\"소요시간6:\", int(need_time6),\"분\")\n",
    "\n",
    "## 3-7) 그래디언트 부스팅 트리(GradientBoostingClassifier)\n",
    "# 학습: 15분 정도 소요\n",
    "grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "grbt.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = grbt.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "GradientBoostingClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"GradientBoostingClassifier 정확도:\", GradientBoostingClassifier_accuracy)\n",
    "GradientBoosting_report = classification_report(y_test, predicted, zero_division=0)\n",
    "GradientBoosting_report_summary = GradientBoosting_report[:50] + GradientBoosting_report[-163:]  \n",
    "print(\"GradientBoosting_summary\",GradientBoosting_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "end = time.time()\n",
    "need_time7 = (end - start) /60\n",
    "print(\"소요시간7:\", int(need_time7),\"분\")\n",
    "\n",
    "## 3-8) 보팅(Voting)\n",
    "# 학습:  20분 이상 소요\n",
    "voting_classifier = VotingClassifier(estimators=[\n",
    "         ('lr', LogisticRegression(C=10000, max_iter=3000, penalty='l2')),\n",
    "        ('cb', ComplementNB()),\n",
    "        ('grbt', GradientBoostingClassifier(random_state=0))\n",
    "], voting='soft')\n",
    "voting_classifier.fit(tfidfv, y_train)\n",
    "# 테스트\n",
    "predicted = voting_classifier.predict(tfidfv_test) #테스트 데이터에 대한 예측\n",
    "VotingClassifier_accuracy = accuracy_score(y_test, predicted) #예측값과 실제값 비교\n",
    "print(\"Voting 정확도:\", VotingClassifier_accuracy)\n",
    "Voting_report = classification_report(y_test, predicted, zero_division=0)\n",
    "Voting_report_summary = Voting_report[:50] + Voting_report[-163:]  \n",
    "print(\"Voting_report_summary\",Voting_report_summary)\n",
    "# 혼돈행렬시각화\n",
    "#graph_confusion_matrix(model, tfidfv_test, y_test)\n",
    "\n",
    "# 소요시간\n",
    "end = time.time()\n",
    "need_time8 = (end - start) /60\n",
    "print(\"소요시간8:\", int(need_time8),\"분\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d121f7",
   "metadata": {},
   "source": [
    "#### 4-3) 성능 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f99678",
   "metadata": {},
   "source": [
    "**성능 평가**   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.74/   \n",
    "LogisticRegression 정확도: 0.81/ 0.81/   \n",
    "Linear Support Vector Machine 정확도: 0.79 /0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.77 /0.77/       \n",
    "Voting 정확도: 0.8192341941228851/0.82/   \n",
    ">\n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.81 // weighted avg f1 0.81              \n",
    "> **Voting** 정확도: 0.81 // weighted avg f1  0.81   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0812b8",
   "metadata": {},
   "source": [
    "## (5) num_word size별 머신러닝 8개 모델 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98510503",
   "metadata": {},
   "source": [
    "#### 5-1). num_word size 20000개 성능 평가   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.74/   \n",
    "LogisticRegression 정확도: 0.82 / 0.81/   \n",
    "Linear Support Vector Machine 정확도: 0.79 /0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.77 /0.76/       \n",
    "Voting 정확도: 0.82 /0.82/   \n",
    ">\n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.82 // weighted avg f1 0.81              \n",
    "> **Voting** 정확도: 0.82 // weighted avg f1  0.82   \n",
    "    \n",
    "#### 5-2). num_word size 5,000개 성능 평가   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.75/   \n",
    "LogisticRegression 정확도: 0.80/ 0.80/   \n",
    "Linear Support Vector Machine 정확도: 0.77/0.77/   \n",
    "GradientBoostingClassifier 정확도: 0.77/0.77/       \n",
    "Voting 정확도: 0.81/0.81/   \n",
    ">\n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.80// weighted avg f1 0.80             \n",
    "> **Voting** 정확도: 0.81// weighted avg f1  0.81   \n",
    "    \n",
    "#### 5-3). num_word size 10,000개 성능 평가   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.75/   \n",
    "LogisticRegression 정확도: 0.81 / 0.81/   \n",
    "Linear Support Vector Machine 정확도: 0.79 /0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.77 /0.76/       \n",
    "Voting 정확도: 0.82/0.81/   \n",
    ">\n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.81 // weighted avg f1 0.81              \n",
    "> **Voting** 정확도: 0.82// weighted avg f1  0.81   \n",
    "\n",
    "\n",
    "#### 5-4). num_word size 15,000개 성능 평가   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.74/   \n",
    "LogisticRegression 정확도: 0.81/ 0.81/   \n",
    "Linear Support Vector Machine 정확도: 0.79 /0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.77 /0.77/       \n",
    "Voting 정확도: 0.8192341941228851/0.82/   \n",
    ">\n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.81 // weighted avg f1 0.81              \n",
    "> **Voting** 정확도: 0.82 // weighted avg f1  0.82   \n",
    "\n",
    "#### [1차 머신러닝 성능 종합평가]\n",
    "* num_word size 5,000에서는 8개모델중 상위 5개 모델이 공통적으로 약 1% 정도씩의 성능하향이 보였으나,\n",
    "10,000개이상에서는 5개 모델의  성능이 거의 같았음\n",
    "\n",
    "* dlsms 로이터뉴스Corpus의 경우, **10,000개 수준이, 유용성있는 수준의 num_word siz인 것으로 보이고**, 그 이상의 단어들은 빈도수가 낮으며, Classify에 유의한 의미가 없는 것으로 해석해도 될 것 같음\n",
    "\n",
    "* **어떠한 size에서건 상관없이 우수한 Accuracy와 f1 score(weighted avg f1) 성능을 보인 모델**은 **1위 Voting_Classifier 모델과 2위 LogisticRegression 모델**이었으며, Voting_Classifier 모델은 앙상블모델로서, 앙상블의 우숭성을 보였으며, 앙상블외에 개별모델로는 LogisticRegression 모델이 가장 우수하였슴\n",
    "\n",
    "* **딥러닝모델과의 비교**는 유의미한 성능차이가 시작되는 **num_word size 10,000개의 단어를 기준**으로 성능 비교할 예정이며, 상기 **Accuracy와 f1 score(weighted avg f1) 1위인 Voting_Classifier 모델과 성능비교**를 할 예정임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829b465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca67189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82e5fda0",
   "metadata": {},
   "source": [
    "# 4. 딥러닝 모델과 비교해 보기\n",
    "위 과정을 통해 나온 최적의 모델과 단어 수 조건에서, 본인이 선택한 다른 모델을 적용한 결과와 비교해 봅시다. 감정 분석 등에 사용했던 RNN이나 1-D CNN 등의 딥러닝 모델 중 하나를 선택해서 오늘 사용했던 데이터셋을 학습해 보고 나오는 결과를 비교해 봅시다. 단, 공정한 비교를 위해 이때 Word2Vec 등의 pretrained model은 사용하지 않도록 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c649e6",
   "metadata": {},
   "source": [
    "#### [주의] 로이터 뉴스의 특이점 일부 정리   \n",
    "- 로이터 뉴스는 다운로드 받은 상태가 문장이 이미 벡터화되어 있으나, 데이터 전처리가 되지않은 상태로 벡터화되어있슴,         \n",
    "- num_word를 10,000개로 해도, word_index 30,979개인데, 이것은 단어 및 숫자, 불용어로 분류되는 관사,접속사, 일부 특수기호등이 총 망라되어 있기 때문임,       \n",
    "- 또한 index 3 이 없고, 대신 string 3 ('3') 이 각 문장의 끝에 위치해서, '< eos >'의 역할을 함(그래서,보정시에도 '< eos >'는 하지 않음)   \n",
    "- '< pad >','< sos >','< unk >' 가 index_to_word 의 0,1,2 에 위치시키고, 3은 비워 놓음, 4부터 word_index의 1번이 들어가도록 되어 있슴,\n",
    "  즉, word_index의 1번 index를 갖는 값은 'the'이며, 이 'the'는 index_to_word에는 index가 4로 되어 있음을 혼동하지 말아야함\n",
    "- word_index에는 '< pad >','< sos >','< unk >'를 index 0,1,2 로 넣으면 않됨, 기존의 word_index들과 중복되어버림, 맨마지막 위치인 30979,30980,30981로 넣거나, 여기 프로젝트에서는 아예 무시해도됨     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1e20d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36dae9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08092c53",
   "metadata": {},
   "source": [
    "#### (1) 데이터 벡터화의 전과정:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e694d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n",
      "2121728/2110848 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words= 10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f63a461a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c709ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "(8982,)\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
      "[ 3  4  3  4  4  4  4  3  3 16]\n",
      "클래스의 수 : 46\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters_word_index.json\n",
      "557056/550378 [==============================] - 0s 0us/step\n",
      "565248/550378 [==============================] - 0s 0us/step\n",
      "30979\n",
      "보정완료여부 확인 3개:index_to_word​: word_index <pad> <sos> <unk>\n",
      "보정후 x_train[0] 텍스트로 변환예시:  <sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "보정완료 OK\n",
      "문장길이평균: 145.96\n",
      "문장길이표준편차: 145.88\n",
      "문장길이Max: 2376\n",
      "문장길이Min: 2\n",
      "문장길이 0개수: 0\n",
      "maxlen 437\n",
      "len(word_index): 30979\n",
      "x_train [list([1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12])\n",
      " list([1, 3267, 699, 3434, 2295, 56, 2, 7511, 9, 56, 3906, 1073, 81, 5, 1198, 57, 366, 737, 132, 20, 4093, 7, 2, 49, 2295, 2, 1037, 3267, 699, 3434, 8, 7, 10, 241, 16, 855, 129, 231, 783, 5, 4, 587, 2295, 2, 2, 775, 7, 48, 34, 191, 44, 35, 1795, 505, 17, 12])\n",
      " list([1, 53, 12, 284, 15, 14, 272, 26, 53, 959, 32, 818, 15, 14, 272, 26, 39, 684, 70, 11, 14, 12, 3886, 18, 180, 183, 187, 70, 11, 14, 102, 32, 11, 29, 53, 44, 704, 15, 14, 19, 758, 15, 53, 959, 47, 1013, 15, 14, 19, 132, 15, 39, 965, 32, 11, 14, 147, 72, 11, 180, 183, 187, 44, 11, 14, 102, 19, 11, 123, 186, 90, 67, 960, 4, 78, 13, 68, 467, 511, 110, 59, 89, 90, 67, 1390, 55, 2678, 92, 617, 80, 1274, 46, 905, 220, 13, 4, 346, 48, 235, 629, 5, 211, 5, 1118, 7, 2, 81, 5, 187, 11, 15, 9, 1709, 201, 5, 47, 3615, 18, 478, 4514, 5, 1118, 7, 232, 2, 71, 5, 160, 63, 11, 9, 2, 81, 5, 102, 59, 11, 17, 12])] 8982 <class 'int'>\n",
      "x_train 내의 인덱스 type확인: float 0 int 1307239 str 0 etc 0 총개수 1307239\n",
      "padding > X_train_tensor: [[  0   0   0 ...  15  17  12]\n",
      " [  0   0   0 ... 505  17  12]\n",
      " [  0   0   0 ...  11  17  12]\n",
      " [  0   0   0 ... 222  17  12]\n",
      " [  0   0   0 ... 156  17  12]] (8982, 437)\n",
      "padding > X_test_tensor: [[   0    0    0 ...  510   17   12]\n",
      " [2202 1816   54 ...  760   17   12]\n",
      " [   0    0    0 ...    8   17   12]\n",
      " [   0    0    0 ...  979   17   12]\n",
      " [   0    0    0 ...    8   17   12]] (2246, 437)\n",
      "y_train_tensor[:3] [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] (8982, 46)\n",
      "y_test_tensor[:3] [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] (2246, 46)\n",
      "X_train_tensor 총개수: (8982, 437) 8982\n",
      "train_len: 7185 valid_len 1797\n",
      "partial_X_train 7185 partial_y_train 7185\n",
      "X_val_tensor 1797 y_val_tensor 1797\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "print(x_train.shape)\n",
    "#print(dir(reuters))\n",
    "#print(len(reuters.get_word_index()))\n",
    "\n",
    "print(x_train[0])\n",
    "print(x_test[0])\n",
    "print(y_train[:10])\n",
    "num_classes = y_train.max() + 1\n",
    "print('클래스의 수 : {}'.format(num_classes))\n",
    "\n",
    "#print('훈련용 뉴스의 최대 길이 :{}'.format(max(len(l) for l in x_train)))\n",
    "#print('훈련용 뉴스의 평균 길이 :{}'.format(sum(map(len, x_train))/len(x_train)))\n",
    "\n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(11,5)\n",
    "sns.countplot(x=y_train)\n",
    "plt.show()\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print(len(word_index))\n",
    "\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "    #word_index[token] = index   # 이 줄은 중복인덱스가 발생하니 하지 말것 \n",
    "    \n",
    "print(\"보정완료여부 확인 3개:index_to_word​: word_index\",index_to_word[0], index_to_word[1], index_to_word[2],)     \n",
    "print(\"보정후 x_train[0] 텍스트로 변환예시: \",  ' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "print(\"보정완료 OK\")\n",
    "\n",
    "## 데이터셋 내 문장 길이 분포\n",
    "total_data_text = list(x_train) + list(x_test)\n",
    "total_data_text_dist = [len(x) for x in total_data_text]\n",
    "#print(total_data_text_dist)\n",
    "\n",
    "mean = round(np.mean(total_data_text_dist),2)\n",
    "std = round(np.std(total_data_text_dist),2)\n",
    "max = np.max(total_data_text_dist)\n",
    "min = np.min(total_data_text_dist)\n",
    "min_count = len([x for x in total_data_text_dist if x == 0])\n",
    "print(\"문장길이평균:\",mean)\n",
    "print(\"문장길이표준편차:\",std)\n",
    "print(\"문장길이Max:\",max)\n",
    "print(\"문장길이Min:\",min)\n",
    "print(\"문장길이 0개수:\", min_count)\n",
    "\n",
    "maxlen = 437   # mean  int(mean + 2*std)\n",
    "print(\"maxlen\", maxlen)\n",
    "\n",
    "## 보정 및 최대길이에 맞추어 Padding\n",
    "# keras.preprocessing.sequence.pad_sequences 을 활용한 패딩 추가 및 maxlen로 일정길이 맞춤\n",
    "print(\"len(word_index):\",len(word_index))\n",
    "print(\"x_train\", x_train[:3], len(x_train), type(x_train[0][0]))\n",
    "\n",
    "# type 확인: train 내의 word index의 type check: 모두 int 임,\n",
    "floatlist = [];intlist = [];strlist = [];etclist = []\n",
    "for X in x_train:\n",
    "    for idx in X:\n",
    "        if type(idx) == float:\n",
    "            floatlist.append(idx)            \n",
    "        elif type(idx) == int:\n",
    "            intlist.append(idx)  \n",
    "        elif type(idx) == str:\n",
    "            strlist.append(idx)   \n",
    "        else:\n",
    "            etclist.append(idx)\n",
    "print(\"x_train 내의 인덱스 type확인:\",\"float\",len(floatlist),\"int\",len(intlist),\"str\",len(strlist),\n",
    "       \"etc\",len(etclist),\"총개수\", len(floatlist)+ len(intlist)+ len(strlist)+len(etclist)) # int만 총개수 2,176,140\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터를 numpy array로 변경. \n",
    "x_train = np.array(x_train, dtype='object')\n",
    "x_test = np.array(x_test, dtype='object')\n",
    "\n",
    "## padding된 데이터: padding된 곳은 0 이 입력됨, train_tensor_data로 변경저장\n",
    "X_train_tensor = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                       value= 0,  # <pad> index 값 : 0\n",
    "                                                       padding= 'pre',           # 성능향상위해 'pre'적용 10%차이\n",
    "                                                       maxlen=maxlen)       # maxlen = 437\n",
    "X_test_tensor = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value= 0,  # <pad> index 값 : 0\n",
    "                                                       padding= 'pre',           # 성능향상위해 'pre'적용 10%차이\n",
    "                                                       maxlen=maxlen)       # maxlen = 437\n",
    "print(\"padding > X_train_tensor:\", X_train_tensor[:5],X_train_tensor.shape)\n",
    "print(\"padding > X_test_tensor:\", X_test_tensor[:5], X_test_tensor.shape)\n",
    "\n",
    "\n",
    "## y_train, y_test 로 변경저장 및 레이블 원핫벡터로 변경저장  \n",
    "y_train_tensor = to_categorical(y_train)\n",
    "y_test_tensor = to_categorical(y_test)\n",
    "print(\"y_train_tensor[:3]\",y_train_tensor[:3], y_train_tensor.shape)\n",
    "print(\"y_test_tensor[:3]\",y_test_tensor[:3], y_test_tensor.shape)\n",
    "\n",
    "## Train, valid data 분리 : \n",
    "print(\"X_train_tensor 총개수:\", X_train_tensor.shape,X_train_tensor.shape[0])\n",
    "train_len = int(X_train_tensor.shape[0]*0.8)\n",
    "valid_len = X_train_tensor.shape[0] - train_len\n",
    "print(\"train_len:\", train_len, \"valid_len\",valid_len)\n",
    "\n",
    "# validation set 20% 분리: \n",
    "X_val_tensor = X_train_tensor[:valid_len]   \n",
    "y_val_tensor = y_train_tensor[:valid_len]\n",
    "\n",
    "# validation set을 제외한 나머지 80%\n",
    "partial_X_train = X_train_tensor[valid_len:]  \n",
    "partial_y_train = y_train_tensor[valid_len:]\n",
    "\n",
    "print(\"partial_X_train\", partial_X_train.shape[0],\"partial_y_train\",len(partial_y_train))\n",
    "print(\"X_val_tensor\",X_val_tensor.shape[0], \"y_val_tensor\",len(y_val_tensor))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841bdb12",
   "metadata": {},
   "source": [
    "#### (2) LSTM 모델구성, 학습 및 성능테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86da006c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 10000\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, None, 200)         800       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 46)                9246      \n",
      "=================================================================\n",
      "Total params: 2,372,646\n",
      "Trainable params: 2,371,446\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 7s 91ms/step - loss: 2.9385 - accuracy: 0.3880 - val_loss: 5.4615 - val_accuracy: 0.2243\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 1.9582 - accuracy: 0.5505 - val_loss: 3.9601 - val_accuracy: 0.2404\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 1.6014 - accuracy: 0.6269 - val_loss: 3.3758 - val_accuracy: 0.4424\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 1.2762 - accuracy: 0.7061 - val_loss: 3.1445 - val_accuracy: 0.3534\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 1.0692 - accuracy: 0.7550 - val_loss: 2.7404 - val_accuracy: 0.4090\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 5s 86ms/step - loss: 0.8896 - accuracy: 0.7964 - val_loss: 3.6585 - val_accuracy: 0.4647\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.7617 - accuracy: 0.8177 - val_loss: 2.4451 - val_accuracy: 0.5381\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.6591 - accuracy: 0.8430 - val_loss: 1.4340 - val_accuracy: 0.6867\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.5627 - accuracy: 0.8635 - val_loss: 1.2873 - val_accuracy: 0.7540\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.4950 - accuracy: 0.8781 - val_loss: 1.3451 - val_accuracy: 0.7641\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.4372 - accuracy: 0.8913 - val_loss: 1.2801 - val_accuracy: 0.7869\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.3978 - accuracy: 0.8931 - val_loss: 1.2370 - val_accuracy: 0.7735\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.3415 - accuracy: 0.9123 - val_loss: 1.4258 - val_accuracy: 0.8013\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.3047 - accuracy: 0.9218 - val_loss: 1.3843 - val_accuracy: 0.8019\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.2828 - accuracy: 0.9271 - val_loss: 1.2728 - val_accuracy: 0.7958\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.2650 - accuracy: 0.9282 - val_loss: 1.2579 - val_accuracy: 0.8002\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2553 - accuracy: 0.9351 - val_loss: 1.3346 - val_accuracy: 0.8030\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2332 - accuracy: 0.9367 - val_loss: 1.5380 - val_accuracy: 0.8024\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2257 - accuracy: 0.9414 - val_loss: 1.5579 - val_accuracy: 0.7902\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2087 - accuracy: 0.9418 - val_loss: 1.3477 - val_accuracy: 0.7958\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.2078 - accuracy: 0.9453 - val_loss: 1.3410 - val_accuracy: 0.7997\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.1951 - accuracy: 0.9442 - val_loss: 1.5385 - val_accuracy: 0.7997\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1931 - accuracy: 0.9485 - val_loss: 1.5007 - val_accuracy: 0.8013\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1841 - accuracy: 0.9496 - val_loss: 1.4130 - val_accuracy: 0.8041\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1790 - accuracy: 0.9498 - val_loss: 1.5868 - val_accuracy: 0.7858\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1817 - accuracy: 0.9488 - val_loss: 1.4565 - val_accuracy: 0.8002\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1779 - accuracy: 0.9518 - val_loss: 1.5218 - val_accuracy: 0.7991\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1704 - accuracy: 0.9506 - val_loss: 1.5237 - val_accuracy: 0.7935\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1581 - accuracy: 0.9550 - val_loss: 1.5306 - val_accuracy: 0.7969\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.1578 - accuracy: 0.9530 - val_loss: 1.6270 - val_accuracy: 0.7941\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1599 - accuracy: 0.9543 - val_loss: 1.5852 - val_accuracy: 0.7863\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1533 - accuracy: 0.9559 - val_loss: 1.6812 - val_accuracy: 0.7245\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1594 - accuracy: 0.9520 - val_loss: 1.5032 - val_accuracy: 0.8002\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1479 - accuracy: 0.9548 - val_loss: 1.5542 - val_accuracy: 0.7991\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1519 - accuracy: 0.9576 - val_loss: 1.5989 - val_accuracy: 0.8047\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1482 - accuracy: 0.9557 - val_loss: 1.7035 - val_accuracy: 0.7969\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.1474 - accuracy: 0.9571 - val_loss: 1.6350 - val_accuracy: 0.7952\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1456 - accuracy: 0.9559 - val_loss: 1.7042 - val_accuracy: 0.7974\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1328 - accuracy: 0.9576 - val_loss: 1.6924 - val_accuracy: 0.8008\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1274 - accuracy: 0.9626 - val_loss: 1.6607 - val_accuracy: 0.7980\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1465 - accuracy: 0.9549 - val_loss: 1.6131 - val_accuracy: 0.8063\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1330 - accuracy: 0.9576 - val_loss: 1.6391 - val_accuracy: 0.8075\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1405 - accuracy: 0.9560 - val_loss: 1.7067 - val_accuracy: 0.8019\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1373 - accuracy: 0.9594 - val_loss: 1.6096 - val_accuracy: 0.7930\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1347 - accuracy: 0.9580 - val_loss: 1.6378 - val_accuracy: 0.8080\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1289 - accuracy: 0.9608 - val_loss: 1.6909 - val_accuracy: 0.8002\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1310 - accuracy: 0.9570 - val_loss: 1.7018 - val_accuracy: 0.7997\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1303 - accuracy: 0.9584 - val_loss: 1.7285 - val_accuracy: 0.8041\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.1253 - accuracy: 0.9606 - val_loss: 1.6411 - val_accuracy: 0.8008\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1225 - accuracy: 0.9626 - val_loss: 1.7782 - val_accuracy: 0.8047\n",
      "  \n",
      "LSTM 모델 성능평가\n",
      "71/71 - 1s - loss: 1.8763 - accuracy: 0.8041\n",
      "LSTM_Test_Accuracy [1.8763363361358643, 0.8040961623191833]\n"
     ]
    }
   ],
   "source": [
    "## Hyper param 설정: Best 80.41%\n",
    "vocab_size = 10000 \n",
    "print(\"vocab_size\",vocab_size)\n",
    "num_classes = num_classes   #46\n",
    "word_vector_dim = 200  # 워드 벡터의 차원 수\n",
    "hidden_unit =  200  \n",
    "drop_rate = 0.5\n",
    "lr = 0.002   # origin 0.001\n",
    "batch_size = 128  \n",
    "epochs= 50  \n",
    "\n",
    "# Best: maxlen 437 v 10000, wv 200, hu 200, drop 0.5, batch 128, epoch 50  rmsprop lr 0.002,Test Accu : 80.41% \n",
    "\n",
    "## LSTM 모델구성\n",
    "model_lstm = tf.keras.Sequential()\n",
    "model_lstm.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_lstm.add(tf.keras.layers.BatchNormalization())\n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model_lstm.add(tf.keras.layers.LSTM(hidden_unit))\n",
    "model_lstm.add(tf.keras.layers.BatchNormalization())\n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model_lstm.add(tf.keras.layers.Dense(hidden_unit, activation='relu'))\n",
    "model_lstm.add(tf.keras.layers.BatchNormalization())\n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "\n",
    "model_lstm.add(tf.keras.layers.Dense(num_classes, activation='softmax'))  # 최종 출력은 46개 기사범주.\n",
    "model_lstm.summary()\n",
    "\n",
    "## LSTM 모델 학습\n",
    "rmsprop = tf.keras.optimizers.RMSprop(learning_rate= lr)  \n",
    "model_lstm.compile(optimizer= rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])              \n",
    "history_lstm = model_lstm.fit(partial_X_train, partial_y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val_tensor,\n",
    "                          y_val_tensor), verbose=1)\n",
    "\n",
    "## LSTM 모델 성능평가\n",
    "print(\"  \")\n",
    "print(\"LSTM 모델 성능평가\")\n",
    "results_lstm = model_lstm.evaluate(X_test_tensor,  y_test_tensor, verbose=2)\n",
    "print(\"LSTM_Test_Accuracy\", results_lstm)\n",
    "\n",
    "#predicted = model_lstm.predict(X_test_tensor)\n",
    "#LSTM_report = classification_report(y_test_tensor, predicted, zero_division=0)\n",
    "#LSTM_report_summary = LSTM_report[:50] + LSTM_report[-163:]  \n",
    "#print(\"LSTM_report_summary\",LSTM_report_summary)\n",
    "#\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41820a82",
   "metadata": {},
   "source": [
    "#### (3) Conv1D model 구성 및 성능테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ac372f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 10000\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 200)         200200    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 200)         200200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 46)                9246      \n",
      "=================================================================\n",
      "Total params: 2,449,846\n",
      "Trainable params: 2,449,846\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 3s 47ms/step - loss: 2.2099 - accuracy: 0.4576 - val_loss: 1.7609 - val_accuracy: 0.5793\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 1.6541 - accuracy: 0.5780 - val_loss: 1.6277 - val_accuracy: 0.5804\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 1.4229 - accuracy: 0.6405 - val_loss: 1.5060 - val_accuracy: 0.6439\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 1.2154 - accuracy: 0.6912 - val_loss: 1.2693 - val_accuracy: 0.6984\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 1.0687 - accuracy: 0.7303 - val_loss: 1.3127 - val_accuracy: 0.6995\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.9641 - accuracy: 0.7594 - val_loss: 1.2046 - val_accuracy: 0.7245\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.8536 - accuracy: 0.7850 - val_loss: 1.2532 - val_accuracy: 0.7101\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.7680 - accuracy: 0.8025 - val_loss: 1.2330 - val_accuracy: 0.7412\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.6959 - accuracy: 0.8180 - val_loss: 1.1660 - val_accuracy: 0.7490\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.6348 - accuracy: 0.8335 - val_loss: 1.1909 - val_accuracy: 0.7446\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5909 - accuracy: 0.8452 - val_loss: 1.2423 - val_accuracy: 0.7568\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5405 - accuracy: 0.8566 - val_loss: 1.3348 - val_accuracy: 0.6978\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.5153 - accuracy: 0.8640 - val_loss: 1.2663 - val_accuracy: 0.7385\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4724 - accuracy: 0.8784 - val_loss: 1.2891 - val_accuracy: 0.7524\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4427 - accuracy: 0.8770 - val_loss: 1.3955 - val_accuracy: 0.7412\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4230 - accuracy: 0.8853 - val_loss: 2.0465 - val_accuracy: 0.6945\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.4130 - accuracy: 0.8902 - val_loss: 1.4229 - val_accuracy: 0.7652\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3663 - accuracy: 0.8997 - val_loss: 1.4068 - val_accuracy: 0.7635\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3514 - accuracy: 0.9034 - val_loss: 1.5071 - val_accuracy: 0.7368\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3478 - accuracy: 0.9051 - val_loss: 1.4293 - val_accuracy: 0.7435\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 3s 46ms/step - loss: 0.3317 - accuracy: 0.9098 - val_loss: 1.5562 - val_accuracy: 0.7696\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3065 - accuracy: 0.9104 - val_loss: 1.5755 - val_accuracy: 0.7407\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2990 - accuracy: 0.9183 - val_loss: 1.5020 - val_accuracy: 0.7474\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.3032 - accuracy: 0.9189 - val_loss: 1.5036 - val_accuracy: 0.7513\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2842 - accuracy: 0.9216 - val_loss: 1.7358 - val_accuracy: 0.7663\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2706 - accuracy: 0.9228 - val_loss: 1.7001 - val_accuracy: 0.7730\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2742 - accuracy: 0.9214 - val_loss: 1.5888 - val_accuracy: 0.7479\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2510 - accuracy: 0.9292 - val_loss: 1.7743 - val_accuracy: 0.7713\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2611 - accuracy: 0.9255 - val_loss: 1.7992 - val_accuracy: 0.7212\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2450 - accuracy: 0.9258 - val_loss: 2.0418 - val_accuracy: 0.7106\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2379 - accuracy: 0.9305 - val_loss: 1.8491 - val_accuracy: 0.7334\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2385 - accuracy: 0.9287 - val_loss: 1.7621 - val_accuracy: 0.7462\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2196 - accuracy: 0.9346 - val_loss: 1.8389 - val_accuracy: 0.7641\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2290 - accuracy: 0.9351 - val_loss: 1.7536 - val_accuracy: 0.7351\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2241 - accuracy: 0.9364 - val_loss: 1.7380 - val_accuracy: 0.7507\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2196 - accuracy: 0.9351 - val_loss: 1.9580 - val_accuracy: 0.7162\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2200 - accuracy: 0.9389 - val_loss: 1.9125 - val_accuracy: 0.7084\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2149 - accuracy: 0.9390 - val_loss: 1.8945 - val_accuracy: 0.7212\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2166 - accuracy: 0.9407 - val_loss: 1.8788 - val_accuracy: 0.7590\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2024 - accuracy: 0.9402 - val_loss: 1.8595 - val_accuracy: 0.7379\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2157 - accuracy: 0.9371 - val_loss: 2.1464 - val_accuracy: 0.7095\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2095 - accuracy: 0.9400 - val_loss: 2.0680 - val_accuracy: 0.7607\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.1986 - accuracy: 0.9389 - val_loss: 1.9982 - val_accuracy: 0.7524\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2153 - accuracy: 0.9381 - val_loss: 2.1141 - val_accuracy: 0.7579\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.1998 - accuracy: 0.9411 - val_loss: 2.1958 - val_accuracy: 0.7629\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.1991 - accuracy: 0.9424 - val_loss: 2.1674 - val_accuracy: 0.7602\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.1994 - accuracy: 0.9418 - val_loss: 1.9875 - val_accuracy: 0.7429\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.2003 - accuracy: 0.9411 - val_loss: 2.1144 - val_accuracy: 0.7090\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.1954 - accuracy: 0.9456 - val_loss: 2.0958 - val_accuracy: 0.6973\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 2s 43ms/step - loss: 0.1976 - accuracy: 0.9427 - val_loss: 2.1089 - val_accuracy: 0.7173\n",
      "  \n",
      "CNN 모델 성능평가\n",
      "71/71 - 0s - loss: 2.4032 - accuracy: 0.7186\n",
      "CNN_Test_Accuracy [2.403167247772217, 0.7186108827590942]\n"
     ]
    }
   ],
   "source": [
    "## CNN Hyper param 설정\n",
    "vocab_size = 10000 \n",
    "print(\"vocab_size\",vocab_size)\n",
    "num_classes = num_classes   #46\n",
    "word_vector_dim = 200  # 워드 벡터의 차원 수\n",
    "hidden_unit = 200\n",
    "cnn_dense_hidden_unit = 200 \n",
    "cnn_filter = 5 \n",
    "cnn_maxpool = 2 \n",
    "drop_rate = 0.5\n",
    "lr = 0.002\n",
    "batch_size = 128  \n",
    "epochs= 50 \n",
    "\n",
    "\n",
    "## CNN_1D 모델\n",
    "\n",
    "model_cnn = tf.keras.Sequential()\n",
    "model_cnn.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_cnn.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model_cnn.add(tf.keras.layers.Conv1D(hidden_unit,cnn_filter, activation='relu'))\n",
    "model_cnn.add(tf.keras.layers.MaxPooling1D(cnn_maxpool))\n",
    "model_cnn.add(tf.keras.layers.Conv1D(hidden_unit,cnn_filter, activation='relu'))\n",
    "model_cnn.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model_cnn.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model_cnn.add(tf.keras.layers.Dense(cnn_dense_hidden_unit, activation='relu'))\n",
    "model_cnn.add(tf.keras.layers.Dense(num_classes, activation='softmax'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model_cnn.summary()\n",
    "\n",
    "rmsprop = tf.keras.optimizers.RMSprop(learning_rate= lr) \n",
    "model_cnn.compile(optimizer=rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])              \n",
    "  \n",
    "history_cnn = model_cnn.fit(partial_X_train, partial_y_train, epochs=epochs, batch_size=batch_size, \n",
    "                            validation_data=(X_val_tensor, y_val_tensor), verbose=1)\n",
    "\n",
    "## CNN 모델 성능평가\n",
    "print(\"  \")\n",
    "print(\"CNN 모델 성능평가\")\n",
    "results_cnn = model_cnn.evaluate(X_test_tensor,  y_test_tensor, verbose=2)\n",
    "print(\"CNN_Test_Accuracy\", results_cnn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8b1d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c152f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2f2f503",
   "metadata": {},
   "source": [
    "# 5. 종합평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61787205",
   "metadata": {},
   "source": [
    "### 1. 20000개 \n",
    "**성능 평가**   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.7671415850400712/weighted avg f1 0.74/   \n",
    "LogisticRegression 정확도: 0.8156723063223509/ 0.81/   \n",
    "Linear Support Vector Machine 정확도: 0.7876224398931434/0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.7702582368655387/0.76/       \n",
    "Voting 정확도: 0.8192341941228851/0.82/   \n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.8156723063223509// weighted avg f1 0.81              \n",
    "> **Voting** 정확도: 0.8192341941228851// weighted avg f1  0.82   \n",
    "    \n",
    "### 2. 5,000개\n",
    "**성능 평가**   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.75/   \n",
    "LogisticRegression 정확도: 0.80/ 0.80/   \n",
    "Linear Support Vector Machine 정확도: 0.77/0.77/   \n",
    "GradientBoostingClassifier 정확도: 0.77/0.77/       \n",
    "Voting 정확도: 0.81/0.81/   \n",
    "\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.80// weighted avg f1 0.80             \n",
    "> **Voting** 정확도: 0.81// weighted avg f1  0.81   \n",
    "    \n",
    "### 3. 10,000개    \n",
    "**성능 평가**   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.75/   \n",
    "LogisticRegression 정확도: 0.81 / 0.81/   \n",
    "Linear Support Vector Machine 정확도: 0.79 /0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.77 /0.76/       \n",
    "Voting 정확도: 0.82/0.81/   \n",
    "\n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.81 // weighted avg f1 0.81              \n",
    "> **Voting** 정확도: 0.82// weighted avg f1  0.81   \n",
    "\n",
    "\n",
    "### 4. 15,000개\n",
    "**성능 평가**   \n",
    "* 정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.74/   \n",
    "LogisticRegression 정확도: 0.81/ 0.81/   \n",
    "Linear Support Vector Machine 정확도: 0.79 /0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.77 /0.77/       \n",
    "Voting 정확도: 0.8192341941228851/0.82/   \n",
    "\n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개**   \n",
    "> **LogisticRegression** 정확도: 0.81 // weighted avg f1 0.81              \n",
    "> **Voting** 정확도: 0.81 // weighted avg f1  0.81   \n",
    "\n",
    "\n",
    "### 5. LSTM 모델 성능평가 : 10,000개 기준 \n",
    ">\n",
    "> **LSTM_Test_Accuracy  0.8040961623191833**\n",
    ">\n",
    "\n",
    "\n",
    "### 5. Conv1D 모델 성능평가 : 10,000개 기준 \n",
    ">\n",
    "> **Conv1D_Test_Accuracy  0.7186108827590942**\n",
    ">\n",
    "\n",
    "### 6. 평가 \n",
    "* **voca size 10000개이상의 경우 voca size 10000개보다 성능개선이 없고 거의 같아서, 종합비교의 기준은 10000개를기준으로 비교했슴**    \n",
    "\n",
    "#### [num_word 10000개 기준 머신러닝 우수모델과 딥러닝모델 성능비교: 정확도 80% 이상]\n",
    "\n",
    "> **LogisticRegression_Test_Accuracy: 0.81 // weighted avg f1 0.81**              \n",
    "> **Voting_Test_Accuracy: 0.82            // weighted avg f1  0.81**   \n",
    "> **LSTM_Test_Accuracy:  0.804**    \n",
    "\n",
    "> **통계기반 머신러닝의 경우, Voting 이 가장 우수하였고, 개별모델로는 LogisticRegressionajtls이 가장우수하였슴**      \n",
    "> **딥러닝의 경우 LSTM이 우수하였고, Conv1D는 정확도 72%선으로 80%에도 미달되었슴**    \n",
    "\n",
    "> 통계기반 머신러닝의 경우, 입력 데이터를 Tfidf data를 사용하였는데, 데이터가 tfidf에의해, 제일 빈도가 높은 관사등이 가중치가 낮추어지면서, 저절로 불용어로 처리가 어느 정도 되었는데, 딥러닝에 입력되는 데이터는 로이터뉴스기사 데이터의 특성상, 불용어처리하기가 용이하지 않아서, 그냥 벡터화하여 처리하였음에도 80% 이상의 정확도를 보였슴\n",
    "\n",
    "> **Voting, LogisticRegressionajtls, LSTM은 뉴스기사 카테고리 분류에 우수한 성능을 가졌으며, 데이터의 성격및 특성에 맞추어, 세가지를 다 사용해 보면서, 제일 우수한 모델을 선택해서, 좀더 깊이 학습하는 것이 좋을 것 같음**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa9fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6df0eb3f",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924fe977",
   "metadata": {},
   "source": [
    "본 프로젝트는 텍스트 데이터를 벡터화하는 과정에서,voca size 가 모델의 성능에 어떤 영향을 미치는지를 8개의 통계기반 머신러닝 모델과 2개의 딥러닝모델들을 대상으로 테스트해보는 프로젝트입니다.\n",
    "\n",
    "\n",
    "사용할 모델은 나이브 베이즈 분류기, ComplementNB, 로지스틱 회귀, 서포트 벡터 머신, 결정 트리, 랜덤 포레스트, 그래디언트 부스팅 트리, 보팅 앙상블분류기의 8개모델과, 딥러닝모델 LSTM, Conv1D 2개로 총 10개의 모델들입니다.\n",
    "\n",
    "데이터인 로이터 뉴스를 살펴보면, 다운로드 받은 상태가 문장이 이미 벡터화되어 있으나, 데이터 전처리가 되지않은 상태로 벡터화되어있고,\n",
    "num_word를 10,000개로 해도, word_index 30,979개인데, 이것은 단어 및 숫자, 불용어로 분류되는 관사,접속사, 일부 특수기호등이 총 망라되어 있기 때문으로 보이며,index 3 이 없고, 대신 string 3 ('3') 이 각 문장의 끝에 위치해서, '< eos >'의 역할을 합니다.\n",
    "그래서, '< pad >','< sos >','< unk >' 는 index_to_word 의 0,1,2 에 위치시키고, 3은 비워 놓은 상태이며, 4부터 word_index의 1번이 들어가도록 되어 있습니다.   \n",
    "그리고,index_to_word에 보정처리하듯이, word_index에는 '< pad >','< sos >','< unk >'를 index 0,1,2 로 넣으면 않되는 것이, 기존의 word_index의 index에 해당되는 단어들을 덮어씌우게 되어서, 학습할때 혼동을 줄수 있어서, 맨마지막 위치인 30979,30980,30981로 넣거나, 여기 프로젝트에서는 아예 무시해도 될듯합니다.\n",
    "\n",
    "### 1. 데이터 전처리   \n",
    "\n",
    "**(1) 8개 머신러닝모델용 데이터 전처리:**    \n",
    "데이터 전처리는 로이터 데이터가 이미 벡터화되어있는 상태인지라, 로이터데이터의 word_index를 사용해서 index_to_word​를 만들었고,index_to_word에 '< pad >','< sos >','< unk >'에 대한 보정처리를 하였으며,index_to_word를 이용하여, 로이터뉴스를 정수벡터에서 텍스트로 재전환하고서,DTM을 만들고서,train data, test data의 Tfidf를 만들었습니다.\n",
    "\n",
    "**(2) 딥러닝용 데이터 전처리:**           \n",
    "데이터 전처리는 문장의 최대길이인 maxlen을 구하기 위해서, 데이터의 분포를 보면서, 평균과 표준편차를 활용하여, maxlen= 437개로 설정하였고, index_to_word에 '< pad >','< sos >','< unk >'에 대한 보정처리를 하였으며, keras의 pad_sequence()함수를 'pre'방식으로 하여, train data, test data를 가가 maxlen에 맞추어서, padding처리를 하였습니다.   \n",
    "이 'pre'방식이 'post'방식에비해서, 약 10%의 성능향상이 있었습니다.   \n",
    "그리고, train data를 8:2의 비율로 분리하여, valid data를 만들었습니다   \n",
    "\n",
    "\n",
    "### 2. 모델 성능 평가\n",
    "\n",
    "**(1) voca size. 20000개**   \n",
    "정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.7671415850400712/weighted avg f1 0.74/   \n",
    "LogisticRegression 정확도: 0.8156723063223509/ 0.81/    \n",
    "Linear Support Vector Machine 정확도: 0.7876224398931434/0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.7702582368655387/0.76/    \n",
    "Voting 정확도: 0.8192341941228851/0.82/   \n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개       \n",
    "LogisticRegression 정확도: 0.8156723063223509// weighted avg f1 0.81      \n",
    "Voting 정확도: 0.8192341941228851// weighted avg f1 0.82**   \n",
    "\n",
    "**(2).voca size 5,000개**    \n",
    "정확도 및 weight avg fi score 70%이상 모델 5개     \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.75/      \n",
    "LogisticRegression 정확도: 0.80/ 0.80/     \n",
    "Linear Support Vector Machine 정확도: 0.77/0.77/      \n",
    "GradientBoostingClassifier 정확도: 0.77/0.77/      \n",
    "Voting 정확도: 0.81/0.81/      \n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개      \n",
    "LogisticRegression 정확도: 0.80// weighted avg f1 0.80   \n",
    "Voting 정확도: 0.81// weighted avg f1 0.81**\n",
    "\n",
    "**(3).voca size 10,000개** \n",
    "정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.75/   \n",
    "LogisticRegression 정확도: 0.81 / 0.81/   \n",
    "Linear Support Vector Machine 정확도: 0.79 /0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.77 /0.76/   \n",
    "Voting 정확도: 0.82/0.81/   \n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개      \n",
    "LogisticRegression 정확도: 0.81 // weighted avg f1 0.81    \n",
    "Voting 정확도: 0.82// weighted avg f1 0.81**\n",
    "\n",
    "**(4).voca size 15,000개**    \n",
    "정확도 및 weight avg fi score 70%이상 모델 5개   \n",
    "ComplementNB 정확도: 0.77 /weighted avg f1 0.74/   \n",
    "LogisticRegression 정확도: 0.81/ 0.81/   \n",
    "Linear Support Vector Machine 정확도: 0.79 /0.78/   \n",
    "GradientBoostingClassifier 정확도: 0.77 /0.77/   \n",
    "Voting 정확도: 0.8192341941228851/0.82/   \n",
    ">\n",
    "* **Accuracy 및 weight avg fi score 80% 이상 모델 2개      \n",
    "LogisticRegression 정확도: 0.81 // weighted avg f1 0.81      \n",
    "Voting 정확도: 0.81 // weighted avg f1 0.81**   \n",
    "\n",
    "**(5).LSTM 모델 성능평가 : 10,000개 기준**\n",
    "* **LSTM_Test_Accuracy 0.8040961623191833**\n",
    "\n",
    "**(6) Conv1D 모델 성능평가 : 10,000개 기준**\n",
    "* **Conv1D_Test_Accuracy 0.7186108827590942**\n",
    "\n",
    "**(7) 평가**\n",
    "**voca size 10000개이상의 경우 voca size 10000개보다 성능개선이 없고 거의 같아서, 종합비교의 기준은 10000개를기준으로 비교했습니다.**    \n",
    "\n",
    "* **[num_word 10000개 기준 머신러닝 우수모델과 딥러닝모델 성능비교: 정확도 80% 이상 및 f1 score 80% 이상]**\n",
    "   * LogisticRegression_Test_Accuracy: 0.81 // weighted avg f1 0.81\n",
    "   * Voting_Test_Accuracy: 0.82 // weighted avg f1 0.81\n",
    "   * LSTM_Test_Accuracy: 0.804\n",
    "\n",
    "* 통계기반 머신러닝의 경우, Voting 이 가장 우수하였고, 개별모델로는 LogisticRegressionajtls이 가장우수하였고,  \n",
    "딥러닝의 경우 LSTM이 우수하였습니다.   \n",
    "\n",
    "### 3.  결론\n",
    "**프로젝트의 주제인 voca size에 따른 성능개선측면은 사이즈가 10000 개이하에서는 size를 5000개에서 10000만개로 늘릴때,  성능개선이 있었으나, 10000개이상에서는 15000개, 20000개로 늘려도 별차이가 없었던 것으로 보아서, 로이터뉴스에서 사용하는 단어사전에서는 유의미하게 사용할수 있는 단어들이 10000개이내에 많이 포진되어있는 것으로 생각되었습니다.**\n",
    "\n",
    "통계기반 머신러닝의 경우, 입력 데이터를 Tfidf data를 사용하였는데, 데이터가 tfidf에의해, 제일 빈도가 높은 관사등이 가중치가 낮추어지면서, 저절로 불용어로 처리가 어느 정도 되었는데, 딥러닝에 입력되는 데이터는 로이터뉴스기사 데이터의 특성상, 불용어처리하기가 용이하지 않아서, 그냥 벡터화하여 처리하였음에도 80% 이상의 정확도를 보였습니다.\n",
    "\n",
    "**Voting, LogisticRegression, LSTM의 3가지 모델은 뉴스기사 카테고리 분류에 우수한 성능을 가졌으며, 데이터의 성격및 특성에 맞추어, 세가지를 다 사용해 보면서, 제일 우수한 모델을 선택해서, 좀더 깊이 학습하는 것이 좋을 것 같습니다.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b8ab46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa721434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1690c8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c46236",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea90d18f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e3e48bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab_size 10000\n",
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_36 (Embedding)     (None, None, 200)         2000000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, None, 200)         800       \n",
      "_________________________________________________________________\n",
      "dropout_99 (Dropout)         (None, None, 200)         0         \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_82 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_83 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_101 (Dropout)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 46)                9246      \n",
      "=================================================================\n",
      "Total params: 2,372,646\n",
      "Trainable params: 2,371,446\n",
      "Non-trainable params: 1,200\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "57/57 [==============================] - 7s 90ms/step - loss: 2.7197 - accuracy: 0.4306 - val_loss: 3.1995 - val_accuracy: 0.2270\n",
      "Epoch 2/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 1.7110 - accuracy: 0.6106 - val_loss: 3.4412 - val_accuracy: 0.3205\n",
      "Epoch 3/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 1.3252 - accuracy: 0.7009 - val_loss: 4.9320 - val_accuracy: 0.3428\n",
      "Epoch 4/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 1.1102 - accuracy: 0.7500 - val_loss: 10.0610 - val_accuracy: 0.3461\n",
      "Epoch 5/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.9412 - accuracy: 0.7858 - val_loss: 5.6207 - val_accuracy: 0.3539\n",
      "Epoch 6/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.8044 - accuracy: 0.8114 - val_loss: 1.6928 - val_accuracy: 0.6505\n",
      "Epoch 7/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.6866 - accuracy: 0.8372 - val_loss: 1.4298 - val_accuracy: 0.6767\n",
      "Epoch 8/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.6013 - accuracy: 0.8572 - val_loss: 2.0861 - val_accuracy: 0.5292\n",
      "Epoch 9/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.5364 - accuracy: 0.8636 - val_loss: 1.1444 - val_accuracy: 0.7819\n",
      "Epoch 10/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.4778 - accuracy: 0.8895 - val_loss: 1.1376 - val_accuracy: 0.8030\n",
      "Epoch 11/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.4297 - accuracy: 0.8958 - val_loss: 1.1854 - val_accuracy: 0.7958\n",
      "Epoch 12/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.3909 - accuracy: 0.9034 - val_loss: 1.1565 - val_accuracy: 0.7952\n",
      "Epoch 13/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.3605 - accuracy: 0.9083 - val_loss: 1.1974 - val_accuracy: 0.8030\n",
      "Epoch 14/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.3470 - accuracy: 0.9145 - val_loss: 1.2559 - val_accuracy: 0.7958\n",
      "Epoch 15/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.3029 - accuracy: 0.9194 - val_loss: 1.2474 - val_accuracy: 0.7969\n",
      "Epoch 16/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2977 - accuracy: 0.9215 - val_loss: 1.2403 - val_accuracy: 0.7974\n",
      "Epoch 17/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2733 - accuracy: 0.9285 - val_loss: 1.3176 - val_accuracy: 0.8013\n",
      "Epoch 18/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2709 - accuracy: 0.9308 - val_loss: 1.3206 - val_accuracy: 0.7908\n",
      "Epoch 19/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.2618 - accuracy: 0.9319 - val_loss: 1.2787 - val_accuracy: 0.8047\n",
      "Epoch 20/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2461 - accuracy: 0.9360 - val_loss: 1.2967 - val_accuracy: 0.8013\n",
      "Epoch 21/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2444 - accuracy: 0.9346 - val_loss: 1.3220 - val_accuracy: 0.7930\n",
      "Epoch 22/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2241 - accuracy: 0.9367 - val_loss: 1.3430 - val_accuracy: 0.7974\n",
      "Epoch 23/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2071 - accuracy: 0.9442 - val_loss: 1.6218 - val_accuracy: 0.7930\n",
      "Epoch 24/50\n",
      "57/57 [==============================] - 5s 85ms/step - loss: 0.2179 - accuracy: 0.9427 - val_loss: 1.4651 - val_accuracy: 0.7885\n",
      "Epoch 25/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2131 - accuracy: 0.9445 - val_loss: 1.3655 - val_accuracy: 0.7980\n",
      "Epoch 26/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.2075 - accuracy: 0.9435 - val_loss: 1.4314 - val_accuracy: 0.7969\n",
      "Epoch 27/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1985 - accuracy: 0.9457 - val_loss: 1.3624 - val_accuracy: 0.7947\n",
      "Epoch 28/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1931 - accuracy: 0.9475 - val_loss: 1.4721 - val_accuracy: 0.7935\n",
      "Epoch 29/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1970 - accuracy: 0.9438 - val_loss: 1.4643 - val_accuracy: 0.7969\n",
      "Epoch 30/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.1841 - accuracy: 0.9485 - val_loss: 1.4226 - val_accuracy: 0.7924\n",
      "Epoch 31/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1856 - accuracy: 0.9461 - val_loss: 1.4772 - val_accuracy: 0.7963\n",
      "Epoch 32/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1782 - accuracy: 0.9473 - val_loss: 1.5941 - val_accuracy: 0.7902\n",
      "Epoch 33/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1763 - accuracy: 0.9493 - val_loss: 1.4449 - val_accuracy: 0.7986\n",
      "Epoch 34/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1783 - accuracy: 0.9496 - val_loss: 1.4264 - val_accuracy: 0.8013\n",
      "Epoch 35/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1793 - accuracy: 0.9503 - val_loss: 1.5126 - val_accuracy: 0.7919\n",
      "Epoch 36/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.1672 - accuracy: 0.9550 - val_loss: 1.3707 - val_accuracy: 0.8024\n",
      "Epoch 37/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1667 - accuracy: 0.9528 - val_loss: 1.5110 - val_accuracy: 0.8052\n",
      "Epoch 38/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1736 - accuracy: 0.9499 - val_loss: 1.4370 - val_accuracy: 0.8058\n",
      "Epoch 39/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1507 - accuracy: 0.9570 - val_loss: 1.4840 - val_accuracy: 0.7969\n",
      "Epoch 40/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1600 - accuracy: 0.9542 - val_loss: 1.5211 - val_accuracy: 0.8013\n",
      "Epoch 41/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1484 - accuracy: 0.9566 - val_loss: 1.4356 - val_accuracy: 0.8036\n",
      "Epoch 42/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1528 - accuracy: 0.9543 - val_loss: 1.4489 - val_accuracy: 0.7997\n",
      "Epoch 43/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1478 - accuracy: 0.9534 - val_loss: 1.4286 - val_accuracy: 0.7986\n",
      "Epoch 44/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1615 - accuracy: 0.9516 - val_loss: 1.5405 - val_accuracy: 0.8058\n",
      "Epoch 45/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1438 - accuracy: 0.9566 - val_loss: 1.6867 - val_accuracy: 0.7980\n",
      "Epoch 46/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1437 - accuracy: 0.9571 - val_loss: 1.5851 - val_accuracy: 0.7969\n",
      "Epoch 47/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1418 - accuracy: 0.9571 - val_loss: 1.6100 - val_accuracy: 0.7908\n",
      "Epoch 48/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1512 - accuracy: 0.9543 - val_loss: 1.5659 - val_accuracy: 0.7913\n",
      "Epoch 49/50\n",
      "57/57 [==============================] - 5s 84ms/step - loss: 0.1541 - accuracy: 0.9528 - val_loss: 1.5939 - val_accuracy: 0.7963\n",
      "Epoch 50/50\n",
      "57/57 [==============================] - 5s 83ms/step - loss: 0.1438 - accuracy: 0.9567 - val_loss: 1.6400 - val_accuracy: 0.7997\n",
      "  \n",
      "LSTM 모델 성능평가\n",
      "71/71 - 1s - loss: 1.7491 - accuracy: 0.7947\n",
      "LSTM_Test_Accuracy [1.7490549087524414, 0.7947462201118469]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/856063905.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mLSTM_report\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mLSTM_report_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_report\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mLSTM_report\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m163\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LSTM_report_summary\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLSTM_report_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \"\"\"\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2076\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     95\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and continuous-multioutput targets"
     ]
    }
   ],
   "source": [
    "## Hyper param 설정\n",
    "vocab_size = 10000 #X_train_tensor.shape[1]\n",
    "print(\"vocab_size\",vocab_size)\n",
    "num_classes = num_classes   #46\n",
    "word_vector_dim = 200  # 워드 벡터의 차원 수\n",
    "hidden_unit =  200# 100  \n",
    "drop_rate = 0.5\n",
    "recur_drop_rate = 0.3\n",
    "lr = 0.003  #0.0001  # origin 0.001\n",
    "batch_size = 128  #128\n",
    "epochs= 50  #100 \n",
    "\n",
    "# Best: maxlen 437 v 10000, wv 200, hu 200, drop 0.5, batch 128, epoch 50  rmsprop lr 0.001,Test Accu : 79.25% \n",
    "\n",
    "\n",
    "## LSTM 모델구성\n",
    "model_lstm = tf.keras.Sequential()\n",
    "model_lstm.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model_lstm.add(tf.keras.layers.BatchNormalization())\n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model_lstm.add(tf.keras.layers.LSTM(hidden_unit))\n",
    "model_lstm.add(tf.keras.layers.BatchNormalization())\n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "\n",
    "model_lstm.add(tf.keras.layers.Dense(hidden_unit, activation='relu'))\n",
    "model_lstm.add(tf.keras.layers.BatchNormalization())\n",
    "model_lstm.add(tf.keras.layers.Dropout(drop_rate))\n",
    "\n",
    "model_lstm.add(tf.keras.layers.Dense(num_classes, activation='softmax'))  # 최종 출력은 46개 기사범주.\n",
    "model_lstm.summary()\n",
    "\n",
    "## LSTM 모델 학습\n",
    "#call back\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_acc', mode='max',baseline = 0.80,  verbose=1, patience= 2)\n",
    "mc = tf.keras.callbacks.ModelCheckpoint('./model/best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "#optimizer\n",
    "rmsprop = tf.keras.optimizers.RMSprop(learning_rate= lr)   # default 0.001\n",
    "# 학습\n",
    "model_lstm.compile(optimizer= rmsprop, loss='categorical_crossentropy', metrics=['accuracy'])   \n",
    "history_lstm = model_lstm.fit(partial_X_train, partial_y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val_tensor,\n",
    "                          y_val_tensor),callbacks=[], verbose=1)\n",
    "\n",
    "## LSTM 모델 성능평가\n",
    "print(\"  \")\n",
    "print(\"LSTM 모델 성능평가\")\n",
    "results_lstm = model_lstm.evaluate(X_test_tensor,  y_test_tensor, verbose=2)\n",
    "print(\"LSTM_Test_Accuracy\", results_lstm)\n",
    "\n",
    "#predicted = model_lstm.predict(X_test_tensor)\n",
    "#LSTM_report = classification_report(y_test_tensor, predicted, zero_division=0)\n",
    "#LSTM_report_summary = LSTM_report[:50] + LSTM_report[-163:]  \n",
    "#print(\"LSTM_report_summary\",LSTM_report_summary)\n",
    "\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f9b57d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n",
      "(8982,)\n",
      "[1, 2, 2, 8, 43, 10, 447, 5, 25, 207, 270, 5, 3095, 111, 16, 369, 186, 90, 67, 7, 89, 5, 19, 102, 6, 19, 124, 15, 90, 67, 84, 22, 482, 26, 7, 48, 4, 49, 8, 864, 39, 209, 154, 6, 151, 6, 83, 11, 15, 22, 155, 11, 15, 7, 48, 9, 4579, 1005, 504, 6, 258, 6, 272, 11, 15, 22, 134, 44, 11, 15, 16, 8, 197, 1245, 90, 67, 52, 29, 209, 30, 32, 132, 6, 109, 15, 17, 12]\n",
      "[1, 4, 1378, 2025, 9, 697, 4622, 111, 8, 25, 109, 29, 3650, 11, 150, 244, 364, 33, 30, 30, 1398, 333, 6, 2, 159, 9, 1084, 363, 13, 2, 71, 9, 2, 71, 117, 4, 225, 78, 206, 10, 9, 1214, 8, 4, 270, 5, 2, 7, 748, 48, 9, 2, 7, 207, 1451, 966, 1864, 793, 97, 133, 336, 7, 4, 493, 98, 273, 104, 284, 25, 39, 338, 22, 905, 220, 3465, 644, 59, 20, 6, 119, 61, 11, 15, 58, 579, 26, 10, 67, 7, 4, 738, 98, 43, 88, 333, 722, 12, 20, 6, 19, 746, 35, 15, 10, 9, 1214, 855, 129, 783, 21, 4, 2280, 244, 364, 51, 16, 299, 452, 16, 515, 4, 99, 29, 5, 4, 364, 281, 48, 10, 9, 1214, 23, 644, 47, 20, 324, 27, 56, 2, 2, 5, 192, 510, 17, 12]\n",
      "클래스의 수 : 46\n",
      "훈련용 뉴스의 최대 길이 :2376\n",
      "훈련용 뉴스의 평균 길이 :145.5398574927633\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 792x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "각 클래스 빈도수:\n",
      "[[   0    1    2    3    4    5    6    7    8    9   10   11   12   13\n",
      "    14   15   16   17   18   19   20   21   22   23   24   25   26   27\n",
      "    28   29   30   31   32   33   34   35   36   37   38   39   40   41\n",
      "    42   43   44   45]\n",
      " [  55  432   74 3159 1949   17   48   16  139  101  124  390   49  172\n",
      "    26   20  444   39   66  549  269  100   15   41   62   92   24   15\n",
      "    48   19   45   39   32   11   50   10   49   19   19   24   36   30\n",
      "    13   21   12   18]]\n",
      "=3\n",
      "30979\n",
      "=3\n",
      "30979\n",
      "=3\n",
      "=3\n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n",
      "8982\n",
      "2246\n",
      "(8982, 9670) (2246, 9670)\n",
      "(8982, 9670) (2246, 9670)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "  (0, 9628)\t0.06356670958147888\n",
      "  (0, 9218)\t0.08780620595054514\n",
      "  (0, 9181)\t0.08604864459739914\n",
      "  (0, 8932)\t0.25028101697583904\n",
      "  (0, 8890)\t0.0930998381922142\n",
      "  (0, 8875)\t0.07672366483129915\n",
      "  (0, 8850)\t0.03988247757031195\n",
      "  (0, 8303)\t0.203150231713389\n",
      "  (0, 8272)\t0.030312371161604353\n",
      "  (0, 8175)\t0.1025062385626965\n",
      "  (0, 8106)\t0.22747636818044054\n",
      "  (0, 8055)\t0.25190182137461803\n",
      "  (0, 7834)\t0.1219387278172762\n",
      "  (0, 7727)\t0.1102444102744686\n",
      "  (0, 7675)\t0.13792521715667663\n",
      "  (0, 7666)\t0.030539304325861907\n",
      "  (0, 7633)\t0.1272430689584012\n",
      "  (0, 7508)\t0.21863456761984176\n",
      "  (0, 6972)\t0.1539628581207626\n",
      "  (0, 6682)\t0.27676451799730706\n",
      "  (0, 6429)\t0.15755807940652689\n",
      "  (0, 6365)\t0.11453293816669016\n",
      "  (0, 6253)\t0.10419591024092598\n",
      "  (0, 6218)\t0.07042182393755048\n",
      "  (0, 6042)\t0.21345820216754235\n",
      "  :\t:\n",
      "  (8981, 3632)\t0.08621812797387604\n",
      "  (8981, 3491)\t0.07481068075649426\n",
      "  (8981, 3155)\t0.08709921432098085\n",
      "  (8981, 3136)\t0.08181638104840938\n",
      "  (8981, 3046)\t0.08006841942701773\n",
      "  (8981, 2939)\t0.06566265598159318\n",
      "  (8981, 2749)\t0.11826022712569333\n",
      "  (8981, 2565)\t0.06272636731804493\n",
      "  (8981, 2358)\t0.15036379649309742\n",
      "  (8981, 2215)\t0.05057033987354948\n",
      "  (8981, 2191)\t0.28558818151776744\n",
      "  (8981, 2083)\t0.07636390667341178\n",
      "  (8981, 1948)\t0.11462344642077285\n",
      "  (8981, 1919)\t0.04317118116215351\n",
      "  (8981, 1863)\t0.10309872587740929\n",
      "  (8981, 1860)\t0.06088044451723479\n",
      "  (8981, 1837)\t0.09068458502535057\n",
      "  (8981, 1650)\t0.13898309873550016\n",
      "  (8981, 1590)\t0.13578473280322462\n",
      "  (8981, 1573)\t0.11856949020698222\n",
      "  (8981, 1552)\t0.0724226795074108\n",
      "  (8981, 1508)\t0.10937254175811499\n",
      "  (8981, 1476)\t0.08015908807936437\n",
      "  (8981, 1315)\t0.16271181440337254\n",
      "  (8981, 1261)\t0.13178194056004253\n",
      "tfidfv_array.shape (8982, 9670)\n",
      "X_train_tensor[:3] [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.08655827 0.         ... 0.         0.         0.        ]] (8982, 9670)\n",
      "X_test_tensor[:3] [[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.04917246 0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]] (2246, 9670)\n",
      "y_train_tensor[:3] [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] (8982, 46)\n",
      "y_test_tensor[:3] [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] (2246, 46)\n",
      "X_train_tensor 총개수: (8982, 9670)\n",
      "train_len: 7185 valid_len 1797\n",
      "partial_X_train 7185 partial_y_train 7185\n",
      "X_val_tensor 1797 y_val_tensor 1797\n"
     ]
    }
   ],
   "source": [
    "##### ONE-HOT 모델에서 오류 계속 남 / 데이터 전처리 및 벡터화\n",
    "\n",
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))\n",
    "print(x_train.shape)\n",
    "#print(dir(reuters))\n",
    "#print(len(reuters.get_word_index()))\n",
    "\n",
    "print(x_train[0])\n",
    "print(x_test[0])\n",
    "\n",
    "num_classes = y_train.max() + 1  #max(y_train) + 1\n",
    "print('클래스의 수 : {}'.format(num_classes))\n",
    "\n",
    "print('훈련용 뉴스의 최대 길이 :{}'.format(np.max([len(l) for l in x_train])))\n",
    "print('훈련용 뉴스의 평균 길이 :{}'.format(np.mean([len(l) for l in x_train])))\n",
    "\n",
    "plt.hist([len(s) for s in x_train], bins=50)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(11,5)\n",
    "sns.countplot(x=y_train)\n",
    "plt.show()\n",
    "\n",
    "unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "print(\"각 클래스 빈도수:\")\n",
    "print(np.asarray((unique_elements, counts_elements)))\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print('=3')\n",
    "print(len(word_index))\n",
    "\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "print('=3')\n",
    "print(len(word_index))\n",
    "\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "print('=3')\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "print('=3')\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))\n",
    "\n",
    "## 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "# train data\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))\n",
    "# test data\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))\n",
    "\n",
    "# 변환여부 확인\n",
    "x_train[:5]\n",
    "x_test[:5]\n",
    "\n",
    "## DTM을 생성하고, DTM의 크기를 확인\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "x_test_dtm =  dtmvector.transform(x_test)\n",
    "print(x_train_dtm.shape, x_test_dtm.shape)\n",
    "\n",
    "## TF-IDF Matrix 생성하고,크기를 확인\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)\n",
    "print(tfidfv.shape, tfidfv_test.shape)\n",
    "print(type(tfidfv))\n",
    "print(tfidfv)\n",
    "\n",
    "## TF-IDF Matrix 를 one_hot 형태의 array로 전환\n",
    "tfidfv_array = tfidfv.todense()\n",
    "tfidfv_test_array = tfidfv_test.todense()\n",
    "print(\"tfidfv_array.shape\", tfidfv_array.shape)\n",
    "\n",
    "## train, test 로 변경저장 및 레이블 원핫벡터로 변경저장  \n",
    "X_train_tensor = tfidfv_array.copy()\n",
    "X_test_tensor = tfidfv_test_array.copy()\n",
    "print(\"X_train_tensor[:3]\",X_train_tensor[:3], X_train_tensor.shape)\n",
    "print(\"X_test_tensor[:3]\",X_test_tensor[:3], X_test_tensor.shape)\n",
    "\n",
    "y_train_tensor = to_categorical(y_train)\n",
    "y_test_tensor = to_categorical(y_test)\n",
    "print(\"y_train_tensor[:3]\",y_train_tensor[:3], y_train_tensor.shape)\n",
    "print(\"y_test_tensor[:3]\",y_test_tensor[:3], y_test_tensor.shape)\n",
    "\n",
    "## Train, valid data 분리 : \n",
    "print(\"X_train_tensor 총개수:\", X_train_tensor.shape)\n",
    "train_len = int(X_train_tensor.shape[0]*0.8)\n",
    "valid_len = X_train_tensor.shape[0] - train_len\n",
    "print(\"train_len:\", train_len, \"valid_len\",valid_len)\n",
    "\n",
    "# validation set 20% 분리: \n",
    "X_val_tensor = X_train_tensor[:valid_len]   \n",
    "y_val_tensor = y_train_tensor[:valid_len]\n",
    "\n",
    "# validation set을 제외한 나머지 80%\n",
    "partial_X_train = X_train_tensor[valid_len:]  \n",
    "partial_y_train = y_train_tensor[valid_len:]\n",
    "\n",
    "print(\"partial_X_train\", partial_X_train.shape[0],\"partial_y_train\",len(partial_y_train))\n",
    "print(\"X_val_tensor\",X_val_tensor.shape[0], \"y_val_tensor\",len(y_val_tensor))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8528d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca96d935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0668c773",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
