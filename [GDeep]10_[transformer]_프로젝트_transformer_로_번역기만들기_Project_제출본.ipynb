{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db073a8d",
   "metadata": {},
   "source": [
    "## 10-5. 프로젝트: 더 멋진 번역기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e97f69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp -r /aiffel/data  /aiffel/aiffel/transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e104f88",
   "metadata": {},
   "source": [
    "#### 라이브러리 버전을 확인해 봅니다.\n",
    "사용할 라이브러리 버전을 둘러봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f077f3b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.21.4\n",
      "3.4.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import numpy\n",
    "import matplotlib\n",
    "\n",
    "print(tensorflow.__version__)\n",
    "print(numpy.__version__)\n",
    "print(matplotlib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abf66282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,time,copy\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6367316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot 시 한글처리\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "mpl.font_manager.findfont(font)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ce1bd5",
   "metadata": {},
   "source": [
    "#### Step 1. 데이터 다운로드 (클라우드 유저용)\n",
    "아래 링크에서 korean-english-park.train.tar.gz 를 사용할 예정입니다. 다운로드할 필요는 없습니다.\n",
    "\n",
    "* [jungyeul/korean-parallel-corpora](https://github.com/jungyeul/korean-parallel-corpora/tree/master/korean-english-news-v1)\n",
    "\n",
    "☁️클라우드 환경에서는 위 데이터를 미리 준비해 놓았으니 연결만 시켜줍시다. 우측 하단의 Cloud shell을 열어주세요.\n",
    "아래와 같이 공유 디렉토리에 저장된 데이터를 가리키는 심볼릭 링크를 생성해 주시면 됩니다.\n",
    "```\n",
    "$ ln -s ~/data ~/aiffel/transformer/data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcf5466",
   "metadata": {},
   "source": [
    "#### Step 2. 데이터 정제 및 토큰화\n",
    "1. set 데이터형이 중복을 허용하지 않는다는 것을 활용해 중복된 데이터를 제거하도록 합니다. 데이터의 병렬 쌍이 흐트러지지 않게 주의하세요! 중복을 제거한 데이터를 cleaned_corpus 에 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20bcc524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94123 94123\n",
      "cleaned_corpus ['두바이 해변 성관계 英 커플 보석으로 석방    `Sex on beach` couple free on bail in Dubai\\n', '우리는 희생자와 그 유가족들 그리고 미국민 들에게 깊은 애도를 표한다.” 라고 말했다.    \"We convey deep condolences to victims, families and the American people.\\n'] 78968\n",
      "결측치 개수 cleaned_corpus    0\n",
      "dtype: int64\n",
      "cleaned_corpus ['두바이 해변 성관계 英 커플 보석으로 석방    `Sex on beach` couple free on bail in Dubai\\n', '우리는 희생자와 그 유가족들 그리고 미국민 들에게 깊은 애도를 표한다.” 라고 말했다.    \"We convey deep condolences to victims, families and the American people.\\n'] 78968\n",
      "저장된 cleaned_corpus 로드후 확인:  ['두바이 해변 성관계 英 커플 보석으로 석방    `Sex on beach` couple free on bail in Dubai', '우리는 희생자와 그 유가족들 그리고 미국민 들에게 깊은 애도를 표한다.” 라고 말했다.    \"We convey deep condolences to victims, families and the American people.']\n",
      "중복 맟 결측치 제거후 문장개수:  78968\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.getenv('HOME')+'/aiffel/transformer/data'\n",
    "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
    "\n",
    "# 데이터 정제 및 토큰화\n",
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
    "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
    "    assert len(kor) == len(eng)\n",
    "\n",
    "    # [[YOUR CODE]]\n",
    "    print(len(kor), len(eng))    \n",
    "    cleaned_corpus = list(set(zip(kor,eng)))\n",
    "    # 문장별로 튜플을 풀어서 str 로 전환: 한개의 문장내 한글 vs 영어는 공백4칸으로 구분, 문장별 구분은 '\\n'으로 구분\n",
    "    cleaned_corpus = [line[0] + ' '*4 + line[1] +'\\n' for line in cleaned_corpus]\n",
    "    print(\"cleaned_corpus\",cleaned_corpus[:2], len(cleaned_corpus))\n",
    "   \n",
    "    return cleaned_corpus\n",
    "\n",
    "cleaned_corpus = clean_corpus(kor_path, eng_path)\n",
    "\n",
    "#결측치체크 및 제거\n",
    "# 결측치 체크위해 DataFrame만들기: \n",
    "df = pd.DataFrame({'cleaned_corpus': cleaned_corpus}) \n",
    "# 결측치제거 : 1개라도 있으면, 해당행 전체 제거\n",
    "print(\"결측치 개수\",df.isnull().sum())\n",
    "if df.isnull().any().any():\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    print(\"결측치제거후 결측치 여부\",df.isnull().any().any())     \n",
    "# 원래의 cleaned_corpus 형태로 변경\n",
    "cleaned_corpus = [x[0] for x in df.values.tolist()]\n",
    "print(\"cleaned_corpus\",cleaned_corpus[:2], len(cleaned_corpus))\n",
    "\n",
    "# 저장\n",
    "with open(os.getenv('HOME')+'/aiffel/transformer/cleaned_corpus/cleaned_corpus', 'w') as f:  \n",
    "        for line in cleaned_corpus:\n",
    "            #line = line[0]+' '*4 + line[1] + '\\n'\n",
    "            f.write(line)\n",
    "            \n",
    "# 저장여부 확인\n",
    "with open(os.getenv('HOME')+'/aiffel/transformer/cleaned_corpus'+ '/cleaned_corpus', \"r\") as f:    \n",
    "    cleaned_corpus_check = f.read().splitlines()    # \\n 떼어 놓고, line별 구분됨 \n",
    "    \n",
    "print(\"저장된 cleaned_corpus 로드후 확인: \", cleaned_corpus_check[:2])\n",
    "print(\"중복 맟 결측치 제거후 문장개수: \", len(cleaned_corpus))   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f728c",
   "metadata": {},
   "source": [
    "2. 정제 함수를 아래 조건을 만족하게 정의하세요.\n",
    ">\n",
    "> * 모든 입력을 소문자로 변환합니다.\n",
    "> * 알파벳, 문장부호, 한글만 남기고 모두 제거합니다.\n",
    "> * 문장부호 양옆에 공백을 추가합니다.\n",
    "> * 문장 앞뒤의 불필요한 공백을 제거합니다.\n",
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e48ee335",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence, mecab_eng = False):\n",
    "    \n",
    "    # [[YOUR CODE]]\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^0-9ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    if mecab_eng == True:\n",
    "        sentence =  '<BOS> ' + sentence + ' <EOS>'\n",
    "        \n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5775554e",
   "metadata": {},
   "source": [
    "문장 알파벳길이별 분포체크:  분포도 상 특이한 이상치 없슴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e6ef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor_max 377\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 265,
       "width": 379
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eng_max 606\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 265,
       "width": 379
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor ['두바이 해변 성관계 英 커플 보석으로 석방', '우리는 희생자와 그 유가족들 그리고 미국민 들에게 깊은 애도를 표한다.” 라고 말했다.', '이라크 정부는 민병대의 철수를 반겼으며 누리 알-말리키 이라크 총리는 “알-사드르가 옳은 결정을 내렸다고 이 지역의 평화와 안정을 위해 함께 노력했으면 한다”고 말했다.']\n",
      "eng ['`Sex on beach` couple free on bail in Dubai\\n', '\"We convey deep condolences to victims, families and the American people.\\n', \"Al-Sadr's political movement holds 30 seats in Iraq's 275-member parliament and was once a partner in al-Maliki's ruling coalition. The party quit the government in 2007 after al-Maliki refused to demand a deadline for the withdrawal of U.S. troops.\\n\"]\n"
     ]
    }
   ],
   "source": [
    "raw_kor_corpus = []\n",
    "raw_eng_corpus = []\n",
    "\n",
    "for pair in cleaned_corpus:\n",
    "    raw_kor, raw_eng = pair.split(\" \"*4)  \n",
    "    raw_kor_corpus.append(raw_kor)\n",
    "    raw_eng_corpus.append(raw_eng)  # 아래 코드에서 set_encode_extra_options(\"bos:eos\")으로 자동으로 '<BOS>', '<EOS>' 붙음\n",
    "\n",
    "## 문장길이별 분포 \n",
    "korlen = [len(x) for x in raw_kor_corpus]\n",
    "kor_max= np.max(korlen)\n",
    "print(\"kor_max\", kor_max)\n",
    "plt.hist(korlen, bins= 100)\n",
    "plt.title(\"kor\")\n",
    "plt.show()\n",
    "\n",
    "englen = [len(x) for x in raw_eng_corpus]\n",
    "eng_max= np.max(englen)\n",
    "print(\"eng_max\", eng_max)\n",
    "plt.hist(englen, bins= 100, color='red')\n",
    "plt.title(\"eng\")\n",
    "plt.show()\n",
    "\n",
    "## sample\n",
    "print(\"kor\",raw_kor_corpus[:3])\n",
    "print(\"eng\",raw_eng_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf3bce7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96285606",
   "metadata": {},
   "source": [
    "3. 한글 말뭉치 kor_corpus 와 영문 말뭉치 eng_corpus 를 각각 분리한 후, 정제하여 토큰화를 진행합니다! 토큰화에는 Sentencepiece를 활용하세요. 첨부된 공식 사이트를 참고해 아래 조건을 만족하는 generate_tokenizer() 함수를 정의합니다. 최종적으로 ko_tokenizer 과 en_tokenizer 를 얻으세요. en_tokenizer에는 set_encode_extra_options(\"bos:eos\") 함수를 실행해 타겟 입력이 문장의 시작 토큰과 끝 토큰을 포함할 수 있게 합니다.\n",
    "* [google/sentencepiece](https://github.com/google/sentencepiece)\n",
    "\n",
    "단어 사전을 매개변수로 받아 원하는 크기의 사전을 정의할 수 있게 합니다. (기본: 20,000)   \n",
    "학습 후 저장된 **model** 파일을 **SentencePieceProcessor() 클래스에 Load()** 한 후 반환합니다.   \n",
    "특수 토큰의 인덱스를 아래와 동일하게 지정합니다.      \n",
    "**PAD : 0 / BOS : 1 / EOS : 2 / UNK : 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb35584",
   "metadata": {},
   "source": [
    "**sentencepiece용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "258fffd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/transformer/cleaned_corpus/kor_corpus --model_prefix=korean_spm --vocab_size=25000 --pad_id=0 --unk_id=3 --pad_piece=<PAD> --unk_piece=<UNK>\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/transformer/cleaned_corpus/kor_corpus\n",
      "  input_format: \n",
      "  model_prefix: korean_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 25000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <UNK>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <PAD>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/transformer/cleaned_corpus/kor_corpus\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78967 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <PAD>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <UNK>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5192554\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1191\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78967 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 160841 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78967\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 210086\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 210086 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=84578 obj=12.9652 num_tokens=415679 num_tokens/piece=4.91474\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=71844 obj=11.8027 num_tokens=417305 num_tokens/piece=5.80849\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=53879 obj=11.8111 num_tokens=434756 num_tokens/piece=8.06912\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=53862 obj=11.7776 num_tokens=435129 num_tokens/piece=8.07859\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=40396 obj=11.9213 num_tokens=459514 num_tokens/piece=11.3752\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=40395 obj=11.8844 num_tokens=459562 num_tokens/piece=11.3767\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=30296 obj=12.0781 num_tokens=486003 num_tokens/piece=16.0418\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=30296 obj=12.0364 num_tokens=486006 num_tokens/piece=16.0419\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=27500 obj=12.1127 num_tokens=494556 num_tokens/piece=17.9839\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=27500 obj=12.0988 num_tokens=494608 num_tokens/piece=17.9857\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: korean_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: korean_spm.vocab\n",
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/transformer/cleaned_corpus/eng_corpus --model_prefix=english_spm --vocab_size=25000 --pad_id=0,--bos_id=1 --eos_id=2 --unk_id=3 --pad_piece=<PAD> --bos_piece=<BOS> --eos_piece=<EOS> --unk_piece=<UNK>\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/transformer/cleaned_corpus/eng_corpus\n",
      "  input_format: \n",
      "  model_prefix: english_spm\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 25000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <UNK>\n",
      "  bos_piece: <BOS>\n",
      "  eos_piece: <EOS>\n",
      "  pad_piece: <PAD>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/transformer/cleaned_corpus/eng_corpus\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 78957 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <PAD>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <BOS>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <EOS>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <UNK>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=10789012\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9506% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=38\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999506\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 78957 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 83783 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 78957\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 46275\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 46275 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=35194 obj=9.97208 num_tokens=87100 num_tokens/piece=2.47485\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=26446 obj=8.1277 num_tokens=87543 num_tokens/piece=3.31025\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: english_spm.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: english_spm.vocab\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 650521 Mar 12 11:29 english_spm.model\r\n",
      "-rw-r--r-- 1 root root 434854 Mar 12 11:29 english_spm.vocab\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentencepiece를 활용하여 학습한 tokenizer를 생성합니다.\n",
    "def generate_tokenizer(corpus_path, vocab_size, lang=\"ko\", pad_id=0, bos_id=1, eos_id=2, unk_id=3,\n",
    "                   pad_piece=\"<PAD>\", bos_piece=\"<BOS>\", eos_piece=\"<EOS>\", unk_piece=\"<UNK>\" ):\n",
    "    \n",
    "    # [[YOUR CODE]]\n",
    "    #temp_file = os.getenv('HOME')+'/aiffel/transformer/cleaned_corpus/cleaned_corpus'\n",
    "    # SentencePiece 학습\n",
    "    if lang == \"ko\":\n",
    "        import sentencepiece as spm \n",
    "        # --pad_piece={} --bos_piece={} --eos_piece={} --unk_piece={}\n",
    "        spm.SentencePieceTrainer.Train(\n",
    "                '--input={} --model_prefix=korean_spm --vocab_size={} --pad_id={} --unk_id={} --pad_piece={} --unk_piece={}'.format(\n",
    "            corpus_path, vocab_size, pad_id, unk_id, pad_piece, unk_piece))\n",
    "        #!ls -l korean_spm* \n",
    "        # SentencePiece tokenizer 객체생성\n",
    "        tokenizer = spm.SentencePieceProcessor()\n",
    "        tokenizer.Load('korean_spm.model')\n",
    "        \n",
    "        # 단어사전생성\n",
    "        #vocab_word, word_index, index_word = word_index_and_index_word(tokenizer, corpus, kor=True) \n",
    "    else: \n",
    "        import sentencepiece as spm1\n",
    "        spm1.SentencePieceTrainer.Train(\n",
    "            '--input={} --model_prefix=english_spm --vocab_size={} --pad_id={},--bos_id={} --eos_id={} --unk_id={} --pad_piece={} --bos_piece={} --eos_piece={} --unk_piece={}'.format(\n",
    "            corpus_path, vocab_size, pad_id, bos_id, eos_id, unk_id, pad_piece, bos_piece, eos_piece, unk_piece))\n",
    "        !ls -l english_spm*\n",
    "        # SentencePiece tokenizer 객체생성\n",
    "        tokenizer = spm1.SentencePieceProcessor()\n",
    "        tokenizer.Load('english_spm.model')\n",
    "        \n",
    "        # 단어사전생성   \n",
    "        #vocab_word, word_index, index_word = word_index_and_index_word(tokenizer, corpus, kor=False)   \n",
    "    \n",
    "    return tokenizer   #, vocab_word, word_index, index_word\n",
    "    \n",
    "\n",
    "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 25000\n",
    "\n",
    "eng_corpus = []\n",
    "kor_corpus = []\n",
    "\n",
    "for pair in cleaned_corpus:\n",
    "    k, e = pair.split(\" \"*4)  \n",
    "    kor_corpus.append(preprocess_sentence(k))\n",
    "    eng_corpus.append(preprocess_sentence(e))  # 아래 코드에서 set_encode_extra_options(\"bos:eos\")으로 자동으로 '<BOS>', '<EOS>' 붙음\n",
    "\n",
    "# 분리된 데이터 저장\n",
    "kor_corpus_path = os.getenv('HOME')+'/aiffel/transformer/cleaned_corpus/kor_corpus'\n",
    "eng_corpus_path = os.getenv('HOME')+'/aiffel/transformer/cleaned_corpus/eng_corpus'\n",
    "\n",
    "with open(kor_corpus_path, 'w') as f:  \n",
    "    for line in kor_corpus:\n",
    "        line = line + '\\n'\n",
    "        f.write(line)\n",
    "with open(eng_corpus_path, 'w') as f:  \n",
    "    for line in eng_corpus:\n",
    "        line = line + '\\n'\n",
    "        f.write(line)\n",
    "        \n",
    "kor_tokenizer  = generate_tokenizer(kor_corpus_path, SRC_VOCAB_SIZE, \"ko\")\n",
    "eng_tokenizer = generate_tokenizer(eng_corpus_path, TGT_VOCAB_SIZE, \"en\")\n",
    "\n",
    "# 별도로 '<BOS>', '<EOS>' 코딩않해도 영어문장 앞뒤로 붙게해주는 옵션: sentencepiece 경우만 해당\n",
    "eng_tokenizer.set_encode_extra_options(\"bos:eos\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b47362e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'<BOS>', '<EOS>' 자동으로 붙는지 테스트: ['<BOS>', '▁sex', '▁on', '▁beach', '▁couple', '▁free', '▁on', '▁bail', '▁in', '▁dubai', '<EOS>']\n",
      "kor_corpus 저장분 확인 78968 ['두바이 해변 성관계 커플 보석으로 석방', '우리는 희생자와 그 유가족들 그리고 미국민 들에게 깊은 애도를 표한다 . 라고 말했다 .', '이라크 정부는 민병대의 철수를 반겼으며 누리 알 말리키 이라크 총리는 알 사드르가 옳은 결정을 내렸다고 이 지역의 평화와 안정을 위해 함께 노력했으면 한다 고 말했다 .', '힐러리 클린턴 상원의원은 17일 현지시간 자신이 이라크전쟁을 끝낼 수 있는 리더십을 갖춘 유일한 대선후보라고 밝혔다 .', '그들은 관공서 일자리 고용에서부터 주지사의 친구나 기부자들의 행동에 이르기까지 일리노이 주지사의 일거수일투족을 감시해 왔습니다 .']\n",
      "eng_corpus 저장분 확인 78968 ['sex on beach couple free on bail in dubai', 'we convey deep condolences to victims , families and the american people .', 'al sadr s political movement holds 30 seats in iraq s 275 member parliament and was once a partner in al maliki s ruling coalition . the party quit the government in 2007 after al maliki refused to demand a deadline for the withdrawal of u . s . troops .', 'hillary clinton said monday she is the only candidate who would exercise the leadership needed to end the war in iraq .', 'they ve been looking at everything from the illinois governor , for hiring people for state jobs , to the actions of friends and contributors .']\n"
     ]
    }
   ],
   "source": [
    "## 체크용 셀\n",
    "# '<BOS>', '<EOS>' 자동으로 붙는지 테스트 : OK\n",
    "tokens = eng_tokenizer.EncodeAsPieces(eng_corpus[0]) \n",
    "print(\"'<BOS>', '<EOS>' 자동으로 붙는지 테스트:\", tokens)\n",
    "\n",
    "# \"한글, 영어 분리잘되었나 저장분 확인        \n",
    "with open(kor_corpus_path, \"r\") as f: kor_check = f.read().splitlines()\n",
    "print(\"kor_corpus 저장분 확인\",len(kor_check), kor_check[:5])    \n",
    "with open(eng_corpus_path, \"r\") as f: eng_check = f.read().splitlines() \n",
    "print(\"eng_corpus 저장분 확인\", len(eng_check), eng_check[:5])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58218c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['두바이 해변 성관계 커플 보석으로 석방', '우리는 희생자와 그 유가족들 그리고 미국민 들에게 깊은 애도를 표한다 . 라고 말했다 .', '이라크 정부는 민병대의 철수를 반겼으며 누리 알 말리키 이라크 총리는 알 사드르가 옳은 결정을 내렸다고 이 지역의 평화와 안정을 위해 함께 노력했으면 한다 고 말했다 .'] [[3593, 3585, 3181, 3427, 12701, 584], [111, 6, 1629, 28, 22, 12863, 187, 48, 1612, 8, 629, 2446, 9, 4552, 10, 8, 11759, 4, 180, 31, 4], [79, 70, 6, 2227, 7, 995, 10, 18177, 42, 3607, 163, 2405, 79, 102, 6, 163, 2915, 11, 8, 24871, 9, 456, 5, 1281, 15, 19, 164, 7, 583, 28, 1883, 5, 43, 178, 24432, 184, 138, 26, 31, 4]] [['▁두바이', '▁해변', '▁성관계', '▁커플', '▁보석으로', '▁석방'], ['▁우리', '는', '▁희생자', '와', '▁그', '▁유가족들', '▁그리고', '▁미국', '민', '▁', '들에게', '▁깊', '은', '▁애도', '를', '▁', '표한다', '▁.', '▁라고', '▁말했다', '▁.'], ['▁이라크', '▁정부', '는', '▁민병대', '의', '▁철수', '를', '▁반겼', '으며', '▁누리', '▁알', '▁말리키', '▁이라크', '▁총리', '는', '▁알', '▁사드르', '가', '▁', '옳', '은', '▁결정', '을', '▁내렸다', '고', '▁이', '▁지역', '의', '▁평화', '와', '▁안정', '을', '▁위해', '▁함께', '▁노력했으', '면', '▁한다', '▁고', '▁말했다', '▁.']]\n",
      "\n",
      "['sex on beach couple free on bail in dubai', 'we convey deep condolences to victims , families and the american people .', 'al sadr s political movement holds 30 seats in iraq s 275 member parliament and was once a partner in al maliki s ruling coalition . the party quit the government in 2007 after al maliki refused to demand a deadline for the withdrawal of u . s . troops .'] [[1, 787, 19, 1770, 731, 443, 19, 3402, 11, 2585, 2], [1, 61, 5681, 1160, 5795, 7, 8, 881, 6, 1360, 79, 12, 4, 177, 54, 5, 2], [1, 105, 2382, 16, 304, 1213, 665, 7, 318, 1710, 11, 122, 16, 128, 3, 585, 639, 755, 12, 25, 19, 194, 9, 2237, 11, 105, 2083, 186, 16, 712, 1021, 5, 4, 119, 1557, 4, 70, 11, 222, 3, 45, 105, 2083, 186, 1999, 13, 8, 743, 9, 1889, 20, 4, 2184, 10, 48, 5, 16, 5, 238, 5, 2]] [['<BOS>', '▁sex', '▁on', '▁beach', '▁couple', '▁free', '▁on', '▁bail', '▁in', '▁dubai', '<EOS>'], ['<BOS>', '▁we', '▁convey', '▁deep', '▁condolence', 's', '▁to', '▁victims', '▁,', '▁famili', 'es', '▁and', '▁the', '▁american', '▁people', '▁.', '<EOS>'], ['<BOS>', '▁al', '▁sadr', '▁s', '▁political', '▁movement', '▁hold', 's', '▁30', '▁seats', '▁in', '▁iraq', '▁s', '▁2', '7', '5', '▁member', '▁parliament', '▁and', '▁was', '▁on', 'ce', '▁a', '▁partner', '▁in', '▁al', '▁malik', 'i', '▁s', '▁ruling', '▁coalition', '▁.', '▁the', '▁party', '▁quit', '▁the', '▁government', '▁in', '▁200', '7', '▁after', '▁al', '▁malik', 'i', '▁refus', 'ed', '▁to', '▁demand', '▁a', '▁deadline', '▁for', '▁the', '▁withdrawal', '▁of', '▁u', '▁.', '▁s', '▁.', '▁troops', '▁.', '<EOS>']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# word_index, index_word 생성함수\n",
    "def word_index_and_index_word(tokenizer, corpus, kor=False):\n",
    "    \n",
    "    corpus_token = []\n",
    "    as_piece = []\n",
    "    for sen in corpus:\n",
    "        corpus_token.append(tokenizer.EncodeAsIds(sen))\n",
    "        as_piece.append(tokenizer.EncodeAsPieces(sen))\n",
    "        \n",
    "    print(corpus[:3],corpus_token[:3],as_piece[:3])  \n",
    "    print()\n",
    "    \n",
    "    if kor==True:  path = \"./korean_spm.vocab\"\n",
    "    else:   path = \"./english_spm.vocab\"\n",
    "        \n",
    "    with open(path, 'r') as f:  vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "        word_index.update({word:idx})\n",
    "        index_word.update({idx:word})\n",
    "  \n",
    "    return  corpus_token, word_index, index_word\n",
    "\n",
    "\n",
    "# 토큰화완료된 한글 코퍼스 및 한글 단어사전생성   \n",
    "kor_corpus_token, kor_word_index, kor_index_word = word_index_and_index_word(kor_tokenizer, kor_corpus, kor= True)\n",
    "# 토큰화완료된 영어 코퍼스 및 영어 단어사전생성   \n",
    "eng_corpus_token, eng_word_index, eng_index_word = word_index_and_index_word(eng_tokenizer, eng_corpus)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db72e8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor_corpus의 정수인덱스 token으로 전환확인 [[3593, 3585, 3181, 3427, 12701, 584], [111, 6, 1629, 28, 22, 12863, 187, 48, 1612, 8, 629, 2446, 9, 4552, 10, 8, 11759, 4, 180, 31, 4], [79, 70, 6, 2227, 7, 995, 10, 18177, 42, 3607, 163, 2405, 79, 102, 6, 163, 2915, 11, 8, 24871, 9, 456, 5, 1281, 15, 19, 164, 7, 583, 28, 1883, 5, 43, 178, 24432, 184, 138, 26, 31, 4], [548, 252, 447, 9, 375, 21, 54, 561, 79, 10898, 5, 2432, 2967, 27, 34, 9801, 5, 1798, 3061, 1386, 16, 987, 215, 30, 4], [22, 86, 18724, 1646, 1938, 17, 323, 570, 7, 1009, 65, 4693, 1552, 7, 5855, 6842, 128, 3588, 570, 7, 260, 193, 264, 21, 2210, 3301, 5, 1561, 73, 8404, 4]]\n",
      "\n",
      "eng_corpus의 정수인덱스 token으로 전환확인 [[1, 787, 19, 1770, 731, 443, 19, 3402, 11, 2585, 2], [1, 61, 5681, 1160, 5795, 7, 8, 881, 6, 1360, 79, 12, 4, 177, 54, 5, 2], [1, 105, 2382, 16, 304, 1213, 665, 7, 318, 1710, 11, 122, 16, 128, 3, 585, 639, 755, 12, 25, 19, 194, 9, 2237, 11, 105, 2083, 186, 16, 712, 1021, 5, 4, 119, 1557, 4, 70, 11, 222, 3, 45, 105, 2083, 186, 1999, 13, 8, 743, 9, 1889, 20, 4, 2184, 10, 48, 5, 16, 5, 238, 5, 2], [1, 1049, 265, 18, 121, 74, 23, 4, 19, 24, 418, 44, 71, 2479, 4, 1661, 1005, 8, 196, 4, 180, 11, 122, 5, 2], [1, 47, 601, 49, 285, 14, 30, 1509, 33, 4, 1340, 1130, 6, 20, 11067, 14, 54, 20, 107, 1094, 6, 8, 4, 597, 7, 10, 1395, 12, 10377, 7, 5, 2]]\n",
      "\n",
      "kor_index_word[0~20] [(0, '<PAD>'), (1, '<s>'), (2, '</s>'), (3, '<UNK>'), (4, '▁.'), (5, '을'), (6, '는'), (7, '의'), (8, '▁'), (9, '은'), (10, '를'), (11, '가'), (12, '▁,'), (13, '에'), (14, '이'), (15, '고'), (16, '한'), (17, '에서'), (18, '로'), (19, '▁이'), (20, '인')]\n",
      "kor_word_index[0~20] [('<PAD>', 0), ('<s>', 1), ('</s>', 2), ('<UNK>', 3), ('▁.', 4), ('을', 5), ('는', 6), ('의', 7), ('▁', 8), ('은', 9), ('를', 10), ('가', 11), ('▁,', 12), ('에', 13), ('이', 14), ('고', 15), ('한', 16), ('에서', 17), ('로', 18), ('▁이', 19), ('인', 20)]\n",
      "\n",
      "eng_index_word[0~20] [(0, '<PAD>'), (1, '<BOS>'), (2, '<EOS>'), (3, '<UNK>'), (4, '▁the'), (5, '▁.'), (6, '▁,'), (7, 's'), (8, '▁to'), (9, '▁a'), (10, '▁of'), (11, '▁in'), (12, '▁and'), (13, 'ed'), (14, 'ing'), (15, '▁'), (16, '▁s'), (17, 'd'), (18, '▁said'), (19, '▁on'), (20, '▁for')]\n",
      "eng_word_index[0~20] [('<PAD>', 0), ('<BOS>', 1), ('<EOS>', 2), ('<UNK>', 3), ('▁the', 4), ('▁.', 5), ('▁,', 6), ('s', 7), ('▁to', 8), ('▁a', 9), ('▁of', 10), ('▁in', 11), ('▁and', 12), ('ed', 13), ('ing', 14), ('▁', 15), ('▁s', 16), ('d', 17), ('▁said', 18), ('▁on', 19), ('▁for', 20)]\n",
      "\n",
      "토큰화완료된 kor_corpus_token의 크기확인: 78968\n",
      "토큰화완료된 eng_corpus_token의 크기확인: 78968\n",
      "한글사전크기 25000\n",
      "영어사전크기 25000\n"
     ]
    }
   ],
   "source": [
    "## 토큰화 완료된 한글, 영어 코퍼스 문장 확인 kor_vocab_word\n",
    "print(\"kor_corpus의 정수인덱스 token으로 전환확인\", kor_corpus_token[:5])\n",
    "print()\n",
    "print(\"eng_corpus의 정수인덱스 token으로 전환확인\", eng_corpus_token[:5])\n",
    "print()\n",
    "\n",
    "## 한글사전 샘플 확인\n",
    "print(\"kor_index_word[0~20]\",[(k,v) for (k,v) in kor_index_word.items() if k<=20])\n",
    "print(\"kor_word_index[0~20]\",[(k,v) for (k,v) in kor_word_index.items() if v <=20])  \n",
    "print()\n",
    "\n",
    "## 영어사전 샘플 확인\n",
    "print(\"eng_index_word[0~20]\",[(k,v) for (k,v) in eng_index_word.items() if k<=20])\n",
    "print(\"eng_word_index[0~20]\",[(k,v) for (k,v) in eng_word_index.items() if v <=20])   \n",
    "print()\n",
    "\n",
    "## 토큰화완료된 corpus 크기 및 단어사전크기확인\n",
    "print(\"토큰화완료된 kor_corpus_token의 크기확인:\", len(kor_corpus_token))\n",
    "print(\"토큰화완료된 eng_corpus_token의 크기확인:\", len(eng_corpus_token))\n",
    "print(\"한글사전크기\",kor_tokenizer.GetPieceSize())\n",
    "print(\"영어사전크기\",eng_tokenizer.GetPieceSize())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe0e4a6",
   "metadata": {},
   "source": [
    "4. 토크나이저를 활용해 토큰의 길이가 50 이하인 데이터를 선별하여 src_corpus 와 tgt_corpus 를 각각 구축하고, 텐서 enc_train 과 dec_train 으로 변환하세요! (❗모든 데이터를 사용할 경우 학습에 굉장히 오랜 시간이 걸립니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf1943cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(kor_corpus_token) 78968\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d0f92d41f74ae89df21b56c7b0a8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/78968 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토큰의 길이가 50 축소후 src_corpus 71549 [[3593, 3585, 3181, 3427, 12701, 584], [111, 6, 1629, 28, 22, 12863, 187, 48, 1612, 8, 629, 2446, 9, 4552, 10, 8, 11759, 4, 180, 31, 4]] [[3392, 2893, 40, 1289, 468, 3, 9, 10255, 330, 11, 7647, 777, 4], [742, 5, 3145, 64, 211, 10238, 14779, 461, 10558, 807, 6875, 23871, 20841, 12393, 180, 9685, 16, 19, 13762, 6, 142, 13534, 14, 309, 33, 72, 949, 829, 67, 2703, 24, 4]]\n",
      "\n",
      "토큰의 길이가 50 축소후 tgt_corpus 71549 [[1, 787, 19, 1770, 731, 443, 19, 3402, 11, 2585, 2], [1, 61, 5681, 1160, 5795, 7, 8, 881, 6, 1360, 79, 12, 4, 177, 54, 5, 2]] [[1, 287, 138, 4, 2837, 6, 147, 3018, 125, 53, 1363, 46, 49, 5046, 5, 2], [1, 4, 5057, 6, 64, 966, 1794, 4, 2003, 689, 6213, 931, 6, 313, 7, 4, 196, 10, 4, 98, 42, 266, 11, 157, 998, 5, 2]]\n",
      "\n",
      "enc_train 71549 [[ 3593  3585  3181  3427 12701   584     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0]\n",
      " [  111     6  1629    28    22 12863   187    48  1612     8   629  2446\n",
      "      9  4552    10     8 11759     4   180    31     4     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0]] [[ 3392  2893    40  1289   468     3     9 10255   330    11  7647   777\n",
      "      4     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0]\n",
      " [  742     5  3145    64   211 10238 14779   461 10558   807  6875 23871\n",
      "  20841 12393   180  9685    16    19 13762     6   142 13534    14   309\n",
      "     33    72   949   829    67  2703    24     4     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0]]\n",
      "\n",
      "dec_train 71549 [[   1  787   19 1770  731  443   19 3402   11 2585    2    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   1   61 5681 1160 5795    7    8  881    6 1360   79   12    4  177\n",
      "    54    5    2    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]] [[   1  287  138    4 2837    6  147 3018  125   53 1363   46   49 5046\n",
      "     5    2    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]\n",
      " [   1    4 5057    6   64  966 1794    4 2003  689 6213  931    6  313\n",
      "     7    4  196   10    4   98   42  266   11  157  998    5    2    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm    # Process 과정을 보기 위해\n",
    "\n",
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "assert len(kor_corpus_token) == len(eng_corpus_token)\n",
    "\n",
    "print(\"len(kor_corpus_token)\",len(kor_corpus_token))\n",
    "print()\n",
    "# 토큰의 길이가 50 이하인 문장만 남깁니다. \n",
    "for idx in tqdm(range(len(kor_corpus_token))):\n",
    "    # [[YOUR CODE]]\n",
    "    if len(kor_corpus_token[idx]) <=50 and len(eng_corpus_token[idx]) <=50 :\n",
    "        src_corpus.append(kor_corpus_token[idx])\n",
    "        tgt_corpus.append(eng_corpus_token[idx])\n",
    "\n",
    "print(\"토큰의 길이가 50 축소후 src_corpus\", len(src_corpus), src_corpus[:2],src_corpus[-2:])\n",
    "print()\n",
    "print(\"토큰의 길이가 50 축소후 tgt_corpus\", len(tgt_corpus), tgt_corpus[:2],tgt_corpus[-2:])\n",
    "print()\n",
    "# 패딩처리를 완료하여 학습용 데이터를 완성. \n",
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, maxlen = 50, padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, maxlen = 50, padding='post')\n",
    "\n",
    "print(\"enc_train\", len(enc_train), enc_train[:2],enc_train[-2:])\n",
    "print()\n",
    "print(\"dec_train\", len(dec_train), dec_train[:2],dec_train[-2:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8390b1f",
   "metadata": {},
   "source": [
    "#### Step 3. 모델 설계\n",
    "오늘 배운 내용을 활용해서 Transformer 모델을 설계해보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a1de20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i) / d_model)\n",
    "\n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "\n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    print(sinusoid_table)\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    return sinusoid_table\n",
    "\n",
    "#print(positional_encoding(10, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed8d1026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads  \n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model) # Linear Layer\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "\n",
    "        \"\"\"\n",
    "        Scaled QK 값 구하기\n",
    "        \"\"\"\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "\n",
    "        if mask is not None: scaled_qk += (mask * -1e9)  \n",
    "\n",
    "        \"\"\"\n",
    "        1. Attention Weights 값 구하기 -> attentions\n",
    "        2. Attention 값을 V에 곱하기 -> out\n",
    "        \"\"\" \n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        out = tf.matmul(attentions, V)\n",
    "\n",
    "        return out, attentions\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        \"\"\"\n",
    "        Embedding을 Head의 수로 분할하는 함수\n",
    "\n",
    "        x: [ batch x length x emb ]\n",
    "        return: [ batch x length x heads x self.depth ]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "\n",
    "        return split_x\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        \"\"\"\n",
    "        분할된 Embedding을 하나로 결합하는 함수\n",
    "        x: [ batch x length x heads x self.depth ]\n",
    "        return: [ batch x length x emb ]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
    "\n",
    "        return combined_x\n",
    "          \n",
    "\n",
    "    def call(self, Q, K, V, mask):\n",
    "        \"\"\"\n",
    "        아래 순서에 따라 소스를 작성하세요.\n",
    "\n",
    "        Step 1: Linear_in(Q, K, V) -> WQ, WK, WV\n",
    "        Step 2: Split Heads(WQ, WK, WV) -> WQ_split, WK_split, WV_split\n",
    "        Step 3: Scaled Dot Product Attention(WQ_split, WK_split, WV_split)\n",
    "                 -> out, attention_weights\n",
    "        Step 4: Combine Heads(out) -> out\n",
    "        Step 5: Linear_out(out) -> out\n",
    "\n",
    "        \"\"\"\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "            \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask)\n",
    "       \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "       \n",
    "        return out, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cc8779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4afc1a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af544025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecoderLayer 클래스를 작성하세요.\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, n_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout) \n",
    "                \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        \n",
    "        \"\"\"\n",
    "        Masked Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)  # padding_mask == dec_mask == tf.maximum(dec_mask,dec_causal_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Multi-Head Attention\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)  # causal_mask==tf.maxi(enc_mas,dec_enc_causal_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "\n",
    "        \"\"\"\n",
    "        Position-Wise Feed Forward Network\n",
    "        \"\"\"\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, dec_attn, dec_enc_attn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2f174ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                        for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66d3d8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
    "                            for _ in range(n_layers)]\n",
    "                            \n",
    "                            \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "    \n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = \\\n",
    "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "\n",
    "        return out, dec_attns, dec_enc_attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a7f12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 pos_len,\n",
    "                 dropout=0.2,\n",
    "                 shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        #self.d_model = tf.cast(d_model, tf.float32)  ==> float로 할 경우 dimension 오류발생됨\n",
    "        self.d_model = d_model   \n",
    "        \"\"\"\n",
    "        1. Embedding Layer 정의\n",
    "        2. Positional Encoding 정의\n",
    "        3. Encoder / Decoder 정의\n",
    "        4. Output Linear 정의\n",
    "        5. Shared Weights\n",
    "        6. Dropout 정의\n",
    "        \"\"\"\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, self.d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, self.d_model)\n",
    "\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)   # int(n_heads)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)   # int(n_heads)\n",
    "\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "\n",
    "        self.shared = shared\n",
    "\n",
    "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "\n",
    "    def embedding(self, emb, x):\n",
    "        \"\"\"\n",
    "        입력된 정수 배열을 Embedding + Pos Encoding\n",
    "        + Shared일 경우 Scaling 작업 포함\n",
    "\n",
    "        x: [ batch x length ]\n",
    "        return: [ batch x length x emb ]\n",
    "        \"\"\"      \n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "\n",
    "        if self.shared: out *= tf.math.sqrt(tf.cast(d_model, tf.float32)) #self.d_model)   # int ???  self.d_model\n",
    "\n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "        \n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        \"\"\"\n",
    "        아래 순서에 따라 소스를 작성하세요.\n",
    "\n",
    "        Step 1: Embedding(enc_in, dec_in) -> enc_in, dec_in\n",
    "        Step 2: Encoder(enc_in, enc_mask) -> enc_out, enc_attns\n",
    "        Step 3: Decoder(dec_in, enc_out, mask)\n",
    "                -> dec_out, dec_attns, dec_enc_attns\n",
    "        Step 4: Out Linear(dec_out) -> logits\n",
    "        \"\"\"\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        \n",
    "        dec_out, dec_attns, dec_enc_attns = \\\n",
    "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f1b9c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    #print(\"enc_mask\",enc_mask.shape,enc_mask,\"dec_enc_causality_mask\",dec_enc_causality_mask.shape,dec_enc_causality_mask)\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "    #print(\"dec_enc_mask\",dec_enc_mask.shape,dec_enc_mask)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "    #print(\"dec_mask\",dec_mask.shape, dec_mask,\"dec_causality_mask\",dec_causality_mask.shape,dec_causality_mask)\n",
    "    return enc_mask, dec_enc_mask, dec_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d277a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마스크 shape\n",
    "\"\"\"\n",
    "enc_mask (64, 1, 1, 50) Tensor(\"strided_slice_1:0\", shape=(64, 1, 1, 50), dtype=float32) dec_enc_causality_mask (50, 50) Tensor(\"Cast_2:0\", shape=(50, 50), dtype=float32)\n",
    "dec_enc_mask (64, 1, 50, 50) Tensor(\"Maximum:0\", shape=(64, 1, 50, 50), dtype=float32)\n",
    "dec_mask (64, 1, 50, 50) Tensor(\"Maximum_1:0\", shape=(64, 1, 50, 50), dtype=float32) dec_causality_mask (50, 50) Tensor(\"Cast_3:0\", shape=(50, 50), dtype=float32)\n",
    "enc_mask (64, 1, 1, 50) Tensor(\"strided_slice_1:0\", shape=(64, 1, 1, 50), dtype=float32) dec_enc_causality_mask (50, 50) Tensor(\"Cast_2:0\", shape=(50, 50), dtype=float32)\n",
    "dec_enc_mask (64, 1, 50, 50) Tensor(\"Maximum:0\", shape=(64, 1, 50, 50), dtype=float32)\n",
    "dec_mask (64, 1, 50, 50) Tensor(\"Maximum_1:0\", shape=(64, 1, 50, 50), dtype=float32) dec_causality_mask (50, 50) Tensor(\"Cast_3:0\", shape=(50, 50), dtype=float32)\n",
    "enc_mask (56, 1, 1, 50) Tensor(\"strided_slice_1:0\", shape=(56, 1, 1, 50), dtype=float32) dec_enc_causality_mask (50, 50) Tensor(\"Cast_2:0\", shape=(50, 50), dtype=float32)\n",
    "dec_enc_mask (56, 1, 50, 50) Tensor(\"Maximum:0\", shape=(56, 1, 50, 50), dtype=float32)\n",
    "dec_mask (56, 1, 50, 50) Tensor(\"Maximum_1:0\", shape=(56, 1, 50, 50), dtype=float32) dec_causality_mask (50, 50) Tensor(\"Cast_3:0\", shape=(50, 50), dtype=float32)\n",
    "enc_mask (1, 1, 1, 50) tf.Tensor(\n",
    "[[[[0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "    1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "    1. 1. 1. 1. 1. 1.]]]], shape=(1, 1, 1, 50), dtype=float32) dec_enc_causality_mask (1, 50) tf.Tensor(\n",
    "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "  1. 1.]], shape=(1, 50), dtype=float32)\n",
    "dec_enc_mask (1, 1, 1, 50) tf.Tensor(\n",
    "[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "    1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "    1. 1. 1. 1. 1. 1.]]]], shape=(1, 1, 1, 50), dtype=float32)\n",
    "dec_mask (1, 1, 1, 1) tf.Tensor([[[[0.]]]], shape=(1, 1, 1, 1), dtype=float32) dec_causality_mask (1, 1) tf.Tensor([[0.]], shape=(1, 1), dtype=float32)\n",
    "enc_mask (1, 1, 1, 50) tf.Tensor(\n",
    "[[[[0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "    1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "    1. 1. 1. 1. 1. 1.]]]], shape=(1, 1, 1, 50), dtype=float32) dec_enc_causality_mask (2, 50) tf.Tensor(\n",
    "[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "  1. 1.]\n",
    " [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "  1. 1.]], shape=(2, 50), dtype=float32)\n",
    "dec_enc_mask (1, 1, 2, 50) tf.Tensor(\n",
    "[[[[0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "    1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "    1. 1. 1. 1. 1. 1.]\n",
    "   [0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "    1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
    "    1. 1. 1. 1. 1. 1.]]]], shape=(1, 1, 2, 50), dtype=float32)\n",
    "dec_mask (1, 1, 2, 2) tf.Tensor(\n",
    "[[[[0. 1.]\n",
    "   [0. 0.]]]], shape=(1, 1, 2, 2), dtype=float32) dec_causality_mask (2, 2) tf.Tensor(\n",
    "[[0. 1.]\n",
    " [0. 0.]], shape=(2, 2), dtype=float32)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16c89053",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  LearningRateScheduler 클래스 함수정의\n",
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "#learning_rate = LearningRateScheduler(d_model = 512, warmup_steps = 4000)\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7271e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07c7bdc6",
   "metadata": {},
   "source": [
    "#### Step 4. 훈련하기\n",
    "앞서 필요한 것들을 모두 정의했기 때문에 우리는 훈련만 하면 됩니다! 아래 과정을 차근차근 따라가며 모델을 훈련하고, 예문에 대한 멋진 번역을 제출하세요!\n",
    "\n",
    "1. 2 Layer를 가지는 Transformer를 선언하세요.\n",
    "(하이퍼파라미터는 자유롭게 조절합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "355693f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 9.82171889e-01 9.64661620e-01 ... 1.05544960e-04\n",
      "  1.03663293e-04 1.01815172e-04]\n",
      " [2.00000000e+00 1.96434378e+00 1.92932324e+00 ... 2.11089920e-04\n",
      "  2.07326586e-04 2.03630344e-04]\n",
      " ...\n",
      " [4.70000000e+01 4.61620788e+01 4.53390961e+01 ... 4.96061312e-03\n",
      "  4.87217476e-03 4.78531309e-03]\n",
      " [4.80000000e+01 4.71442507e+01 4.63037578e+01 ... 5.06615808e-03\n",
      "  4.97583806e-03 4.88712826e-03]\n",
      " [4.90000000e+01 4.81264226e+01 4.72684194e+01 ... 5.17170304e-03\n",
      "  5.07950135e-03 4.98894344e-03]]\n"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "\n",
    "n_layers= 2\n",
    "d_model= 512\n",
    "n_heads= 8  \n",
    "d_ff= 2048\n",
    "src_vocab_size = 25000\n",
    "tgt_vocab_size = 25000\n",
    "pos_len = 50  #200 #50\n",
    "dropout= 0.3\n",
    "shared=True\n",
    "\n",
    "\n",
    "# 트랜스포머 모델설정\n",
    "transformer = Transformer(n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 src_vocab_size,\n",
    "                 tgt_vocab_size,\n",
    "                 pos_len,\n",
    "                 dropout=dropout,\n",
    "                 shared=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9b3bdf",
   "metadata": {},
   "source": [
    "2. 논문에서 사용한 것과 동일한 Learning Rate Scheduler를 선언하고, 이를 포함하는 Adam Optimizer를 선언하세요. (Optimizer의 파라미터 역시 논문과 동일하게 설정합니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d3702c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(d_model)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1=0.9,\n",
    "                                     beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69331692",
   "metadata": {},
   "source": [
    "3. Loss 함수를 정의하세요.\n",
    "\n",
    "Sequence-to-sequence 모델에서 사용했던 Loss와 유사하되, **Masking** 되지 않은 입력의 개수로 Scaling하는 과정을 추가합니다. (트랜스포머가 모든 입력에 대한 Loss를 한 번에 구하기 때문입니다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56f2b1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    #[주의} real data는 transformer model 내에서는 마스크가 씌워지는 절차없으니,여기서 씌움,모델내에서는 enc_train,dec_train 만 씌움\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))   # 여기선 마스크씌울 부분이 0 이됨, \"곱해주는 마스크\"라서, 0이됨 \n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask         # 여기선 마스크씌울 부분이 0 이므로, 곱해주어야 패딩부분이 0이되어 무시됨,즉, loss의 합계에서 제외됨 \n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "039f03e4",
   "metadata": {},
   "source": [
    "4. train_step 함수를 정의하세요.\n",
    "\n",
    "**입력 데이터에 알맞은 Mask를 생성**하고, 이를 모델에 전달하여 연산에서 사용할 수 있게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da0914e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Step 함수 정의\n",
    "\n",
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    # 최종적으로 optimizer.apply_gradients()가 사용됩니다. \n",
    "    # [[YOUR CODE]]\n",
    "    variables = model.encoder.trainable_variables + model.decoder.trainable_variables \n",
    "    gradients = tape.gradient(loss, variables)\n",
    "    optimizer.apply_gradients(zip(gradients, variables))\n",
    "    \n",
    "        \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddb3b2a",
   "metadata": {},
   "source": [
    "5. 학습을 진행합니다.\n",
    "\n",
    "매 Epoch 마다 제시된 예문에 대한 번역을 생성하고, 멋진 번역이 생성되면 그때의 하이퍼파라미터와 생성된 번역을 제출하세요!\n",
    "\n",
    "예문   \n",
    "```\n",
    "1. 오바마는 대통령이다.\n",
    "2. 시민들은 도시 속에 산다.\n",
    "3. 커피는 필요 없다.\n",
    "4. 일곱 명의 사망자가 발생했다.\n",
    "```   \n",
    "결과(output)   \n",
    "```\n",
    "Translations\n",
    "> 1. obama is the president elect .\n",
    "> 2. they are in the city .\n",
    "> 3. they don t need to be a lot of drink .\n",
    "> 4. seven other people have been killed in the attacks .\n",
    "```\n",
    "\n",
    "파라메터\n",
    "```\n",
    "Hyperparameters\n",
    "> n_layers: 2\n",
    "> d_model: 512\n",
    "> n_heads: 8\n",
    "> d_ff: 2048\n",
    "> dropout: 0.3\n",
    "\n",
    "Training Parameters\n",
    "> Warmup Steps: 4000\n",
    "> Batch Size: 64\n",
    "> Epoch At: 5\n",
    "```\n",
    "\n",
    "번역 생성에는 아래 소스를 사용하시길 바랍니다!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27baa383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 시각화 함수\n",
    "\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    print(\"@@@ enc_attns\",len(enc_attns),enc_attns[0].shape,\"dec_attns.shape\",len(dec_attns),dec_attns[0].shape, \n",
    "          \"dec_enc_attns.shape\",len(dec_enc_attns),dec_enc_attns[0].shape )\n",
    "    \n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "487bd626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 함수\n",
    "\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4377494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 및 Attention 시각화 결합\n",
    "\n",
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, epoch, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
    "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    #-----------------------------------\n",
    "    print(\"epoch\",epoch)   \n",
    "    translate_result = [epoch, sentence, result] \n",
    "    #------------------------------------   \n",
    "       \n",
    "    if (epoch== 1000 or epoch >= EPOCHS-1)  and plot_attention :\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)   \n",
    "        \n",
    "    return  translate_result   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076ef0d8",
   "metadata": {},
   "source": [
    "translate() 함수의 plot_attention 변수를 True 로 주면 번역 결과에 대한 Attention Map을 시각화 해볼 수 있습니다.\n",
    "\n",
    "마지막으로, 학습의 전 과정을 구현한 코드를 첨부합니다. 구현 과정에 참고해 주세요. 수고하셨습니다!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867e82ca",
   "metadata": {},
   "source": [
    "#### 학습1:  Hyper param Tuning 코드 없으나, 지우지 말것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3a65a212",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom tqdm import tqdm_notebook \\nimport tqdm\\n\\n#Training Parameters\\nWarmup_Steps= 4000\\nBATCH_SIZE = 64\\nEPOCHS = 1 #20 #20,50\\n\\'\\'\\'\\n#Hyperparameters\\nn_layers= 3\\nd_model= 512\\nn_heads= 8  \\nd_ff= 2048\\nsrc_vocab_size = 20000\\ntgt_vocab_size = 20000\\npos_len = 100 #100 #200 #50\\ndropout= 0.3\\nshared=True\\n\\'\\'\\'\\n\\nexamples = [\\n            \"오바마는 대통령이다.\",\\n            \"시민들은 도시 속에 산다.\",\\n            \"커피는 필요 없다.\",\\n            \"일곱 명의 사망자가 발생했다.\"\\n]\\n\\n# loss append\\nhistory = {\\'loss\\':[], \\'val_loss\\':[], \\'lr\\':[]}\\n\\nfor epoch in range(EPOCHS):\\n    total_loss = 0\\n    \\n    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\\n    random.shuffle(idx_list)\\n    t = tqdm.notebook.tqdm(idx_list)  #tqdm_notebook(idx_list)\\n\\n    for (batch, idx) in enumerate(t):\\n        batch_loss, enc_attns, dec_attns, dec_enc_attns = train_step(enc_train[idx:idx+BATCH_SIZE],\\n                    dec_train[idx:idx+BATCH_SIZE],\\n                    transformer,\\n                    optimizer)\\n\\n        total_loss += batch_loss\\n        \\n        t.set_description_str(\\'Epoch %2d\\' % (epoch + 1))\\n        t.set_postfix_str(\\'Loss %.4f\\' % (total_loss.numpy() / (batch + 1)))\\n        \\n        history[\\'loss\\'].append(round(total_loss.numpy() / (batch + 1),4))\\n        history[\\'lr\\'].append(optimizer.learning_rate)\\n\\n    for example in examples:\\n        translate(example, transformer, kor_tokenizer, eng_tokenizer, epoch, plot_attention= False) #True)\\n\\n# loss 그래프 \\nprint(\"history.keys()\",history.keys()) \\nplt.plot(range(len(history[\\'loss\\'])),history[\\'loss\\'])\\nplt.title(\\'Transformer_loss graph\\')\\nplt.xlabel(\\'step\\')\\nplt.ylabel(\\'loss\\')\\nplt.show()\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습1\n",
    "\"\"\"\n",
    "from tqdm import tqdm_notebook \n",
    "import tqdm\n",
    "\n",
    "#Training Parameters\n",
    "Warmup_Steps= 4000\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 1 #20 #20,50\n",
    "'''\n",
    "#Hyperparameters\n",
    "n_layers= 3\n",
    "d_model= 512\n",
    "n_heads= 8  \n",
    "d_ff= 2048\n",
    "src_vocab_size = 20000\n",
    "tgt_vocab_size = 20000\n",
    "pos_len = 100 #100 #200 #50\n",
    "dropout= 0.3\n",
    "shared=True\n",
    "'''\n",
    "\n",
    "examples = [\n",
    "            \"오바마는 대통령이다.\",\n",
    "            \"시민들은 도시 속에 산다.\",\n",
    "            \"커피는 필요 없다.\",\n",
    "            \"일곱 명의 사망자가 발생했다.\"\n",
    "]\n",
    "\n",
    "# loss append\n",
    "history = {'loss':[], 'val_loss':[], 'lr':[]}\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm.notebook.tqdm(idx_list)  #tqdm_notebook(idx_list)\n",
    "\n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                    dec_train[idx:idx+BATCH_SIZE],\n",
    "                    transformer,\n",
    "                    optimizer)\n",
    "\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "        \n",
    "        history['loss'].append(round(total_loss.numpy() / (batch + 1),4))\n",
    "        history['lr'].append(optimizer.learning_rate)\n",
    "\n",
    "    for example in examples:\n",
    "        translate(example, transformer, kor_tokenizer, eng_tokenizer, epoch, plot_attention= False) #True)\n",
    "\n",
    "# loss 그래프 \n",
    "print(\"history.keys()\",history.keys()) \n",
    "plt.plot(range(len(history['loss'])),history['loss'])\n",
    "plt.title('Transformer_loss graph')\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9ccd8a",
   "metadata": {},
   "source": [
    "#### 학습2:  Hyper param Tuning 코드추가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "691d3a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0 param 20\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [1.00000000e+00 9.82171889e-01 9.64661620e-01 ... 1.05544960e-04\n",
      "  1.03663293e-04 1.01815172e-04]\n",
      " [2.00000000e+00 1.96434378e+00 1.92932324e+00 ... 2.11089920e-04\n",
      "  2.07326586e-04 2.03630344e-04]\n",
      " ...\n",
      " [4.70000000e+01 4.61620788e+01 4.53390961e+01 ... 4.96061312e-03\n",
      "  4.87217476e-03 4.78531309e-03]\n",
      " [4.80000000e+01 4.71442507e+01 4.63037578e+01 ... 5.06615808e-03\n",
      "  4.97583806e-03 4.88712826e-03]\n",
      " [4.90000000e+01 4.81264226e+01 4.72684194e+01 ... 5.17170304e-03\n",
      "  5.07950135e-03 4.98894344e-03]]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc5439864d242cf92ba63ab84f3193e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Epoch_변화시_학습율적용_step >> count_step 1118 lr 0.00019530655\n",
      "epoch_loss 7.7896\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the president\n",
      "epoch 0\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the affirmative is the first of the  ⁇ \n",
      "epoch 0\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the time is a .\n",
      "epoch 0\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the u . s .\n",
      "epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "456a10f5827f41a78cf87d889198f4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Epoch_변화시_학습율적용_step >> count_step 2236 lr 0.0003906131\n",
      "epoch_loss 6.7158\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the first time .\n",
      "epoch 1\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the move is the first time .\n",
      "epoch 1\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the greene s  ⁇ \n",
      "epoch 1\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the two were also , the country , said .\n",
      "epoch 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aad62c30c6c440f698b7a7f1646e163c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Epoch_변화시_학습율적용_step >> count_step 3354 lr 0.00058591965\n",
      "epoch_loss 6.1963\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is a very president .\n",
      "epoch 2\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the biggest , the arises was a .\n",
      "epoch 2\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: it s not a very very very very very very very very very very very very very very very very very very very very very .\n",
      "epoch 2\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the official said the company was killed in the block .\n",
      "epoch 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8517233628348c7bb225934a9e5a607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Epoch_변화시_학습율적용_step >> count_step 4472 lr 0.0006608671\n",
      "epoch_loss 5.8426\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the first time .\n",
      "epoch 3\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the biggest the city of the city .\n",
      "epoch 3\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: the has been a lot of the  ⁇ \n",
      "epoch 3\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the death of the deaths are in the death .\n",
      "epoch 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66cbf171af8440c483e18b68d38a73cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Epoch_변화시_학습율적용_step >> count_step 5590 lr 0.00059109746\n",
      "epoch_loss 5.4966\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the first time .\n",
      "epoch 4\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: thestormy of the city of the city of the city of the city s new york city .\n",
      "epoch 4\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: theshak is not a .\n",
      "epoch 4\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the death toll is death of the death toll .\n",
      "epoch 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2340e6399b5d44628790c79243d9874f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Epoch_변화시_학습율적용_step >> count_step 6708 lr 0.0005395957\n",
      "epoch_loss 5.1563\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama s president is the president of the president .\n",
      "epoch 5\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the time the city is in the city of the city of the city .\n",
      "epoch 5\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: it s not to be a  ⁇ \n",
      "epoch 5\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the death toll from the death toll .\n",
      "epoch 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b5747d1bcde45d1b199c03dc36ddcde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Epoch_변화시_학습율적용_step >> count_step 7826 lr 0.0004995686\n",
      "epoch_loss 4.8344\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is a way to be a president .\n",
      "epoch 6\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the study was a highest .\n",
      "epoch 6\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: there is no such a  ⁇ \n",
      "epoch 6\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: another death was killed .\n",
      "epoch 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf04245b0014fdf92315810b78fe2f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Epoch_변화시_학습율적용_step >> count_step 8944 lr 0.0004673036\n",
      "epoch_loss 4.5173\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama s presidential election .\n",
      "epoch 7\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the study was a highest .\n",
      "epoch 7\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: there is no more likely to be a great .\n",
      "epoch 7\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the death toll was reported .\n",
      "epoch 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427603a9e46c44c09f88372679d0bc54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Epoch_변화시_학습율적용_step >> count_step 10062 lr 0.00044057803\n",
      "epoch_loss 4.2025\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the best .\n",
      "epoch 8\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: the men are the men in the city of the city .\n",
      "epoch 8\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: it s a goodck .\n",
      "epoch 8\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the death toll in the city of death .\n",
      "epoch 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54aec8cfd31649dabc741325a8214138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Epoch_변화시_학습율적용_step >> count_step 11180 lr 0.00041796904\n",
      "epoch_loss 3.8945\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the way .\n",
      "epoch 9\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: vehicles in the city of the city .\n",
      "epoch 9\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: not just how the  ⁇ \n",
      "epoch 9\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: the deaths of the death toll in the nan have been killed since the death toll .\n",
      "epoch 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fcd1cf24454a7b8b37a8c3e1598c61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Epoch_변화시_학습율적용_step >> count_step 12298 lr 0.00039851782\n",
      "epoch_loss 3.5973\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the way .\n",
      "epoch 10\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: vehiclesy in the city .\n",
      "epoch 10\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: not only the  xl . not just about the problem .\n",
      "epoch 10\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: a small girl was killed .\n",
      "epoch 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3150be115ce04514aaed43f62b4a7db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Epoch_변화시_학습율적용_step >> count_step 13416 lr 0.0003815518\n",
      "epoch_loss 3.3173\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is a long termed by his the president .\n",
      "epoch 11\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: all vehicles get from the city .\n",
      "epoch 11\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: not only the very good . not only been very good .\n",
      "epoch 11\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: a small number of dead wererrays .\n",
      "epoch 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3218c47aba44fd6940ac1e566fd33de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Epoch_변화시_학습율적용_step >> count_step 14534 lr 0.00036658312\n",
      "epoch_loss 3.0553\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: the obamas are the same .\n",
      "epoch 12\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: they are very excited .\n",
      "epoch 12\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: there is no term in a visa .\n",
      "epoch 12\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: a small number of deadly dead .\n",
      "epoch 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01e0668919f42c19c6d1694ce573ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Epoch_변화시_학습율적용_step >> count_step 15652 lr 0.0003532483\n",
      "epoch_loss 2.8096\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is a espan .\n",
      "epoch 13\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: take theshape our\n",
      "epoch 13\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: there is no sign that there is no  ⁇ \n",
      "epoch 13\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: a small girl machine emba is stillhp .\n",
      "epoch 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "079e1643a6d74c6b8a81800b3543ffdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Epoch_변화시_학습율적용_step >> count_step 16770 lr 0.0003412703\n",
      "epoch_loss 2.5799\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the best way .\n",
      "epoch 14\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: vehicles was a dazzling ketch .\n",
      "epoch 14\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: there s never term in tighten cases . . . . . . . . . . you have a right .\n",
      "epoch 14\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: a small number of dead has been killed .\n",
      "epoch 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c37890a56d944ab8af6fa4c15df49803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Epoch_변화시_학습율적용_step >> count_step 17888 lr 0.00033043354\n",
      "epoch_loss 2.3703\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is a third liar .\n",
      "epoch 15\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: al , new complicated in the city of down .\n",
      "epoch 15\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: it s never more . it . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . com .\n",
      "epoch 15\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: a small girl , 4 ⁇  police .\n",
      "epoch 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ce7871634ce4f5c8ee2d755400f589e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Epoch_변화시_학습율적용_step >> count_step 19006 lr 0.00032056763\n",
      "epoch_loss 2.177\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is a verdierwalker .\n",
      "epoch 16\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: vehicles failed .\n",
      "epoch 16\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: there s never term . it s something . . i don t have a good . not rerun .\n",
      "epoch 16\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: a small girl hit has beenenez .\n",
      "epoch 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67aaac272ad54124b825de68f3f74a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Epoch_변화시_학습율적용_step >> count_step 20124 lr 0.00031153572\n",
      "epoch_loss 1.9987\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the best for his corners .\n",
      "epoch 17\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: nineally residents are from the city of growny .\n",
      "epoch 17\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: it s never more only about you re doing  ⁇ \n",
      "epoch 17\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: a hospital , which is 4 . skirmish\n",
      "epoch 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "010b5f91b1f8497fbfc837c13f3ff43b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Epoch_변화시_학습율적용_step >> count_step 21242 lr 0.0003032266\n",
      "epoch_loss 1.8355\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the best candidate .\n",
      "epoch 18\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: vehicles was nearly the city of support .\n",
      "epoch 18\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: you have to . to be changing a co loath .\n",
      "epoch 18\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: a small girl hit s chunk .\n",
      "epoch 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51b4f5575f4f409498b0d77caddd7217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1118 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Epoch_변화시_학습율적용_step >> count_step 22360 lr 0.00029554873\n",
      "epoch_loss 1.6844\n",
      "Input: 오바마는 대통령이다.\n",
      "Predicted translation: obama is the best candidate .\n",
      "epoch 19\n",
      "Input: 시민들은 도시 속에 산다.\n",
      "Predicted translation: vehicles weren t what increased was .\n",
      "epoch 19\n",
      "Input: 커피는 필요 없다.\n",
      "Predicted translation: there s never term . . . you know , there s never just you don t come from your lp . . . . . you feel at this rate .\n",
      "epoch 19\n",
      "Input: 일곱 명의 사망자가 발생했다.\n",
      "Predicted translation: a hospital .\n",
      "epoch 19\n",
      "history.keys() dict_keys(['EPOCHS']) dict_keys(['20'])\n",
      "history[hpname][f'{param}']['loss'] [7.7896, 6.7158, 6.1963, 5.8426, 5.4966, 5.1563, 4.8344, 4.5173, 4.2025, 3.8945, 3.5973, 3.3173, 3.0553, 2.8096, 2.5799, 2.3703, 2.177, 1.9987, 1.8355, 1.6844]\n",
      "history[hpname][f'{param}']['lr'] [0.00019530655, 0.0003906131, 0.00058591965, 0.0006608671, 0.00059109746, 0.0005395957, 0.0004995686, 0.0004673036, 0.00044057803, 0.00041796904, 0.00039851782, 0.0003815518, 0.00036658312, 0.0003532483, 0.0003412703, 0.00033043354, 0.00032056763, 0.00031153572, 0.0003032266, 0.00029554873]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 282,
       "width": 471
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS_Best_loss ['20', {'loss': [7.7896, 6.7158, 6.1963, 5.8426, 5.4966, 5.1563, 4.8344, 4.5173, 4.2025, 3.8945, 3.5973, 3.3173, 3.0553, 2.8096, 2.5799, 2.3703, 2.177, 1.9987, 1.8355, 1.6844], 'val_loss': [], 'lr': [0.00019530655, 0.0003906131, 0.00058591965, 0.0006608671, 0.00059109746, 0.0005395957, 0.0004995686, 0.0004673036, 0.00044057803, 0.00041796904, 0.00039851782, 0.0003815518, 0.00036658312, 0.0003532483, 0.0003412703, 0.00033043354, 0.00032056763, 0.00031153572, 0.0003032266, 0.00029554873], 'result': [[0, '오바마는 대통령이다.', 'obama is the president'], [0, '시민들은 도시 속에 산다.', 'the affirmative is the first of the  ⁇ '], [0, '커피는 필요 없다.', 'the time is a .'], [0, '일곱 명의 사망자가 발생했다.', 'the u . s .'], [1, '오바마는 대통령이다.', 'obama is the first time .'], [1, '시민들은 도시 속에 산다.', 'the move is the first time .'], [1, '커피는 필요 없다.', 'the greene s  ⁇ '], [1, '일곱 명의 사망자가 발생했다.', 'the two were also , the country , said .'], [2, '오바마는 대통령이다.', 'obama is a very president .'], [2, '시민들은 도시 속에 산다.', 'the biggest , the arises was a .'], [2, '커피는 필요 없다.', 'it s not a very very very very very very very very very very very very very very very very very very very very very .'], [2, '일곱 명의 사망자가 발생했다.', 'the official said the company was killed in the block .'], [3, '오바마는 대통령이다.', 'obama is the first time .'], [3, '시민들은 도시 속에 산다.', 'the biggest the city of the city .'], [3, '커피는 필요 없다.', 'the has been a lot of the  ⁇ '], [3, '일곱 명의 사망자가 발생했다.', 'the death of the deaths are in the death .'], [4, '오바마는 대통령이다.', 'obama is the first time .'], [4, '시민들은 도시 속에 산다.', 'thestormy of the city of the city of the city of the city s new york city .'], [4, '커피는 필요 없다.', 'theshak is not a .'], [4, '일곱 명의 사망자가 발생했다.', 'the death toll is death of the death toll .'], [5, '오바마는 대통령이다.', 'obama s president is the president of the president .'], [5, '시민들은 도시 속에 산다.', 'the time the city is in the city of the city of the city .'], [5, '커피는 필요 없다.', 'it s not to be a  ⁇ '], [5, '일곱 명의 사망자가 발생했다.', 'the death toll from the death toll .'], [6, '오바마는 대통령이다.', 'obama is a way to be a president .'], [6, '시민들은 도시 속에 산다.', 'the study was a highest .'], [6, '커피는 필요 없다.', 'there is no such a  ⁇ '], [6, '일곱 명의 사망자가 발생했다.', 'another death was killed .'], [7, '오바마는 대통령이다.', 'obama s presidential election .'], [7, '시민들은 도시 속에 산다.', 'the study was a highest .'], [7, '커피는 필요 없다.', 'there is no more likely to be a great .'], [7, '일곱 명의 사망자가 발생했다.', 'the death toll was reported .'], [8, '오바마는 대통령이다.', 'obama is the best .'], [8, '시민들은 도시 속에 산다.', 'the men are the men in the city of the city .'], [8, '커피는 필요 없다.', 'it s a goodck .'], [8, '일곱 명의 사망자가 발생했다.', 'the death toll in the city of death .'], [9, '오바마는 대통령이다.', 'obama is the way .'], [9, '시민들은 도시 속에 산다.', 'vehicles in the city of the city .'], [9, '커피는 필요 없다.', 'not just how the  ⁇ '], [9, '일곱 명의 사망자가 발생했다.', 'the deaths of the death toll in the nan have been killed since the death toll .'], [10, '오바마는 대통령이다.', 'obama is the way .'], [10, '시민들은 도시 속에 산다.', 'vehiclesy in the city .'], [10, '커피는 필요 없다.', 'not only the  xl . not just about the problem .'], [10, '일곱 명의 사망자가 발생했다.', 'a small girl was killed .'], [11, '오바마는 대통령이다.', 'obama is a long termed by his the president .'], [11, '시민들은 도시 속에 산다.', 'all vehicles get from the city .'], [11, '커피는 필요 없다.', 'not only the very good . not only been very good .'], [11, '일곱 명의 사망자가 발생했다.', 'a small number of dead wererrays .'], [12, '오바마는 대통령이다.', 'the obamas are the same .'], [12, '시민들은 도시 속에 산다.', 'they are very excited .'], [12, '커피는 필요 없다.', 'there is no term in a visa .'], [12, '일곱 명의 사망자가 발생했다.', 'a small number of deadly dead .'], [13, '오바마는 대통령이다.', 'obama is a espan .'], [13, '시민들은 도시 속에 산다.', 'take theshape our'], [13, '커피는 필요 없다.', 'there is no sign that there is no  ⁇ '], [13, '일곱 명의 사망자가 발생했다.', 'a small girl machine emba is stillhp .'], [14, '오바마는 대통령이다.', 'obama is the best way .'], [14, '시민들은 도시 속에 산다.', 'vehicles was a dazzling ketch .'], [14, '커피는 필요 없다.', 'there s never term in tighten cases . . . . . . . . . . you have a right .'], [14, '일곱 명의 사망자가 발생했다.', 'a small number of dead has been killed .'], [15, '오바마는 대통령이다.', 'obama is a third liar .'], [15, '시민들은 도시 속에 산다.', 'al , new complicated in the city of down .'], [15, '커피는 필요 없다.', 'it s never more . it . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . com .'], [15, '일곱 명의 사망자가 발생했다.', 'a small girl , 4 ⁇  police .'], [16, '오바마는 대통령이다.', 'obama is a verdierwalker .'], [16, '시민들은 도시 속에 산다.', 'vehicles failed .'], [16, '커피는 필요 없다.', 'there s never term . it s something . . i don t have a good . not rerun .'], [16, '일곱 명의 사망자가 발생했다.', 'a small girl hit has beenenez .'], [17, '오바마는 대통령이다.', 'obama is the best for his corners .'], [17, '시민들은 도시 속에 산다.', 'nineally residents are from the city of growny .'], [17, '커피는 필요 없다.', 'it s never more only about you re doing  ⁇ '], [17, '일곱 명의 사망자가 발생했다.', 'a hospital , which is 4 . skirmish'], [18, '오바마는 대통령이다.', 'obama is the best candidate .'], [18, '시민들은 도시 속에 산다.', 'vehicles was nearly the city of support .'], [18, '커피는 필요 없다.', 'you have to . to be changing a co loath .'], [18, '일곱 명의 사망자가 발생했다.', 'a small girl hit s chunk .'], [19, '오바마는 대통령이다.', 'obama is the best candidate .'], [19, '시민들은 도시 속에 산다.', 'vehicles weren t what increased was .'], [19, '커피는 필요 없다.', 'there s never term . . . you know , there s never just you don t come from your lp . . . . . you feel at this rate .'], [19, '일곱 명의 사망자가 발생했다.', 'a hospital .']]}]\n",
      "Best_hpname_param_list 1 [['EPOCHS', ['20', {'loss': [7.7896, 6.7158, 6.1963, 5.8426, 5.4966, 5.1563, 4.8344, 4.5173, 4.2025, 3.8945, 3.5973, 3.3173, 3.0553, 2.8096, 2.5799, 2.3703, 2.177, 1.9987, 1.8355, 1.6844], 'val_loss': [], 'lr': [0.00019530655, 0.0003906131, 0.00058591965, 0.0006608671, 0.00059109746, 0.0005395957, 0.0004995686, 0.0004673036, 0.00044057803, 0.00041796904, 0.00039851782, 0.0003815518, 0.00036658312, 0.0003532483, 0.0003412703, 0.00033043354, 0.00032056763, 0.00031153572, 0.0003032266, 0.00029554873], 'result': [[0, '오바마는 대통령이다.', 'obama is the president'], [0, '시민들은 도시 속에 산다.', 'the affirmative is the first of the  ⁇ '], [0, '커피는 필요 없다.', 'the time is a .'], [0, '일곱 명의 사망자가 발생했다.', 'the u . s .'], [1, '오바마는 대통령이다.', 'obama is the first time .'], [1, '시민들은 도시 속에 산다.', 'the move is the first time .'], [1, '커피는 필요 없다.', 'the greene s  ⁇ '], [1, '일곱 명의 사망자가 발생했다.', 'the two were also , the country , said .'], [2, '오바마는 대통령이다.', 'obama is a very president .'], [2, '시민들은 도시 속에 산다.', 'the biggest , the arises was a .'], [2, '커피는 필요 없다.', 'it s not a very very very very very very very very very very very very very very very very very very very very very .'], [2, '일곱 명의 사망자가 발생했다.', 'the official said the company was killed in the block .'], [3, '오바마는 대통령이다.', 'obama is the first time .'], [3, '시민들은 도시 속에 산다.', 'the biggest the city of the city .'], [3, '커피는 필요 없다.', 'the has been a lot of the  ⁇ '], [3, '일곱 명의 사망자가 발생했다.', 'the death of the deaths are in the death .'], [4, '오바마는 대통령이다.', 'obama is the first time .'], [4, '시민들은 도시 속에 산다.', 'thestormy of the city of the city of the city of the city s new york city .'], [4, '커피는 필요 없다.', 'theshak is not a .'], [4, '일곱 명의 사망자가 발생했다.', 'the death toll is death of the death toll .'], [5, '오바마는 대통령이다.', 'obama s president is the president of the president .'], [5, '시민들은 도시 속에 산다.', 'the time the city is in the city of the city of the city .'], [5, '커피는 필요 없다.', 'it s not to be a  ⁇ '], [5, '일곱 명의 사망자가 발생했다.', 'the death toll from the death toll .'], [6, '오바마는 대통령이다.', 'obama is a way to be a president .'], [6, '시민들은 도시 속에 산다.', 'the study was a highest .'], [6, '커피는 필요 없다.', 'there is no such a  ⁇ '], [6, '일곱 명의 사망자가 발생했다.', 'another death was killed .'], [7, '오바마는 대통령이다.', 'obama s presidential election .'], [7, '시민들은 도시 속에 산다.', 'the study was a highest .'], [7, '커피는 필요 없다.', 'there is no more likely to be a great .'], [7, '일곱 명의 사망자가 발생했다.', 'the death toll was reported .'], [8, '오바마는 대통령이다.', 'obama is the best .'], [8, '시민들은 도시 속에 산다.', 'the men are the men in the city of the city .'], [8, '커피는 필요 없다.', 'it s a goodck .'], [8, '일곱 명의 사망자가 발생했다.', 'the death toll in the city of death .'], [9, '오바마는 대통령이다.', 'obama is the way .'], [9, '시민들은 도시 속에 산다.', 'vehicles in the city of the city .'], [9, '커피는 필요 없다.', 'not just how the  ⁇ '], [9, '일곱 명의 사망자가 발생했다.', 'the deaths of the death toll in the nan have been killed since the death toll .'], [10, '오바마는 대통령이다.', 'obama is the way .'], [10, '시민들은 도시 속에 산다.', 'vehiclesy in the city .'], [10, '커피는 필요 없다.', 'not only the  xl . not just about the problem .'], [10, '일곱 명의 사망자가 발생했다.', 'a small girl was killed .'], [11, '오바마는 대통령이다.', 'obama is a long termed by his the president .'], [11, '시민들은 도시 속에 산다.', 'all vehicles get from the city .'], [11, '커피는 필요 없다.', 'not only the very good . not only been very good .'], [11, '일곱 명의 사망자가 발생했다.', 'a small number of dead wererrays .'], [12, '오바마는 대통령이다.', 'the obamas are the same .'], [12, '시민들은 도시 속에 산다.', 'they are very excited .'], [12, '커피는 필요 없다.', 'there is no term in a visa .'], [12, '일곱 명의 사망자가 발생했다.', 'a small number of deadly dead .'], [13, '오바마는 대통령이다.', 'obama is a espan .'], [13, '시민들은 도시 속에 산다.', 'take theshape our'], [13, '커피는 필요 없다.', 'there is no sign that there is no  ⁇ '], [13, '일곱 명의 사망자가 발생했다.', 'a small girl machine emba is stillhp .'], [14, '오바마는 대통령이다.', 'obama is the best way .'], [14, '시민들은 도시 속에 산다.', 'vehicles was a dazzling ketch .'], [14, '커피는 필요 없다.', 'there s never term in tighten cases . . . . . . . . . . you have a right .'], [14, '일곱 명의 사망자가 발생했다.', 'a small number of dead has been killed .'], [15, '오바마는 대통령이다.', 'obama is a third liar .'], [15, '시민들은 도시 속에 산다.', 'al , new complicated in the city of down .'], [15, '커피는 필요 없다.', 'it s never more . it . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . com .'], [15, '일곱 명의 사망자가 발생했다.', 'a small girl , 4 ⁇  police .'], [16, '오바마는 대통령이다.', 'obama is a verdierwalker .'], [16, '시민들은 도시 속에 산다.', 'vehicles failed .'], [16, '커피는 필요 없다.', 'there s never term . it s something . . i don t have a good . not rerun .'], [16, '일곱 명의 사망자가 발생했다.', 'a small girl hit has beenenez .'], [17, '오바마는 대통령이다.', 'obama is the best for his corners .'], [17, '시민들은 도시 속에 산다.', 'nineally residents are from the city of growny .'], [17, '커피는 필요 없다.', 'it s never more only about you re doing  ⁇ '], [17, '일곱 명의 사망자가 발생했다.', 'a hospital , which is 4 . skirmish'], [18, '오바마는 대통령이다.', 'obama is the best candidate .'], [18, '시민들은 도시 속에 산다.', 'vehicles was nearly the city of support .'], [18, '커피는 필요 없다.', 'you have to . to be changing a co loath .'], [18, '일곱 명의 사망자가 발생했다.', 'a small girl hit s chunk .'], [19, '오바마는 대통령이다.', 'obama is the best candidate .'], [19, '시민들은 도시 속에 산다.', 'vehicles weren t what increased was .'], [19, '커피는 필요 없다.', 'there s never term . . . you know , there s never just you don t come from your lp . . . . . you feel at this rate .'], [19, '일곱 명의 사망자가 발생했다.', 'a hospital .']]}]]]\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 튜닝_학습\n",
    "from tqdm import tqdm_notebook \n",
    "import tqdm\n",
    "\n",
    "#Training Parameters\n",
    "warmup_steps = 4000\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20 \n",
    "\n",
    "n_layers= 2\n",
    "d_model= 512\n",
    "n_heads= 8  \n",
    "d_ff= 2048\n",
    "src_vocab_size = 25000\n",
    "tgt_vocab_size = 25000\n",
    "pos_len = 50  \n",
    "dropout= 0.3\n",
    "optimizer = []\n",
    "shared=True\n",
    "\n",
    "\n",
    "examples = [\"오바마는 대통령이다.\", \"시민들은 도시 속에 산다.\", \"커피는 필요 없다.\", \"일곱 명의 사망자가 발생했다.\"]\n",
    "\n",
    "## Hyper param tuning : hparam 한개씩 해서,search space 구성후, loss가 제일 낮은 param을 1차 자동선택후,  번역수준을 눈으로 추가확인  \n",
    "# hpname list 설정\n",
    "hp_name_list = ['EPOCHS'] \n",
    "\n",
    "# search space 설정: param 설정\n",
    "dropout_list = [0.1,0.3,0.5]\n",
    "optimizer_list = [tf.keras.optimizers.RMSprop(learning_rate),tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)]\n",
    "warmup_steps_list = [2000,4000,6000]\n",
    "d_model_list = [256,1024]\n",
    "batchsize_list = [64,128, 256]\n",
    "epoch_list= [20]\n",
    "\n",
    "# 금번 Tuning 대상 설정\n",
    "total_hyperparam_list = [epoch_list]\n",
    "\n",
    "# 필요 list\n",
    "hyperparam_list = []\n",
    "Best_hpname_param_list = []\n",
    "\n",
    "# 학습 Histoty Dict 설정\n",
    "history={}\n",
    "\n",
    "# Hyper param Tuning 실행\n",
    "for ix, hpname in enumerate(hp_name_list):\n",
    "    history[hpname]={}\n",
    "    hyperparam_list = total_hyperparam_list[ix]    \n",
    "    for i, param in enumerate(hyperparam_list):\n",
    "        print(\"i\",i, \"param\",param)\n",
    "        history[hpname][f'{param}']= {'loss':[], 'val_loss':[], 'lr':[],'result':[]}\n",
    "\n",
    "        del transformer\n",
    "\n",
    "        # 트랜스포머 모델설정\n",
    "        transformer = Transformer(n_layers,\n",
    "                                  d_model,\n",
    "                                  n_heads,\n",
    "                                  d_ff,\n",
    "                                  src_vocab_size,\n",
    "                                  tgt_vocab_size,\n",
    "                                  pos_len,\n",
    "                                  dropout,\n",
    "                                  shared=True)\n",
    "\n",
    "        # 학습율 객체화 \n",
    "        learning_rate = LearningRateScheduler(d_model = d_model, warmup_steps = warmup_steps)\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "        \n",
    "        # 별도 학습율 계산 함수 정의\n",
    "        def compute_lr(step,warmup_steps):\n",
    "            arg1 = step ** -0.5\n",
    "            arg2 = step * (warmup_steps ** -1.5)\n",
    "            lr= (d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "            lr = lr.numpy()\n",
    "            return lr\n",
    "        \n",
    "\n",
    "        @tf.function()\n",
    "        def train_step(src, tgt, model, optimizer):\n",
    "            gold = tgt[:, 1:]\n",
    "\n",
    "            enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "            # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "            with tf.GradientTape() as tape:\n",
    "                predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "                loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "                # 최종적으로 optimizer.apply_gradients()가 사용됩니다. \n",
    "                # [[YOUR CODE]]\n",
    "                variables = model.encoder.trainable_variables + model.decoder.trainable_variables \n",
    "                gradients = tape.gradient(loss, variables)\n",
    "                optimizer.apply_gradients(zip(gradients, variables))\n",
    "\n",
    "            return loss, enc_attns, dec_attns, dec_enc_attns\n",
    "        \n",
    "\n",
    "        count_step = 0\n",
    "        for epoch in range(param):  #EPOCHS):\n",
    "            total_loss = 0\n",
    "\n",
    "            idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "            random.shuffle(idx_list)\n",
    "            t = tqdm.notebook.tqdm(idx_list)  #tqdm_notebook(idx_list)\n",
    "            \n",
    "            for (batch, idx) in enumerate(t):\n",
    "                count_step+= 1\n",
    "                batch_loss, enc_attns, dec_attns, dec_enc_attns = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                            dec_train[idx:idx+BATCH_SIZE],transformer, optimizer)  \n",
    "\n",
    "                total_loss += batch_loss      #batch_loss: 배치단위인데, 배치내에서, seq_len으로 나눈것,즉,배치내 단어별 평균손실\n",
    "                batch_loss1 = round(total_loss.numpy() / (batch + 1),4)   # 총누적손실을 누적배치size로 나눈것,즉,배치별 평균\n",
    "                \n",
    "                t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "                t.set_postfix_str('Loss %.4f' % (batch_loss1))\n",
    "                \n",
    "                # step기준 learning_rate\n",
    "                lr = compute_lr(count_step, warmup_steps)\n",
    "                \n",
    "                # step기준 batch 단위 loss 집계 \n",
    "                #history[hpname][f'{param}']['loss'].append(batch_loss1)\n",
    "                #history['lr'].append(optimizer.learning_rate)\n",
    "                #history['lr'].append(optimizer.learning_rate)\n",
    "                \n",
    "            print(\"Epoch\",epoch, \"Epoch_변화시_학습율적용_step >> count_step\",count_step, \"lr\", lr)    \n",
    "            \n",
    "            # epoch기준 loss 및 lr 집계   \n",
    "            print('epoch_loss', batch_loss1)\n",
    "            history[hpname][f'{param}']['loss'].append(batch_loss1)\n",
    "            history[hpname][f'{param}']['lr'].append(lr)\n",
    "            \n",
    "            \n",
    "            for example in examples:\n",
    "                translate_result = translate(example, transformer, kor_tokenizer, eng_tokenizer, epoch, plot_attention= False) #True)\n",
    "                history[hpname][f'{param}']['result'].append(translate_result)\n",
    "\n",
    "\n",
    "        # loss 그래프 \n",
    "        print(\"history.keys()\",history.keys(), history[hpname].keys() ) \n",
    "        print(\"history[hpname][f'{param}']['loss']\", history[hpname][f'{param}']['loss'])\n",
    "        print(\"history[hpname][f'{param}']['lr']\", history[hpname][f'{param}']['lr'])\n",
    "        \n",
    "        fig,ax = plt.subplots(1,2)\n",
    "        ax[0].plot(range(len(history[hpname][f'{param}']['loss'])),history[hpname][f'{param}']['loss'])\n",
    "        ax[0].set_title(hpname +'_'+  f'{param}_Transformer_loss graph')\n",
    "        ax[0].set_xlabel('epoch')\n",
    "        ax[0].set_ylabel('loss')\n",
    "        ax[1].plot(range(len(history[hpname][f'{param}']['lr'])),history[hpname][f'{param}']['lr'])\n",
    "        ax[1].set_title(hpname +'_'+   f'{param}_Transformer_learning_rate graph')\n",
    "        ax[1].set_xlabel('epoch')\n",
    "        ax[1].set_ylabel('lr')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "            \n",
    "    # Best_param 선택 \n",
    "    \n",
    "    Best_loss =  [[k1,v1] for k1,v1 in history[hpname].items() if v1['loss'][-1] == np.min([v['loss'][-1] for k,v in history[hpname].items()])][0] \n",
    "    print(hpname+\"_Best_loss\", Best_loss,)\n",
    "   \n",
    "    # hpname별 Best_param 집계\n",
    "    Best_hpname_param_list.append([hpname, Best_loss])\n",
    "    \n",
    "print(\"Best_hpname_param_list\",len(Best_hpname_param_list),Best_hpname_param_list)\n",
    "                                   \n",
    "# 저장\n",
    "dfhistory = pd.DataFrame(history)\n",
    "dfhistory.to_pickle(f'/aiffel/aiffel/transformer/data/History_{hpname}')\n",
    "\n",
    "df = pd.DataFrame(Best_hpname_param_list)  \n",
    "df.to_pickle(f'/aiffel/aiffel/transformer/data/Best_hpname_param_list_{hpname}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b439ed",
   "metadata": {},
   "source": [
    "## 종합요약\n",
    "\n",
    "#### 번역문 평가 \n",
    "\"오바마는 대통렬이다\" 한문장만 맞고, 나머지 두문장 \"시민들은 도시 속에 산다\",\"일곱 명의 사망자가 발생했다\"는 문맥속에 단어만 일부 들어있는데, \"커피는 필요 없다\" 문장은 커피란 단어조차 않들어간 엉뚱한 번역문임\n",
    "\n",
    "```\n",
    "[0, '오바마는 대통령이다.', 'obama is the president'],\n",
    "[8, '시민들은 도시 속에 산다.', 'the men are the men in the city of the city .'],\n",
    "[16, '커피는 필요 없다.\n",
    "[14, '일곱 명의 사망자가 발생했다.', 'a small number of dead has been killed .'] \n",
    " \n",
    "```\n",
    "\n",
    "#### 하이퍼 파람\n",
    "warmup_steps = 4000   \n",
    "BATCH_SIZE = 64   \n",
    "EPOCHS = 20    \n",
    "\n",
    "n_layers= 2   \n",
    "d_model= 512   \n",
    "n_heads= 8    \n",
    "d_ff= 2048   \n",
    "src_vocab_size = 25000   \n",
    "tgt_vocab_size = 25000   \n",
    "pos_len = 50     \n",
    "dropout= 0.3   \n",
    "optimizer = tf.keras.optimizers.Adam()   \n",
    "shared=True   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30964e9",
   "metadata": {},
   "source": [
    "## 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848fe23f",
   "metadata": {},
   "source": [
    "본 프로젝트는 트랜스포머모델을 활용하여, 한글을 영어로 번역하는 프로젝트입니다.\n",
    "\n",
    "한글 및 영어 데이터를 다운로드 받아서, 번역쌍(pair)을 흐트르지 않고서 중복데이터를 제거하기위해, zip 과 set을 사용하여,\n",
    "중복을 제거하였고(결측치제거 병행), 데이터는 원래 94123 쌍에서, 78968쌍으로 약 15%가 줄었습니다. \n",
    "\n",
    "남은 문장들을 대상으로  소문자변환, 숫자및한글및영어및 특수문자, 공백처리등등의 데이터정제 및 target문자 'BOS','EOS'처리를 해주는\n",
    "preprocess함수를 정의하였고, SentencePiece기법을 사용하여, 한글과 영어를 병행하여, train을 시켜서, 단어토큰화및 정수인덱스토큰화를 할수 있는\n",
    "generate_tokenizer함수를 만들어서, kor_tokenizer와 eng_tokenizer를 완성하였습니다.          \n",
    "여기에서, 별도로 'BOS', 'EOS' 코딩않해도 영어문장 앞뒤로 붙게해주는 옵션 tokenizer.set_encode_extra_options(\"bos:eos\")\n",
    "도 배웠습니다.  preprocess함수에서의 <BOS>,<EOS>처리코드를 삭제해도 되지만, 나중 참조를 위해 메모해두고 유지했습니다.   \n",
    "\n",
    "SRC_VOCAB_SIZE 와 TGT_VOCAB_SIZE는 25,000로 설정했고,SentencePiece의 EncodeAsPieces,EncodeAsIds를 사용하여, \n",
    "사용하기 편리한 단어사전 word_index,index_word을 만들었습니다\n",
    "\n",
    "여기서, 한글,영어 공히 문장의 최대길이가 50이하가 되도록 maxlen을 50으로 잡고 초과되는 문장을 제거하고서, \n",
    "tf.keras.preprocessing.sequence.pad_sequences로 padding처리하였는데, 최종 학습에 들어가는 문장은 78968쌍에서,\n",
    "71288쌍으로 축소되었고 이문장들은 모두 사용할 예정입니다.\n",
    "\n",
    "transfor 모델설계는 여태까지 배운 다른 어떤 딥러닝모델보다, 모델내의 중여한 구성품이 많습니다.   \n",
    "positional_encoding함수,MultiHeadAttention함수,PoswiseFeedForwardNet함수,EncoderLayer함수,DecoderLayer함수,\n",
    "Encoder함수,Decoder함수,앞서의 layer들을 조합할 Transformer 모델함수를 내부의 작동원리를 코드를 통해 하나하나 익혀가면서,\n",
    "만들었습니다.\n",
    "\n",
    "그리고, 마스크를 만들 3개의 함수 generate_padding_mask, generate_causality_mask, generate_masks함수를 만들었는데,\n",
    "이 함스들로 enc_mask, dec_enc_mask, dec_mask 3종류의 마스크를 만들어서, 인코더의 MultiHeadAttention,\n",
    "디코더의 masked_MultiHeadAttention, dec_enc_MultiHeadAttention내의 scaled_dot_qk에 적용됩니다.\n",
    "(디코더에 적용되는 마스크들은 tf.maximum에 의해서, padding과 Not lookahead를 동시에 할수있게 처리되었습니다.\n",
    " \n",
    "train step진행에따라, 학습율이 증가했다가 4000step이후 감소되는 LearningRateScheduler함수, optimize설정및 \n",
    "labeldata의 padding을 처리해줄 마스크를 적용해주는 custom loss function을 만들었습니다. \n",
    "\n",
    "미분및 역전파등 핵심적 학습을 진행시킬 train step함수, 시각화 및 평가함수를 하나 하나 내부의 코드들의 작동순서및 원리들를\n",
    "파악해가며 만들었습니다.\n",
    " \n",
    "최종적으로 학습 epoch를 진행시킬 for loop 코드를 만들어서, transformer가 train step함수를 통해서,batch size단위별로\n",
    "학습이 진해되도록 하였고, 학습로그기록을 위해, history dict를 만들어서, epoch별로 학습loss 및 변화되는 learning_rate가\n",
    "기록되도록 하였습니다. ( learning_rate 는 학습율 계산하는 함수를 산정공식 그대로 적용하여 만들어서, epoch마다 기록및 프린트함)\n",
    " \n",
    "Hyper param Tuning을 위해 KerasTuner를 LMS에 인스톨하여 사용해 보았는데, dependency 문제가 있는지,작동하지를 않아서 사용을 못하고,\n",
    "학습 loop 상위에 Tuning for loop를 씌워서, dropout rate, warmup_steps, optimizer, batch_size,epoch등을 해보았는데,\n",
    "LMS교재상의 지정된 Hyper param과 거의 같게 나와서, 시간관계상 나머지 Hyper param은 LMS 그대로 사용하였습니다.   \n",
    "\n",
    "epock별로 번역결과를 출력해서, 번역결과의 개선여부를 살펴보았는데, 눈에띄게 잘된 번역은 잘 않보이고, 맞는 단어가 한두개이상씩\n",
    "들어가있는 수준이었습니다. 제출후 시간을 갖고서, layer를 2개로 제한된데서, 4개이상으로 늘려서, \n",
    "epoch를 충분히 300 회이상 시켜 보아야 제대로 된 번역이 나올것 같다는 생각입니다.\n",
    " \n",
    "지금 세계적으로 열풍이 부는 chatGPT도 동일한(내부에 개선된 부품코드가 있을 수 있겠으나) 트랜스포머로 만들었으니,\n",
    "모델 내부의 개선점도 찾아보고, 아이디어들을 발굴접목하며,지속적으로 모델을 개선해서, 현실세계에서, \n",
    "다양한 문제에 적용해볼 생각입니다.   \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0847b5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba627e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "save_path  = '/aiffel/aiffel/transformer/model'\n",
    "\n",
    "#encoder.save(save_path + '/s2s_encoder_model.h5')\n",
    "#decoder.save(save_path + '/s2s_decoder_model.h5')\n",
    "\n",
    "#encoder = load_model('s2s_encoder_model.h5')\n",
    "#decoder = load_model('s2s_decoder_model.h5')\n",
    "\n",
    "#model_to_dot(encoder, show_shapes=True)\n",
    "#model_to_dot(decoder, show_shapes=True)\n",
    "\n",
    "#transformer.save(save_path)  ??????????????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434da4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ebccd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02aa560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939b477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c60753",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
